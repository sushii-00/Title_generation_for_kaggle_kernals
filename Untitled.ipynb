{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "73d271e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Activation\n",
    "import gensim\n",
    "from numpy import array\n",
    "import tensorflow.keras.utils as ku\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from keras.models import load_model\n",
    "# set seeds for reproducability\n",
    "# from tensorflow import set_random_seed\n",
    "# from numpy.random import seed\n",
    "# set_random_seed(2)\n",
    "# seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff12977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\sudha\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sudha\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sudha\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sudha\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\sudha\\anaconda3\\envs\\tf2.6.0\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68a8461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Competitions.csv', 'CompetitionTags.csv', 'Datasets.csv', 'DatasetTags.csv', 'DatasetTasks.csv', 'DatasetTaskSubmissions.csv', 'DatasetVersions.csv', 'DatasetVotes.csv', 'Datasources.csv', 'EpisodeAgents.csv', 'Episodes.csv', 'ForumMessages.csv', 'ForumMessageVotes.csv', 'Forums.csv', 'ForumTopics.csv', 'KernelLanguages.csv', 'Kernels.csv', 'KernelTags.csv', 'KernelVersionCompetitionSources.csv', 'KernelVersionDatasetSources.csv', 'KernelVersionKernelSources.csv', 'KernelVersions.csv', 'KernelVotes.csv', 'Organizations.csv', 'Submissions.csv', 'Tags.csv', 'TeamMemberships.csv', 'Teams.csv', 'UserAchievements.csv', 'UserFollowers.csv', 'UserOrganizations.csv', 'Users.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"archive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5e21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions = pd.read_csv(\"archive/KernelVersions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c022716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ScriptId</th>\n",
       "      <th>ParentScriptVersionId</th>\n",
       "      <th>ScriptLanguageId</th>\n",
       "      <th>AuthorUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>VersionNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>EvaluationDate</th>\n",
       "      <th>IsChange</th>\n",
       "      <th>TotalLines</th>\n",
       "      <th>LinesInsertedFromPrevious</th>\n",
       "      <th>LinesChangedFromPrevious</th>\n",
       "      <th>LinesUnchangedFromPrevious</th>\n",
       "      <th>LinesInsertedFromFork</th>\n",
       "      <th>LinesDeletedFromFork</th>\n",
       "      <th>LinesChangedFromFork</th>\n",
       "      <th>LinesUnchangedFromFork</th>\n",
       "      <th>TotalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2212</td>\n",
       "      <td>455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>54628</td>\n",
       "      <td>04/23/2015 02:04:57</td>\n",
       "      <td>5.0</td>\n",
       "      <td>caretNN test</td>\n",
       "      <td>04/23/2015</td>\n",
       "      <td>True</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2215</td>\n",
       "      <td>455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>54628</td>\n",
       "      <td>04/23/2015 02:18:27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>caretNN test</td>\n",
       "      <td>04/23/2015</td>\n",
       "      <td>True</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2219</td>\n",
       "      <td>455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>54628</td>\n",
       "      <td>04/23/2015 02:33:14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>caretNN test</td>\n",
       "      <td>04/23/2015</td>\n",
       "      <td>True</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2221</td>\n",
       "      <td>455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>54628</td>\n",
       "      <td>04/23/2015 02:33:52</td>\n",
       "      <td>8.0</td>\n",
       "      <td>caretNN test</td>\n",
       "      <td>04/23/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2268</td>\n",
       "      <td>494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>103872</td>\n",
       "      <td>04/23/2015 09:50:16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Starter Logistic Regression in R</td>\n",
       "      <td>04/23/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  ScriptId  ParentScriptVersionId  ScriptLanguageId  AuthorUserId  \\\n",
       "0  2212       455                    NaN                 1         54628   \n",
       "1  2215       455                    NaN                 1         54628   \n",
       "2  2219       455                    NaN                 1         54628   \n",
       "3  2221       455                    NaN                 1         54628   \n",
       "4  2268       494                    NaN                 1        103872   \n",
       "\n",
       "          CreationDate  VersionNumber                             Title  \\\n",
       "0  04/23/2015 02:04:57            5.0                      caretNN test   \n",
       "1  04/23/2015 02:18:27            6.0                      caretNN test   \n",
       "2  04/23/2015 02:33:14            7.0                      caretNN test   \n",
       "3  04/23/2015 02:33:52            8.0                      caretNN test   \n",
       "4  04/23/2015 09:50:16            1.0  Starter Logistic Regression in R   \n",
       "\n",
       "  EvaluationDate  IsChange  TotalLines  LinesInsertedFromPrevious  \\\n",
       "0     04/23/2015      True        48.0                        0.0   \n",
       "1     04/23/2015      True        48.0                        0.0   \n",
       "2     04/23/2015      True        48.0                        0.0   \n",
       "3     04/23/2015     False        48.0                        0.0   \n",
       "4     04/23/2015     False        55.0                        NaN   \n",
       "\n",
       "   LinesChangedFromPrevious  LinesUnchangedFromPrevious  \\\n",
       "0                       1.0                        48.0   \n",
       "1                       1.0                        48.0   \n",
       "2                       1.0                        48.0   \n",
       "3                       1.0                        48.0   \n",
       "4                       NaN                         NaN   \n",
       "\n",
       "   LinesInsertedFromFork  LinesDeletedFromFork  LinesChangedFromFork  \\\n",
       "0                    NaN                   NaN                   NaN   \n",
       "1                    NaN                   NaN                   NaN   \n",
       "2                    NaN                   NaN                   NaN   \n",
       "3                    NaN                   NaN                   NaN   \n",
       "4                    0.0                   0.0                   0.0   \n",
       "\n",
       "   LinesUnchangedFromFork  TotalVotes  \n",
       "0                     NaN           0  \n",
       "1                     NaN           0  \n",
       "2                     NaN           0  \n",
       "3                     NaN           2  \n",
       "4                    56.0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_versions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94535f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_versions.sort_values(by = ['Id'] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0c99a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ScriptId</th>\n",
       "      <th>ParentScriptVersionId</th>\n",
       "      <th>ScriptLanguageId</th>\n",
       "      <th>AuthorUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>VersionNumber</th>\n",
       "      <th>Title</th>\n",
       "      <th>EvaluationDate</th>\n",
       "      <th>IsChange</th>\n",
       "      <th>TotalLines</th>\n",
       "      <th>LinesInsertedFromPrevious</th>\n",
       "      <th>LinesChangedFromPrevious</th>\n",
       "      <th>LinesUnchangedFromPrevious</th>\n",
       "      <th>LinesInsertedFromFork</th>\n",
       "      <th>LinesDeletedFromFork</th>\n",
       "      <th>LinesChangedFromFork</th>\n",
       "      <th>LinesUnchangedFromFork</th>\n",
       "      <th>TotalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2505</td>\n",
       "      <td>03/25/2015 18:25:32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hello</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3716</td>\n",
       "      <td>03/25/2015 18:31:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RF Proximity</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3716</td>\n",
       "      <td>03/25/2015 18:51:15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RF Proximity</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3716</td>\n",
       "      <td>03/25/2015 21:57:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R version</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3716</td>\n",
       "      <td>03/25/2015 21:57:44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R version</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997556</th>\n",
       "      <td>82788715</td>\n",
       "      <td>22893137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>5868546</td>\n",
       "      <td>12/20/2021 03:14:09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bike Sharing Members v Casual Users</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997476</th>\n",
       "      <td>82788832</td>\n",
       "      <td>21869635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>1017089</td>\n",
       "      <td>12/20/2021 03:16:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Predict ICU Mortality - SHAP</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996883</th>\n",
       "      <td>82788835</td>\n",
       "      <td>22884657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>9187572</td>\n",
       "      <td>12/20/2021 03:16:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pytorch CNN 97%</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996884</th>\n",
       "      <td>82788868</td>\n",
       "      <td>22882435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8999151</td>\n",
       "      <td>12/20/2021 03:17:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>remote-sensing-fcn</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996153</th>\n",
       "      <td>82788891</td>\n",
       "      <td>22200613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8430941</td>\n",
       "      <td>12/20/2021 03:17:39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CV_Xử Lý Dog-Cat-Pandas image classifier CNN</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>True</td>\n",
       "      <td>263.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5998013 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  ScriptId  ParentScriptVersionId  ScriptLanguageId  \\\n",
       "724             1         1                    NaN                 1   \n",
       "1919            2         2                    NaN                 1   \n",
       "1920            8         2                    NaN                 1   \n",
       "639             9         4                    NaN                 1   \n",
       "640            10         4                    NaN                 1   \n",
       "...           ...       ...                    ...               ...   \n",
       "5997556  82788715  22893137                    NaN                12   \n",
       "5997476  82788832  21869635                    NaN                 9   \n",
       "5996883  82788835  22884657                    NaN                 8   \n",
       "5996884  82788868  22882435                    NaN                 8   \n",
       "5996153  82788891  22200613                    NaN                 9   \n",
       "\n",
       "         AuthorUserId         CreationDate  VersionNumber  \\\n",
       "724              2505  03/25/2015 18:25:32            1.0   \n",
       "1919             3716  03/25/2015 18:31:07            1.0   \n",
       "1920             3716  03/25/2015 18:51:15            2.0   \n",
       "639              3716  03/25/2015 21:57:36            1.0   \n",
       "640              3716  03/25/2015 21:57:44            2.0   \n",
       "...               ...                  ...            ...   \n",
       "5997556       5868546  12/20/2021 03:14:09            2.0   \n",
       "5997476       1017089  12/20/2021 03:16:33            2.0   \n",
       "5996883       9187572  12/20/2021 03:16:40            NaN   \n",
       "5996884       8999151  12/20/2021 03:17:18            NaN   \n",
       "5996153       8430941  12/20/2021 03:17:39            1.0   \n",
       "\n",
       "                                                Title EvaluationDate  \\\n",
       "724                                             hello     03/23/2018   \n",
       "1919                                     RF Proximity     03/23/2018   \n",
       "1920                                     RF Proximity     03/23/2018   \n",
       "639                                         R version     03/23/2018   \n",
       "640                                         R version     03/23/2018   \n",
       "...                                               ...            ...   \n",
       "5997556           Bike Sharing Members v Casual Users     12/20/2021   \n",
       "5997476                  Predict ICU Mortality - SHAP     12/20/2021   \n",
       "5996883                               pytorch CNN 97%     12/20/2021   \n",
       "5996884                            remote-sensing-fcn     12/20/2021   \n",
       "5996153  CV_Xử Lý Dog-Cat-Pandas image classifier CNN     12/20/2021   \n",
       "\n",
       "         IsChange  TotalLines  LinesInsertedFromPrevious  \\\n",
       "724          True         1.0                        NaN   \n",
       "1919         True        79.0                        NaN   \n",
       "1920         True        79.0                        0.0   \n",
       "639          True         1.0                        NaN   \n",
       "640          True         1.0                        0.0   \n",
       "...           ...         ...                        ...   \n",
       "5997556     False       178.0                        0.0   \n",
       "5997476     False       649.0                        0.0   \n",
       "5996883     False         NaN                        NaN   \n",
       "5996884     False         NaN                        NaN   \n",
       "5996153      True       263.0                       18.0   \n",
       "\n",
       "         LinesChangedFromPrevious  LinesUnchangedFromPrevious  \\\n",
       "724                           NaN                         NaN   \n",
       "1919                          NaN                         NaN   \n",
       "1920                          0.0                        80.0   \n",
       "639                           NaN                         NaN   \n",
       "640                           0.0                         2.0   \n",
       "...                           ...                         ...   \n",
       "5997556                       0.0                       178.0   \n",
       "5997476                       0.0                       649.0   \n",
       "5996883                       NaN                         NaN   \n",
       "5996884                       NaN                         NaN   \n",
       "5996153                       0.0                       245.0   \n",
       "\n",
       "         LinesInsertedFromFork  LinesDeletedFromFork  LinesChangedFromFork  \\\n",
       "724                        NaN                   NaN                   NaN   \n",
       "1919                       NaN                   NaN                   NaN   \n",
       "1920                       NaN                   NaN                   NaN   \n",
       "639                        NaN                   NaN                   NaN   \n",
       "640                        NaN                   NaN                   NaN   \n",
       "...                        ...                   ...                   ...   \n",
       "5997556                    NaN                   NaN                   NaN   \n",
       "5997476                    0.0                   8.0                   0.0   \n",
       "5996883                    NaN                   NaN                   NaN   \n",
       "5996884                    NaN                   NaN                   NaN   \n",
       "5996153                   18.0                  10.0                   0.0   \n",
       "\n",
       "         LinesUnchangedFromFork  TotalVotes  \n",
       "724                         NaN           0  \n",
       "1919                        NaN           0  \n",
       "1920                        NaN           0  \n",
       "639                         NaN           0  \n",
       "640                         NaN           0  \n",
       "...                         ...         ...  \n",
       "5997556                     NaN           0  \n",
       "5997476                   649.0           0  \n",
       "5996883                     NaN           0  \n",
       "5996884                     NaN           0  \n",
       "5996153                   245.0           0  \n",
       "\n",
       "[5998013 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f362e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5998013"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kernel_versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0d58f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82782199"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_versions['Id'][5998012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26a1465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_versions['Id'][0]==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3833cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5998013):\n",
    "    if kernel_versions['Id'][i] == 2212:\n",
    "        print(i)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Title  TotalVotes\n",
      "724                                               hello           0\n",
      "1919                                       RF Proximity           0\n",
      "1920                                       RF Proximity           0\n",
      "639                                           R version           0\n",
      "640                                           R version           0\n",
      "641                                           R version           0\n",
      "642                                           R version           0\n",
      "73                                                Test1           0\n",
      "74                                                Test1           0\n",
      "75                                   are icons missing?           0\n",
      "76                                                Test1           0\n",
      "77                                                Test1           0\n",
      "78                                   are icons missing?           0\n",
      "79                                                Test1           0\n",
      "80                                   are icons missing?           0\n",
      "81                                   are icons missing?           0\n",
      "643                                          hi allison           0\n",
      "644                                          hi allison           0\n",
      "645                                          hi allison           0\n",
      "646                                          hi allison           0\n",
      "647                                    hi allison again           0\n",
      "1386                            testing version bolding           0\n",
      "1387                            testing version bolding           0\n",
      "1388                            testing version bolding           0\n",
      "1389                            testing version bolding           0\n",
      "648                                    hi allison again           0\n",
      "1390                            testing version bolding           0\n",
      "1391                            testing version bolding           0\n",
      "1392                            testing version bolding           0\n",
      "1393                            testing version bolding           0\n",
      "1394                            testing version bolding           0\n",
      "1921            testing version bolding with new script           0\n",
      "1922            testing version bolding with new script           0\n",
      "649                                           as.raster           0\n",
      "725   whoops, doing this logged in under my own name...           0\n",
      "726   whoops, doing this logged in under my own name...           0\n",
      "727   whoops, doing this logged in under my own name...           0\n",
      "728   whoops, doing this logged in under my own name...           0\n",
      "729   whoops, doing this logged in under my own name...           0\n",
      "730   whoops, doing this logged in under my own name...           0\n",
      "731   whoops, doing this logged in under my own name...           0\n",
      "732   whoops, doing this logged in under my own name...           0\n",
      "733   whoops, doing this logged in under my own name...           0\n",
      "734   whoops, doing this logged in under my own name...           0\n",
      "735   whoops, doing this logged in under my own name...           0\n",
      "736   whoops, doing this logged in under my own name...           0\n",
      "737   whoops, doing this logged in under my own name...           0\n",
      "738   whoops, doing this logged in under my own name...           0\n",
      "739   whoops, doing this logged in under my own name...           0\n",
      "740   whoops, doing this logged in under my own name...           0\n"
     ]
    }
   ],
   "source": [
    "print(kernel_versions[['Title','TotalVotes']][0:50]) #,kernel_versions['TotalVotes'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f23130",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = pd.read_csv(\"archive/Kernels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c08e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AuthorUserId</th>\n",
       "      <th>CurrentKernelVersionId</th>\n",
       "      <th>ForkParentKernelVersionId</th>\n",
       "      <th>ForumTopicId</th>\n",
       "      <th>FirstKernelVersionId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>EvaluationDate</th>\n",
       "      <th>MadePublicDate</th>\n",
       "      <th>IsProjectLanguageTemplate</th>\n",
       "      <th>CurrentUrlSlug</th>\n",
       "      <th>Medal</th>\n",
       "      <th>MedalAwardDate</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>TotalComments</th>\n",
       "      <th>TotalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2505</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03/25/2015 18:25:32</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>03/25/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>hello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3716</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26670.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>03/25/2015 18:31:07</td>\n",
       "      <td>04/16/2015</td>\n",
       "      <td>03/25/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>rf-proximity</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>8649</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3716</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>03/25/2015 21:57:36</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>03/25/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>r-version</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>28963</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>03/25/2015 22:01:04</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>03/25/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>test1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3716</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>03/25/2015 22:19:00</td>\n",
       "      <td>03/23/2018</td>\n",
       "      <td>03/25/2015</td>\n",
       "      <td>False</td>\n",
       "      <td>are-icons-missing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607055</th>\n",
       "      <td>22921815</td>\n",
       "      <td>9044464</td>\n",
       "      <td>82786126.0</td>\n",
       "      <td>81766681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82785623.0</td>\n",
       "      <td>12/20/2021 02:18:20</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>icc-semana-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607056</th>\n",
       "      <td>22921858</td>\n",
       "      <td>9202544</td>\n",
       "      <td>82786588.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82785787.0</td>\n",
       "      <td>12/20/2021 02:21:18</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>shubinov-nlp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607057</th>\n",
       "      <td>22922025</td>\n",
       "      <td>715788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82729548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82786242.0</td>\n",
       "      <td>12/20/2021 02:29:06</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>optimisation-tmin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607058</th>\n",
       "      <td>22922210</td>\n",
       "      <td>459771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82786761.0</td>\n",
       "      <td>12/20/2021 02:38:52</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>automl-for-avazu-autox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607059</th>\n",
       "      <td>22922404</td>\n",
       "      <td>459771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82787320.0</td>\n",
       "      <td>12/20/2021 02:49:43</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>12/20/2021</td>\n",
       "      <td>False</td>\n",
       "      <td>automl-for-loan-autox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607060 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  AuthorUserId  CurrentKernelVersionId  \\\n",
       "0              1          2505                   205.0   \n",
       "1              2          3716                  1748.0   \n",
       "2              4          3716                    41.0   \n",
       "3              5         28963                    19.0   \n",
       "4              6          3716                    21.0   \n",
       "...          ...           ...                     ...   \n",
       "607055  22921815       9044464              82786126.0   \n",
       "607056  22921858       9202544              82786588.0   \n",
       "607057  22922025        715788                     NaN   \n",
       "607058  22922210        459771                     NaN   \n",
       "607059  22922404        459771                     NaN   \n",
       "\n",
       "        ForkParentKernelVersionId  ForumTopicId  FirstKernelVersionId  \\\n",
       "0                             NaN           NaN                   1.0   \n",
       "1                             NaN       26670.0                   2.0   \n",
       "2                             NaN           NaN                   9.0   \n",
       "3                             NaN           NaN                  13.0   \n",
       "4                             NaN           NaN                  15.0   \n",
       "...                           ...           ...                   ...   \n",
       "607055                 81766681.0           NaN            82785623.0   \n",
       "607056                        NaN           NaN            82785787.0   \n",
       "607057                 82729548.0           NaN            82786242.0   \n",
       "607058                        NaN           NaN            82786761.0   \n",
       "607059                        NaN           NaN            82787320.0   \n",
       "\n",
       "               CreationDate EvaluationDate MadePublicDate  \\\n",
       "0       03/25/2015 18:25:32     03/23/2018     03/25/2015   \n",
       "1       03/25/2015 18:31:07     04/16/2015     03/25/2015   \n",
       "2       03/25/2015 21:57:36     03/23/2018     03/25/2015   \n",
       "3       03/25/2015 22:01:04     03/23/2018     03/25/2015   \n",
       "4       03/25/2015 22:19:00     03/23/2018     03/25/2015   \n",
       "...                     ...            ...            ...   \n",
       "607055  12/20/2021 02:18:20     12/20/2021     12/20/2021   \n",
       "607056  12/20/2021 02:21:18     12/20/2021     12/20/2021   \n",
       "607057  12/20/2021 02:29:06     12/20/2021     12/20/2021   \n",
       "607058  12/20/2021 02:38:52     12/20/2021     12/20/2021   \n",
       "607059  12/20/2021 02:49:43     12/20/2021     12/20/2021   \n",
       "\n",
       "        IsProjectLanguageTemplate          CurrentUrlSlug  Medal  \\\n",
       "0                           False                   hello    NaN   \n",
       "1                           False            rf-proximity    3.0   \n",
       "2                           False               r-version    NaN   \n",
       "3                           False                   test1    NaN   \n",
       "4                           False       are-icons-missing    NaN   \n",
       "...                           ...                     ...    ...   \n",
       "607055                      False           icc-semana-09    NaN   \n",
       "607056                      False            shubinov-nlp    NaN   \n",
       "607057                      False       optimisation-tmin    NaN   \n",
       "607058                      False  automl-for-avazu-autox    NaN   \n",
       "607059                      False   automl-for-loan-autox    NaN   \n",
       "\n",
       "       MedalAwardDate  TotalViews  TotalComments  TotalVotes  \n",
       "0                 NaN         165              0           0  \n",
       "1          07/15/2016        8649              1          13  \n",
       "2                 NaN          95              0           0  \n",
       "3                 NaN         105              0           0  \n",
       "4                 NaN         109              0           0  \n",
       "...               ...         ...            ...         ...  \n",
       "607055            NaN           6              0           0  \n",
       "607056            NaN           5              0           0  \n",
       "607057            NaN           1              0           0  \n",
       "607058            NaN           8              0           0  \n",
       "607059            NaN           4              0           0  \n",
       "\n",
       "[607060 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7db85f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607060"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425b39ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       165\n",
      "1      8649\n",
      "2        95\n",
      "3       105\n",
      "4       109\n",
      "5       124\n",
      "6        78\n",
      "7        46\n",
      "8       299\n",
      "9        97\n",
      "10    10871\n",
      "11    32660\n",
      "12      253\n",
      "13    10878\n",
      "14      154\n",
      "15    57774\n",
      "16      339\n",
      "17      397\n",
      "18     2994\n",
      "19      325\n",
      "20      219\n",
      "21     1242\n",
      "22     1075\n",
      "23      294\n",
      "24     1522\n",
      "25      579\n",
      "26      180\n",
      "27       72\n",
      "28      268\n",
      "29     1301\n",
      "30      244\n",
      "31      322\n",
      "32      872\n",
      "33      164\n",
      "34       78\n",
      "35      146\n",
      "36      224\n",
      "37       74\n",
      "38       81\n",
      "39      165\n",
      "40      179\n",
      "41      182\n",
      "42      105\n",
      "43      215\n",
      "44      611\n",
      "45       55\n",
      "46       53\n",
      "47      222\n",
      "48      227\n",
      "49       99\n",
      "Name: TotalViews, dtype: int64 0       165\n",
      "1      8649\n",
      "2        95\n",
      "3       105\n",
      "4       109\n",
      "5       124\n",
      "6        78\n",
      "7        46\n",
      "8       299\n",
      "9        97\n",
      "10    10871\n",
      "11    32660\n",
      "12      253\n",
      "13    10878\n",
      "14      154\n",
      "15    57774\n",
      "16      339\n",
      "17      397\n",
      "18     2994\n",
      "19      325\n",
      "20      219\n",
      "21     1242\n",
      "22     1075\n",
      "23      294\n",
      "24     1522\n",
      "25      579\n",
      "26      180\n",
      "27       72\n",
      "28      268\n",
      "29     1301\n",
      "30      244\n",
      "31      322\n",
      "32      872\n",
      "33      164\n",
      "34       78\n",
      "35      146\n",
      "36      224\n",
      "37       74\n",
      "38       81\n",
      "39      165\n",
      "40      179\n",
      "41      182\n",
      "42      105\n",
      "43      215\n",
      "44      611\n",
      "45       55\n",
      "46       53\n",
      "47      222\n",
      "48      227\n",
      "49       99\n",
      "Name: TotalViews, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(kernels['TotalViews'][0:50], kernels['TotalViews'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca75912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607060"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3387da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a list of popular kernal titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba1ac249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are only going to take those titles which have more than a certain number of votes, so that we dont up with garbage titles\n",
    "# kaggle kernel title can be garbage values as well, especially the ones with less votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d9c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge kernels and versions to retreive kernel title and total votes for kernel\n",
    "kernels_trc = kernels[['Id', 'TotalVotes' ,'TotalViews']]\n",
    "kernel_version_trc = kernel_versions[['Id' , 'Title']]\n",
    "kernel_titles_votes = kernels_trc.merge(kernel_version_trc)\n",
    "\n",
    "\n",
    "\n",
    "# kernels_trc = kernels[['CurrentKernelVersionId', 'TotalVotes']].rename(columns={'CurrentKernelVersionId' : 'Id'})\n",
    "# kernel_version_trc = kernel_versions[['Id', 'Title']]\n",
    "# kernels_titles_votes = kernels_trc.merge(kernel_version_trc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3966150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TotalVotes</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>8649</td>\n",
       "      <td>RF Proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>R version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>R version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>R version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129564</th>\n",
       "      <td>22913643</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Exercise: Data Leakage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129565</th>\n",
       "      <td>22914187</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Competition: TalkingData AdTracking FraudDetec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129566</th>\n",
       "      <td>22914784</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Advanced Fires Analysis with Plotly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129567</th>\n",
       "      <td>22915501</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>KyNet- quickdraw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129568</th>\n",
       "      <td>22920581</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>kernel2cc2b314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129569 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  TotalVotes  TotalViews  \\\n",
       "0              1           0         165   \n",
       "1              2          13        8649   \n",
       "2              9           0          78   \n",
       "3             11           0          46   \n",
       "4             12           0         299   \n",
       "...          ...         ...         ...   \n",
       "129564  22913643           0          17   \n",
       "129565  22914187           0          20   \n",
       "129566  22914784           0          30   \n",
       "129567  22915501           0          18   \n",
       "129568  22920581           0           1   \n",
       "\n",
       "                                                    Title  \n",
       "0                                                   hello  \n",
       "1                                            RF Proximity  \n",
       "2                                               R version  \n",
       "3                                               R version  \n",
       "4                                               R version  \n",
       "...                                                   ...  \n",
       "129564                             Exercise: Data Leakage  \n",
       "129565  Competition: TalkingData AdTracking FraudDetec...  \n",
       "129566                Advanced Fires Analysis with Plotly  \n",
       "129567                                   KyNet- quickdraw  \n",
       "129568                                     kernel2cc2b314  \n",
       "\n",
       "[129569 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_titles_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43ad11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking for null values and dropping those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bcb0e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id            0\n",
       "TotalVotes    0\n",
       "TotalViews    0\n",
       "Title         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_titles_votes.isnull().sum()\n",
    "# kernel_titles_votes['Title'].isnull().sum()\n",
    "# kernel_titles_votes['Title'].isnull().sum()\n",
    "# kernel_titles_votes['Title'].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af17b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=kernel_titles_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a402f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c74e283f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id            0\n",
       "TotalVotes    0\n",
       "TotalViews    0\n",
       "Title         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d546260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129565"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1276041",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to get rid of titles that are gibberish, we will have to place a filter\n",
    "### and we will decide this with the number of votes and number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d50d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_title_votes = df.sort_values('TotalVotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3d2e12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129565"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kernel_title_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285c0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_title_views = df.sort_values('TotalViews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08c1af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular_kernel_titles = kernels_titles_votes[kernels_titles_votes['TotalVotes'] > 0]['Title'].unique().tolist()\n",
    "kernel_title_views = kernel_title_views[kernel_title_views['TotalViews']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53db6211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129089"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kernel_title_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2857d84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TotalVotes</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72038</th>\n",
       "      <td>238701</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>Exploratory_Descriptive_LendingClub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72037</th>\n",
       "      <td>238699</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>SantanderScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72036</th>\n",
       "      <td>238697</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>Exploratory_Descriptive_LendingClub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72035</th>\n",
       "      <td>238696</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>MyFirstScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88549</th>\n",
       "      <td>449069</td>\n",
       "      <td>4800</td>\n",
       "      <td>396418</td>\n",
       "      <td>ipl_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86825</th>\n",
       "      <td>400732</td>\n",
       "      <td>5315</td>\n",
       "      <td>1956433</td>\n",
       "      <td>Titanic: Survived or Not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57486</th>\n",
       "      <td>182517</td>\n",
       "      <td>5453</td>\n",
       "      <td>623609</td>\n",
       "      <td>HdSanary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86245</th>\n",
       "      <td>382896</td>\n",
       "      <td>5642</td>\n",
       "      <td>502778</td>\n",
       "      <td>A Journey through Titanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83728</th>\n",
       "      <td>314923</td>\n",
       "      <td>6266</td>\n",
       "      <td>497761</td>\n",
       "      <td>Direct Copy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129565 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  TotalVotes  TotalViews                                Title\n",
       "0           1           0         165                                hello\n",
       "72038  238701           0          76  Exploratory_Descriptive_LendingClub\n",
       "72037  238699           0         133                      SantanderScript\n",
       "72036  238697           0         107  Exploratory_Descriptive_LendingClub\n",
       "72035  238696           0         236                        MyFirstScript\n",
       "...       ...         ...         ...                                  ...\n",
       "88549  449069        4800      396418                             ipl_play\n",
       "86825  400732        5315     1956433            Titanic: Survived or Not?\n",
       "57486  182517        5453      623609                             HdSanary\n",
       "86245  382896        5642      502778            A Journey through Titanic\n",
       "83728  314923        6266      497761                          Direct Copy\n",
       "\n",
       "[129565 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_title_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca971dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TotalVotes</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127582</th>\n",
       "      <td>20926648</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Forest Type Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127508</th>\n",
       "      <td>20862457</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Character Recognition CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128960</th>\n",
       "      <td>22235801</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I. Road to Visualization Expert - App Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127025</th>\n",
       "      <td>20361817</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Simple CNN code to be in the top 30% (99.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127827</th>\n",
       "      <td>21151238</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pet_Adoption_Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90825</th>\n",
       "      <td>582111</td>\n",
       "      <td>1493</td>\n",
       "      <td>613861</td>\n",
       "      <td>serialhomicideexploration.R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57486</th>\n",
       "      <td>182517</td>\n",
       "      <td>5453</td>\n",
       "      <td>623609</td>\n",
       "      <td>HdSanary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86845</th>\n",
       "      <td>401078</td>\n",
       "      <td>2656</td>\n",
       "      <td>1185253</td>\n",
       "      <td>Home sales data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86838</th>\n",
       "      <td>400931</td>\n",
       "      <td>2912</td>\n",
       "      <td>1315836</td>\n",
       "      <td>First_try ashyamal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86825</th>\n",
       "      <td>400732</td>\n",
       "      <td>5315</td>\n",
       "      <td>1956433</td>\n",
       "      <td>Titanic: Survived or Not?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129089 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  TotalVotes  TotalViews  \\\n",
       "127582  20926648           1           2   \n",
       "127508  20862457           0           2   \n",
       "128960  22235801           0           2   \n",
       "127025  20361817           0           2   \n",
       "127827  21151238           0           2   \n",
       "...          ...         ...         ...   \n",
       "90825     582111        1493      613861   \n",
       "57486     182517        5453      623609   \n",
       "86845     401078        2656     1185253   \n",
       "86838     400931        2912     1315836   \n",
       "86825     400732        5315     1956433   \n",
       "\n",
       "                                              Title  \n",
       "127582                   Forest Type Classification  \n",
       "127508                    Character Recognition CNN  \n",
       "128960  I. Road to Visualization Expert - App Store  \n",
       "127025  Simple CNN code to be in the top 30% (99.2)  \n",
       "127827                      Pet_Adoption_Prediction  \n",
       "...                                             ...  \n",
       "90825                   serialhomicideexploration.R  \n",
       "57486                                      HdSanary  \n",
       "86845                               Home sales data  \n",
       "86838                            First_try ashyamal  \n",
       "86825                     Titanic: Survived or Not?  \n",
       "\n",
       "[129089 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_title_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abb84312",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_titles = kernel_title_views[kernel_title_views['TotalVotes']> 0]['Title'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07b3687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Forest Type Classification',\n",
       " 'Great Guide of Starters : LightGBM',\n",
       " 'ENAS4',\n",
       " 'titanic_EDA_R',\n",
       " 'Exercise: Machine Learning Competitions',\n",
       " 'ml-practice-ex2',\n",
       " 'Different embeddings with Attention! [Fork]',\n",
       " 'Modular 2D-Unet + visu',\n",
       " 'kernel32ed546728',\n",
       " 'Data Augmentation: Packages Overview',\n",
       " 'kernel6cce1ef667',\n",
       " 'style_baseline',\n",
       " 'kernelfea9e15a45',\n",
       " 'Poverty Prediction- From Preprocessing to Stacking',\n",
       " 'IEEE-Fraud-Detection-EDA_v1',\n",
       " 'Deterministic neural networks using PyTorch',\n",
       " 'fast.ai v3 lesson 1',\n",
       " '🎶 Fly me to the Moon 🎶',\n",
       " 'Exploring Motivations for Kiva Loans',\n",
       " 'kernel54bc4e8555',\n",
       " 'All State Claim Severity - Neural Net',\n",
       " 'kernele962a73491',\n",
       " 'Seattle Crisis Data Set - Dashboard',\n",
       " \"Sangman's Frozen Pollack Pancake\",\n",
       " 'Evaluating Magnetic Shield Tensors',\n",
       " 'Bike Sharing(Feature Engineering, Random Forest )',\n",
       " 'kernel32e4055fa0',\n",
       " 'T2_Adib Yusril Wafi_1606837991',\n",
       " 'Digit recognition using NN',\n",
       " 'Starter: [Dataset no longer available] 3a9a4154-a',\n",
       " 'AnimalShelterDataSet-DataScienceTermProject',\n",
       " 'Keras ResNet-50',\n",
       " 'First neural net model',\n",
       " '[3rd ML Month] 25th solution',\n",
       " 'House Prices Prediction',\n",
       " 'IEEE Fraud Baseline',\n",
       " 'Best Kannada MNIST SelfCnn test',\n",
       " 'Contagious Diseases: Maps and Data Analysis',\n",
       " 'First attempt',\n",
       " 'Digit Recognizer using Neural Networks',\n",
       " 'Starter: [Dataset no longer available] 5f44d8d0-4',\n",
       " 'kernel39ab17c053',\n",
       " 'DenseNet (tf-keras) on CIFAR-10',\n",
       " 'Starter: lgbmaaa c6d72b8c-f',\n",
       " 'KaKR 3rd Keras/Xception',\n",
       " 'Movie Similarity Search using Doc2Vec',\n",
       " 'Beginner Forest Classification Kernel_Aninda',\n",
       " 'Suicide report, Data Visualization',\n",
       " 'Starter: dadosia aed8c11d-e',\n",
       " 'convert dataset to coco-format tools',\n",
       " 'Visualization + useful functions + small EDA',\n",
       " 'Food Preferences',\n",
       " 'Starter: [Dataset no longer available] 52af0c75-e',\n",
       " 'How people learn to code',\n",
       " 'Analysing the Rain Forest burnings',\n",
       " 'kernel42d8bc1723',\n",
       " 'Starter: [Dataset no longer available] e28ae635-4',\n",
       " 'Students Performance Visualization',\n",
       " 'Starter: [Dataset no longer available] 35a57ae8-0',\n",
       " 'kerneld771a11870',\n",
       " 'kernel5e403e7618',\n",
       " 'Iris Data Analsis',\n",
       " 'Digit Recognizer using MLP for beginners',\n",
       " 'kernelfe3761dc44',\n",
       " 'testser',\n",
       " 'Berlin Neighbourhoods',\n",
       " 'Starter: [Dataset no longer available] e18cd61f-1',\n",
       " 'Visualization for data_2019',\n",
       " 'India_ML_Hiring_AV_1',\n",
       " 'kernel05f7dc4db1',\n",
       " 'Notebook 55d5088d272c9404cd14',\n",
       " 'laba 3 social',\n",
       " 'Gapminder graph using R',\n",
       " 'Autoregressive Model: Natural Gas Consumption',\n",
       " 'Ultrasound Nerve Segmentation with fastai',\n",
       " 'Exercise: Random Forests',\n",
       " 'Starter: FiveThirtyEight Biopics 5b5e9c4e-0',\n",
       " 'FAT19 fastai implements with MixUp, MultiPrepro',\n",
       " 'PDSSC - Lab session - anomaly detection',\n",
       " 'IG Public Data',\n",
       " 'Exercise: Partial Plots 85a5f0',\n",
       " 'kernel366c2d955b',\n",
       " 'Exercise: Joining Data',\n",
       " 'kerneld8f939895e',\n",
       " 'Ciphertext Challenge III v2',\n",
       " 'BigQuery Machine Learning Exercise',\n",
       " 'Titanic',\n",
       " 'SetNet Trainer',\n",
       " 'simple_Convolut_NN_for_beginner',\n",
       " 'amazon_sentimental_naive_bayes-2',\n",
       " '3D Visualization of Molecules with Plotly',\n",
       " 'GradBM11',\n",
       " 'Lyft: EDA, Animations, generating CSVs',\n",
       " 'kernelc7d0eb29aa',\n",
       " 'Understanding_Cloudsf_rom_Satellite_Images',\n",
       " 'San Francisco Crime',\n",
       " 'DEEPLABV3-RESNET101 for Severstal SDD',\n",
       " 'kernelbf48105178',\n",
       " 'schnet',\n",
       " 'kernel11c35f143a',\n",
       " 'Exercise: Creating, Reading and Writing',\n",
       " 'House Price - Prediction',\n",
       " 'Fraud Detection - IEEE',\n",
       " 'kernel61289a7423',\n",
       " 'Visualizacion con python',\n",
       " 'Notebookfe3637daaa',\n",
       " 'Starter: [Dataset no longer available] 0c1030df-1',\n",
       " 'Predict winPlacePerc of PUPG',\n",
       " 'Exercise: Group By, Having & Count',\n",
       " 'Starter: Simple Stock Data set b4433827-a',\n",
       " 'House Prices: Deep Learning by Keras',\n",
       " 'GRE Dataset Analysis',\n",
       " 'AICamp Decision Tree Exercise 2',\n",
       " 'Exercise: Bar Charts and Heatmaps',\n",
       " 'Complete Titanic tutorial with ML, NN & Ensembling',\n",
       " 'Simple Linear Regression using Sklearn',\n",
       " 'Linear regression',\n",
       " 'Xception baseline for Severstal transfer learning',\n",
       " 'rl-test',\n",
       " 'Iceberg Challenge Convolutional Net 1',\n",
       " 'Trabalho Software II',\n",
       " 'Topic Analysis of IMDB Reviews Chaza',\n",
       " 'ML Tutorial using Breast Cancer Dataset',\n",
       " 'aps360  - Airbnb Seattle Data Cleaning',\n",
       " 'Transfer learning ResNet50 for Digit Recognizer',\n",
       " 'kernel905a723b08',\n",
       " 'Text-classification-example',\n",
       " 'kaggle meta data simple analysis - dd16',\n",
       " 'credit_card',\n",
       " 'NLP Week5-Arch 362 Fall19',\n",
       " '🏎️ The Race to Predict Molecular Properties',\n",
       " 'MNIST Digit detection',\n",
       " 'calculas',\n",
       " 'House Price Prediction',\n",
       " 'house sales analysis',\n",
       " 'RSNA EDA',\n",
       " 'kernel54e62774bb',\n",
       " 'fighter',\n",
       " 'Starter: [Dataset no longer available] 21d53a39-0',\n",
       " 'Boston Crime Analysis',\n",
       " 'Exercise: TensorFlow Programming',\n",
       " 'CarClassification v1.0',\n",
       " 'US Twitter Airline Sentiment',\n",
       " 'Proyecto Inteligencia Artificial',\n",
       " 'Wordl Cup (My First Example 01 )',\n",
       " 'How effectively business is driving conversions?',\n",
       " 'split',\n",
       " 'chaos',\n",
       " 'Using GTP-2 Finetuned',\n",
       " 'helsings solution',\n",
       " 'IBM HR Flight Risk',\n",
       " 'Severstal: fastai UNet Baseline',\n",
       " 'Exercise: Syntax, Variables, and Numbers',\n",
       " 'kernel6691c9bf41',\n",
       " 'Suicide study for Brazil',\n",
       " 'Predicting App Ratings and EDA',\n",
       " 'fast.ai lesson 3 camvid',\n",
       " 'New inferance with classifier',\n",
       " 'Starter: Cardiovascular Disease dataset 3da6b6d2-3',\n",
       " 'Collab comp twelfth try',\n",
       " 'Lab6-MorganDally-1313361',\n",
       " 'DMMM CA1',\n",
       " 'MAS Keras DataFrame',\n",
       " 'CONV_NET_MNIST',\n",
       " 'Titanic - Oma',\n",
       " 'PMR3508-2019-56 (knn-adult)',\n",
       " 'gradient_in_a_box',\n",
       " 'IG eda and models',\n",
       " 'Movie Reviews EDA (DNN)',\n",
       " 'The Secret Charts Library',\n",
       " 'Movie Recommender Systems',\n",
       " 'shopee-part-2',\n",
       " 'first try',\n",
       " 'Starter: [Dataset no longer available] b33b6ed7-c',\n",
       " 'kernel37ac5f2b18',\n",
       " 'Tactic 03. Hyperparameter optimization. LightGBM',\n",
       " 'Probability of Default - Bank Loan Data',\n",
       " 'Team Vengers',\n",
       " 'Data-Exploration-and-Modeling-for-Titanic',\n",
       " 'Starter: [Dataset no longer available] 4b11fd2d-d',\n",
       " 'Context-Aware Recommender',\n",
       " 'Starter: Tic-Tac-Toe Endgame Dataset 7334f0bc-b',\n",
       " 'YouthAI-7.27-word2vec',\n",
       " 'Squad Visualization (XY Coordinate)',\n",
       " 'NYC-Taxi-trip-duration',\n",
       " 'Housing price',\n",
       " 'Dataset preparation for classification task',\n",
       " 'Sberbank-DOTA2',\n",
       " 'titanic-kj',\n",
       " 'lag_Data_Analysis_Position_Analysis',\n",
       " 'Data exploration and visualization',\n",
       " '2018 Kaggle Survey - Starter Kit!!',\n",
       " 'Query for US Census for 2000 and 2010',\n",
       " \"First R Project - Iris' Flowers Classification\",\n",
       " 'Unsupervised Jigsaw Puzzle Solving on MNIST',\n",
       " 'LogsticRegWeatherAUS',\n",
       " 'kernelfb8b0e3419',\n",
       " 'Knee/Elbow Point Detection',\n",
       " 'midtermExam_ข้อ4_Agriculture_Crop_India',\n",
       " 'On_going',\n",
       " 'Steel_Masking',\n",
       " 'Understanding Clouds Keras Unet',\n",
       " 'rsna-intracranial-hemorrhage-detection',\n",
       " 'EDA and a Neural Network',\n",
       " 'Test Bert',\n",
       " 'Learning ML and Python with Titanic Disaster',\n",
       " 'Learning Sign Language Digits with CNN (DL)',\n",
       " 'VSB Power LSTM understanding',\n",
       " 'Basic Neural Network using Tensorflow',\n",
       " 'XG_Boosting_Animal_Disease_Predictor',\n",
       " 'Titanic-Solution',\n",
       " 'San Francisco Open Data',\n",
       " 'Predicting Molecular Properties',\n",
       " 'CS 100 Data Science 2',\n",
       " 'kernele9bd22856d',\n",
       " 'Analysis of crimes in Boston',\n",
       " 'Starter: [Dataset no longer available] 674b089f-5',\n",
       " 'Optimizing lightGBM hyperparameters',\n",
       " '0.8518+ What proper weights give? IEEE-Int. Blend',\n",
       " 'Aerial Cactus Identification',\n",
       " 'kernela74f49afa3',\n",
       " 'all shit',\n",
       " 'Exercise: Lists',\n",
       " 'Tactic 05. Class weight',\n",
       " 'Using Tensorflow 2.0 w/ Bert on NQ',\n",
       " 'Insightful EDA + modeling LGBM and XGB on GPU',\n",
       " 'classify country of addr2 --addr2 usage',\n",
       " 'kerneldde92faa9e',\n",
       " 'UNet v1 - no data augmentation no regularization',\n",
       " 'with_val4',\n",
       " 'Mushroom Data with CLASSIFIERS',\n",
       " 'IEEE Fraud Detection (LGBM Single Model)',\n",
       " 'Carleton AI - Intro to Data Science Workshop #2',\n",
       " 'submit mask_rcnn',\n",
       " 'quora2-tnn-2',\n",
       " 'Olympics Games!',\n",
       " 'Trabalho desligamentos',\n",
       " 'From prototyping to submission (fastai)',\n",
       " 'Vehicle Angle Prediction: Understanding / EDA',\n",
       " 'Average Masks',\n",
       " 'Linear Regression for bagrut averages in Israel',\n",
       " 'Bank Loan Modeling ile ML',\n",
       " 'ML Workshop',\n",
       " 'Self Driving Car - Steering Angle Predictions',\n",
       " 'BinanceAPI',\n",
       " 'Movie Review - Data Preprocessing Tutorial',\n",
       " 'Titanic solution',\n",
       " 'Steel detection',\n",
       " 'Multilayer perceptron using tensorflow',\n",
       " 'Keras Blueprint',\n",
       " 'DETAILED Project Walkthough of PetFinder.my',\n",
       " 'kernel28381adf39',\n",
       " 'ExercicioAvaliacaoPoliticasPublicas 7eed09',\n",
       " 'CS 100 Data Science',\n",
       " 'Starter: [Dataset no longer available] 8d1a0f1c-c',\n",
       " 'titanic begining',\n",
       " 'mlbre',\n",
       " 'Playing with thresholds',\n",
       " 'feature engineering and Regression',\n",
       " 'Single RNN with 5 folds',\n",
       " 'Notebookdd21610efc',\n",
       " 'Submission2 - Ranran',\n",
       " 'homework2_LGBM',\n",
       " 'DR Titanic on Kaggle 9-13-2016',\n",
       " 'Pneumonia Prediction from Chest X-ray Images',\n",
       " 'kernel-APTOS-model_testing',\n",
       " 'Starter: [Dataset no longer available] b3074691-9',\n",
       " 'severstal mlcomp+catalyst infer 0.90672',\n",
       " 'Whales. A Simple Guide!',\n",
       " 'Signus-Detection',\n",
       " 'Extensive EDA and Modeling XGB and Hyperopt',\n",
       " 'fast.ai Titanic',\n",
       " 'kernel64fb1c2f57',\n",
       " 'kernel13e1a32036',\n",
       " 'Titanic kaggle practice',\n",
       " 'Baseline in PyTorch',\n",
       " 'Synthetic Financial Datasets For Fraud Detection',\n",
       " 'Titanic Survive Prediction(Radom Forest)',\n",
       " 'Exploratory Analysis and Model Building',\n",
       " 'KannadaMNIST',\n",
       " 'Titanic Survival Prediction ()',\n",
       " 'Music Classification using CNN Model',\n",
       " 'Titatninc: My First Solution of ML',\n",
       " 'Singapore Aibnb Analysis',\n",
       " 'Forecast: Simple, Exponential, ARIMA',\n",
       " 'NLPHW',\n",
       " 'Statistical Analysis for Elo',\n",
       " 'AirbnbData',\n",
       " 'house_price_draft1',\n",
       " 'Categorical Feature Encoding Challenge (EDA&Model)',\n",
       " 'foot_stats',\n",
       " 'DS Bowl 2019: Simple LGBM using aggregated data',\n",
       " 'Exercise: Introduction',\n",
       " 'Breast Cancer Wisconsin (Diagnostic) Data Set',\n",
       " 'Prudential Life Assessment - Fastai',\n",
       " 'Recommending news articles based on read articles',\n",
       " 'Starter: Median Age of the Population 6c94061d-3',\n",
       " 'Riga flights small review',\n",
       " 'My first Titanic Survival Pred',\n",
       " 'PMR3508-2019-43 - Using KNN predicator on the Adul',\n",
       " 'Starter Notebook',\n",
       " 'kernel3a079b2012',\n",
       " 'kernel4a76752644',\n",
       " 'Box Office Linear Regression',\n",
       " 'Facial Keypoints Detection',\n",
       " 'Advanced EDA on NY Airbnb',\n",
       " 'CNN - LSTM Vietnamese Sentiment',\n",
       " 'Salt Segmentation',\n",
       " 'minist_cnn',\n",
       " 'Stock Behavior From Business News',\n",
       " 'example.py',\n",
       " 'PetFinder Simple LGBM',\n",
       " 'chapter5',\n",
       " 'Classifying wines by the continent',\n",
       " 'Exploratory/Classifiers/Interpretation',\n",
       " 'kernel6c2a8c11af',\n",
       " 'Starter: [Dataset no longer available] 4cd6a916-4',\n",
       " 'NYC Inmates in Custody - Kaggle class',\n",
       " 'kernel5b1230f141',\n",
       " 'CNN filters on CIFAR10',\n",
       " 'fast.ai ootb (cutout+efficientnet)',\n",
       " 'EDA & Feat Engineering - Encode & Conquer',\n",
       " 'Exercise: Feature Selection',\n",
       " 'LGBM-Baseline',\n",
       " '[RE]APTOS2019DataPreprocessing_efficientnet_exdata',\n",
       " 'Students performance analysis',\n",
       " 'Blue book for bulldozers using Random Forest',\n",
       " 'Liver Patients Analysis and Prediction',\n",
       " 'kernel063584ac38',\n",
       " 'core-fa19-applications',\n",
       " 'LA Parking Violation Explorer and Recommendations',\n",
       " 'Starter: [Dataset no longer available] 56670048-5',\n",
       " '2. Encourage Diversity, Reduce Bias - CoLA',\n",
       " 'MNIST Classification',\n",
       " 'Seedlings',\n",
       " 'Deep autoencoder',\n",
       " 'Home Credit Default Risk Model Building',\n",
       " 'Starter: Health Insurance Coverage in ff2196b1-c',\n",
       " 'kernel41a778107d',\n",
       " 'Elaboracao Modelo - Aula Python - ML II',\n",
       " 'Taxi_price_prediction',\n",
       " 'kernelf1d3567b90',\n",
       " 'pytorch',\n",
       " 'Predicting Fraud in Financial Payment Services',\n",
       " 'Grab Traffic Mgmt',\n",
       " 'MO_lab1_2019',\n",
       " 'Iris data Classification and EDA',\n",
       " 'kickstarter_data_exploary',\n",
       " 'Pima_indians_diabetes_prediction-Keras',\n",
       " 'Device classification',\n",
       " 'A2 (demo). Analyzing cardiovascular data',\n",
       " 'Insights into kickstarter crowdfunding data',\n",
       " 'kernel1b448d261e',\n",
       " 'CNN Kernel For Video Capture',\n",
       " 'Skin Cancer MNIST',\n",
       " 'motor-gen-dcgan',\n",
       " 'kernel1e8914f0a6',\n",
       " 'XGBoost & Feature Selection DSBowl 🥣 🥣',\n",
       " '10-MA-AD-YI-SHC',\n",
       " 'kernal_cb(T)',\n",
       " 'kernel298e7c995f',\n",
       " 'Toxic Comment Visualization',\n",
       " 'death records',\n",
       " 'kernel2c8a6b2240',\n",
       " 'Different Linear Models',\n",
       " 'perfumerecommendations',\n",
       " 'FashionMNIST',\n",
       " 'HR Analytics practice',\n",
       " 'Best model and Result Analysis',\n",
       " 'Heart Disease Preprocessing & Prediction',\n",
       " 'Better NLP Summarisers Notebook',\n",
       " 'kernel0265e7b8fa',\n",
       " 'Oreilly_Chapter_2_Exercises',\n",
       " 'Titanic using Extratrees, 0.82775',\n",
       " 'Aptos blindness cb_6_1',\n",
       " 'kernel165d743c76',\n",
       " 'Cost of living',\n",
       " 'AI Project',\n",
       " 'Pet Adoption (EDA) + Preliminary Model',\n",
       " 'Starter: [Dataset no longer available] c5d70096-5',\n",
       " 'TruncatedSVD, t-SNE and Decision Tree Baseline',\n",
       " 'Hospitality in Era of Airbnb',\n",
       " 'Quality Prediction in Iron Ore',\n",
       " 'Basic ensemble model',\n",
       " 'Fast.ai, RF vs. Classic Titanic',\n",
       " 'svm-knn',\n",
       " 'News Category Classifier',\n",
       " 'Titanic Competition: Data Exploration #1',\n",
       " 'kernel_LR_KD',\n",
       " '20190919',\n",
       " 'Santander Customer Prediction',\n",
       " 'House Prices: from data cleaning to modeling',\n",
       " 'The Examination on Fatal Police Shootings in USA',\n",
       " 'houses_price_prediction',\n",
       " 'musclehub gym ab test',\n",
       " 'ASHRAE - Great Energy Predictor III',\n",
       " 'Keras Binary Cats & Dogs ResNet 98%',\n",
       " 'DS301_Lab5',\n",
       " 'Arcface_humpback_Customhead_FastAI',\n",
       " \"Starter: Birds' Songs Numeric Dataset 72982dec-1\",\n",
       " 'EEGLea',\n",
       " 'Candidates Popularity HeatMap by State',\n",
       " 'Electricity consumption in the largest NL cities',\n",
       " '10X PBMC 2,700 Dataset',\n",
       " 'Transfer Learning Tutorial',\n",
       " 'BikeBuyer Prediction',\n",
       " 'Exercise: Pipelines',\n",
       " 'learn2reg_tutorial',\n",
       " 'APTOS_DenseNet121_Unbalanced',\n",
       " 'Text Preprocessing, Load Embeddings and CNN',\n",
       " 'Titanic ML challenge',\n",
       " 'movielens_analysis',\n",
       " 'Automating Data Pipelines Day 2',\n",
       " 'Predicting Graduate Admission',\n",
       " 'kernel291f179b22',\n",
       " 'Suicide Data: An Exploration and Analysis',\n",
       " 'Costa Rica Problem',\n",
       " 'Exercise: Cross-Validation',\n",
       " 'Starter: NOAA Precipitation 15 Minute d62c0dd7-6',\n",
       " 'Titanic Model',\n",
       " 'Movie Review Competition Public Leaderboard',\n",
       " 'Yake +Brown Clustering Pipeline',\n",
       " 'Image shape distribution - previous and present',\n",
       " 'kernel3401d761ea',\n",
       " 'kernelb3c067ffc5',\n",
       " 'Spotify data analysis',\n",
       " 'Discussion upvotes: how long till the medal?',\n",
       " 'materiation_property',\n",
       " 'Notebookc14e1652ca',\n",
       " 'Learn Python',\n",
       " 'Pytorch ResNeXt 32x8d',\n",
       " 'Causal Impact Analysis on Android Market',\n",
       " 'Jigsaw Text classify',\n",
       " 'Exercise: Order By',\n",
       " 'XGBClassifier',\n",
       " 'Starter: [Dataset no longer available] f5b23f28-d',\n",
       " 'Getting Started with Titanic',\n",
       " 'Use multiple year data',\n",
       " 'kernelf69f757d7e',\n",
       " 'uCode Script 2',\n",
       " 'Deep Learning from Scratch Learning Note (Chinese)',\n",
       " 'KSMConsulting',\n",
       " 'Movie Revenue Prediction',\n",
       " 'Housing_Regression_Using_Keras',\n",
       " 'Captchas - Single characters',\n",
       " 'Titanic with simple Scikit-learn',\n",
       " 'Exercise: As & With',\n",
       " 'Load all tables for data exploration',\n",
       " 'It Takes a Village (and a Markov Model)',\n",
       " 'Just showing off a cool plot!',\n",
       " 'Script_aminos',\n",
       " 'CareerVillage Initial Analysis',\n",
       " 'Starter: deepScapulaSSM 3092944f-f',\n",
       " 'Risk assessment in social lending',\n",
       " 'kernel707679fcd7',\n",
       " 'kernele3b16db7eb',\n",
       " 'MainKernel',\n",
       " 'House: Simple Random Forest Regression',\n",
       " 'Wine data visualization',\n",
       " 'Multi-label segmentation using fastai',\n",
       " 'House Prices Data',\n",
       " 'pandas-concat-append',\n",
       " 'Feature Selection with Random Forest',\n",
       " 'Santander Genetic Feature Engineering',\n",
       " 'Bi-LSTM-GRU Dual Embedding New Test 4',\n",
       " 'crimes',\n",
       " 'simple recommender: pivot tfidf cossim',\n",
       " 'Recognising MNIST digits',\n",
       " 'DL HW2',\n",
       " 'controller',\n",
       " 'Starter: [Dataset no longer available] dce74447-5',\n",
       " 'Notebook ac86b49f288e04be31bb',\n",
       " 'jigsawv7',\n",
       " 'City of LA',\n",
       " 'MIDAS',\n",
       " 'Preprocessing Train and Validation',\n",
       " 'Club Mahindra Challenge',\n",
       " 'Confidence Interval Estimation via Bootstrapping',\n",
       " 'Advanced Fires Analysis with Plotly',\n",
       " 'AICamp Ensemble Bias vs Variance Exercise',\n",
       " 'Headline Generation - Reuters',\n",
       " 'ASHRAE Energy - Simple Average',\n",
       " 'kernel31ebce6bb6',\n",
       " 'CNN_KERAS_Accuracy(75%)',\n",
       " 'Primer_intento',\n",
       " 'Statistical_Learning_In_Python',\n",
       " 'IBM Capstone Project',\n",
       " 'Starter: Malaria Cell Images Dataset 8a93d9fa-a',\n",
       " 'Starter: [Dataset no longer available] 1b66bc8b-f',\n",
       " 'rossmann-data-engineering',\n",
       " 'GPT2-Large (774M) with Pytorch: Not that terrified',\n",
       " 'Data visualization',\n",
       " 'NMT Playground',\n",
       " 'Easiest-Kernel-For-EveryOne-In-Python',\n",
       " 'Deep Dive into EDA+Feature Engineering',\n",
       " 'data_prep',\n",
       " 'Starter: HR all models a70149d6-6',\n",
       " 'kernel604b0f6337',\n",
       " 'Fruits360 V14 Keras CNN',\n",
       " \"Poverty level prediction: Beginer's kernel\",\n",
       " 'Airline Price Optimization Micro-Challenge',\n",
       " 'Rape crimes India - EDA',\n",
       " 'PAD: WT 4-1',\n",
       " 'boston with xgboost',\n",
       " 'Sentiment Analysis using Bidirectional LSTM',\n",
       " 'Introduction to Generative Adversarial Networks',\n",
       " 'Exploration of 2015 Traffic Dataset',\n",
       " 'TrainAndTest',\n",
       " 'Trabalho-World-Marathon-Majors',\n",
       " 'kannada-minst-lgb',\n",
       " 'Starter: Parking Garage Data 77181bc0-8',\n",
       " 'IEEE-CIS Fraud Detection with XGBoost in R',\n",
       " 'my ibm data attrition',\n",
       " 'Starter: OECD Registered Unemployment 13dcb0b0-7',\n",
       " 'Supervised and Unsupervised Model',\n",
       " 'Predicting TED Talks Views with ML Models',\n",
       " 'Starter: People 25 Years and Over c0db8fcd-d',\n",
       " 'kernel4e16427c36',\n",
       " 'Titanic Daniel y  Ana',\n",
       " 'TestNotebook',\n",
       " 'Bayesian Nerual Networks with TensorFlow 2.0',\n",
       " 'LGBM - Demand Forecasting',\n",
       " 'BigQuery-Geotab Intersection Congestion',\n",
       " 'Red Pinedo Chang Velasquez',\n",
       " 'kernel35dcdd01f4',\n",
       " 'Exercise: Functions and Getting Help',\n",
       " 'Multi-Input Deep Learning Model Baseline',\n",
       " 'xgb_mg_all',\n",
       " 'Starter: [Dataset no longer available] 7fc8fa2f-6',\n",
       " 'LightGBM Starter BayesianOptimization',\n",
       " 'Steel mmdet',\n",
       " 'Steel Defect Detection EDA_t01',\n",
       " 'ASHRAE: interactive data visualization with plotly',\n",
       " 'House Pricing Using Neural Nets',\n",
       " 'CIFAR-100 Final',\n",
       " 'RSNA IH Detection - EDA & Baseline',\n",
       " '(Ver Scripts)Is_kaggle_kernel_or_script_runinng?',\n",
       " 'Starter: [Dataset no longer available] 00f49757-e',\n",
       " 'Starter: [Dataset no longer available] d82aea26-9',\n",
       " 'Compressing MNIST Images (to 784 bits)',\n",
       " 'Plotly Tutorial for Beginners',\n",
       " 'Histology-Baseline',\n",
       " 'kernel2929ea4dd6',\n",
       " 'kernel2a17a8e51e',\n",
       " 'Using R for EDA & modeling',\n",
       " 'Penalised Logistic Regression Model - Titanic',\n",
       " 'US airline sentiment LSTM',\n",
       " 'Kernel Group 2 11.46',\n",
       " 'Starter: [Dataset no longer available] 72f3b0ee-a',\n",
       " 'Xception_baseline',\n",
       " 'Fork of Freesound 0720 + curated mix fold12',\n",
       " 'EfficientNetB5, Keras, Added Preproc (APTOS 2019)',\n",
       " 'Exercise: Explore Your Data',\n",
       " 'Starter: training_data 3888564f-2',\n",
       " 'model prediction & submission',\n",
       " 'bert_with_fastai_tutorial',\n",
       " 'Notebooka90fa7956c',\n",
       " 'Cuisine Analysis',\n",
       " 'GCN on bonds and distances',\n",
       " 'kernel43c388654d',\n",
       " 'kernel3a557e133d',\n",
       " 'Audio Emotion | Part 4 - Apply to new audio data',\n",
       " 'kernel26b4e551bb',\n",
       " 'pytorchdensenet201',\n",
       " 'kernele2b4d269f3',\n",
       " 'Starter: mohanty-data 39cbc6e3-1',\n",
       " 'Stanford Dogs Keras VGG16 |',\n",
       " 'kernelb24f02dee3',\n",
       " 'Classification of field position decision tree',\n",
       " 'kernel788d16525b',\n",
       " 'Recommendation Systems - Different Models',\n",
       " 'Neural Network baseline aa49c2',\n",
       " 'ML-Avaliação_-_Q4',\n",
       " 'Keras_EfficientNet[0.954]',\n",
       " 'fastai',\n",
       " 'Plant Disease Detection using Keras N',\n",
       " 'NYC Open Data: Tree Colors Autumn',\n",
       " 'WWI16SEA_Flight_Analysis',\n",
       " 'Data_Science_301_V2',\n",
       " 'Starter: [Dataset no longer available] a322ae74-a',\n",
       " 'Policy Gradient',\n",
       " 'utils',\n",
       " 'kerneleefe9ff821',\n",
       " 'GStore: Part 1 (Data cleansing)',\n",
       " 'New Features',\n",
       " 'upura-kaggle-tutorial-05-tuning',\n",
       " 'Basic Digits Recognizer with Keras',\n",
       " 'Starter: [Dataset no longer available] b45a6072-c',\n",
       " 'First Look',\n",
       " 'tweet topic modeling',\n",
       " \"Lei's Model\",\n",
       " 'Simple RF Starter',\n",
       " 'Computer Vision with seedlings',\n",
       " 'Fork of Hello',\n",
       " 'my stacking method',\n",
       " 'Arcface_humpback_Customhead_FastAI_score919',\n",
       " 'Creating, Reading & Writing Data',\n",
       " 'Starter: ATP matches 1968 2018 cleaned 3e01410e-9',\n",
       " 'Jigsaw2',\n",
       " 'Convert from Training Images to Pytorch Dataset',\n",
       " 'CellularImages',\n",
       " 'GAN dogs starter 24-Jul -Custom Layers',\n",
       " 'quick_classification',\n",
       " 'DarthKernel',\n",
       " 'kernel759fd9023d',\n",
       " 'Dashboarding with Scheduled Notebooks',\n",
       " 'CNN With FAST AI',\n",
       " 'Severstal :: Preparing dataset for classification',\n",
       " 'kernel57b754e1c6',\n",
       " 'Extensive EDA and Modelling - Geotab Inertsection',\n",
       " 'MyMnist',\n",
       " 'Petfinder_Prediction_Notebook',\n",
       " 'Group 3 Final',\n",
       " 'kernel2e6cebb5be',\n",
       " 'SummariserCosineMethodClass',\n",
       " 'kernel8fcd557e24',\n",
       " 'kernel82240146e6',\n",
       " 'playground',\n",
       " 'Data Cleaning Challenge: Scale and Normalize Data',\n",
       " 'VSB Fault Detection - DWT denoising',\n",
       " 'hand_written_digit_recognition',\n",
       " 'Kannada MNIST - activation visualization',\n",
       " 'kernel房价预测小白',\n",
       " 'kernel089d065788',\n",
       " 'Starter: E-bird Brazilian Observations c91c74c4-e',\n",
       " 'Data Breaches Tableau Visualisation',\n",
       " '2nd place solution',\n",
       " 'EDA Chicago Sex Offenders',\n",
       " 'Starter: Heart Disease UCI c6493e15-8',\n",
       " 'Predicting Customer Churn',\n",
       " 'ensemble_lightGBM_CatBoost',\n",
       " 'Python Notebook',\n",
       " 'How to Remember Pandas Index Methods',\n",
       " 'Flatiron VG Model',\n",
       " 'Flower Recognition',\n",
       " 'Homework_2_Yuki_Wang_Wine',\n",
       " 'Wine Data',\n",
       " 'SVM on Telugu Handwritten Characters',\n",
       " 'Starter: [Dataset no longer available] 2db0e532-1',\n",
       " 'TF_NN',\n",
       " 'ExercicioAvaliacaoPoliticasPublicas',\n",
       " 'Digit Recognition',\n",
       " 'Extract Image features from pretrained NN_日本語ver',\n",
       " 'Starter: Parking Garage Data 9eba6994-2',\n",
       " 'Fraud detection using different algorithms',\n",
       " 'Pesquisadores2017',\n",
       " 'Temporal Analysis of the Denver Police Dataset',\n",
       " 'NBA Player Salary And Median Influence',\n",
       " 'My 1st try with Titanic',\n",
       " 'Convert Categorical to Numerical Data',\n",
       " 'NER Detection',\n",
       " 'Starter: Parking Garage Data 52b96e08-0',\n",
       " 'Learning Rates Study: Dogs vs. Cats',\n",
       " '2 Sigma News - Benchmark 0/1 (6 months)',\n",
       " 'Análise Exploratória - Suicídios',\n",
       " 'Titanic: Explore Features',\n",
       " 'Memory optimization and analysis of Wildfire data',\n",
       " 'Starter: Bitcoin Blockchain e9b1a94c-9',\n",
       " 'Starter: World Bank Health Nutrition 99379575-2',\n",
       " 'quora',\n",
       " 'LeNet-5 using keras',\n",
       " 'Starter: severstal 9ff82489-2',\n",
       " 'Clark Final Project',\n",
       " 'CSII Assignment C, Image Classifier',\n",
       " 'kernel3f015118af',\n",
       " 'Simple ensemble model',\n",
       " 'kernelca9c675253',\n",
       " 'Detailed EDA with visualizations',\n",
       " 'Exercise: Your First Machine Learning Model',\n",
       " 'Baseline model',\n",
       " 'NYC Taxi Fare Prediction',\n",
       " 'NYC - Data Science Project',\n",
       " 'Starter kernel for > 0.79',\n",
       " 'Cardusage_Kmeans',\n",
       " 'Whales competition',\n",
       " 'Visualize  FIFA19 soccer data with Seaborn',\n",
       " 'kernel5284202d83',\n",
       " 'Titanic_Logistic Regression',\n",
       " 'Digit Recognitions',\n",
       " '3D Interactive Car with Plotly',\n",
       " 'first_test',\n",
       " 'kernel7efe7ce8c8',\n",
       " 'San Francisco Crime Classification',\n",
       " 'kernel41a5e5794c',\n",
       " 'kernel50ffec1ec1',\n",
       " 'kernel9ed11caa41',\n",
       " 'Start Here: A Gentle Introduction',\n",
       " 'kernel62a7eb826f',\n",
       " 'DatingKernel',\n",
       " 'second day interactive dashboard',\n",
       " 'denoised autoencoder',\n",
       " 'World Happiness Report : EDA',\n",
       " 'AA_practice Fraud_detection',\n",
       " 'A Simple Tutorial on Exploratory Data Analysis',\n",
       " 'datafile (3)',\n",
       " 'Churn Modelling Data Visualization and Prediction',\n",
       " 'Starter: [Dataset no longer available] 5f7d761f-d',\n",
       " 'kernel1610835510',\n",
       " 'Starter: [Dataset no longer available] 307db770-c',\n",
       " 'Computer vision with seedlings',\n",
       " 'Tensorflow2.0 + DCGAN',\n",
       " 'Pytorch_Overview',\n",
       " 'DogBreedIdentByResent50',\n",
       " 'severstal-mlcomp-train',\n",
       " 'mxnet-gluon-baseline',\n",
       " 'Simple LGBM Solution',\n",
       " 'kernel32ba29eee5',\n",
       " 'Desmatamento Amazonia Legal',\n",
       " '2016B5A70471G',\n",
       " 'Exercise: Final Project',\n",
       " 'k-nearest neighbor',\n",
       " 'Eliminate features recursively + CV',\n",
       " 'Flower Recogition HackerEarth Ensemble',\n",
       " 'Warm Up: Machine Learning with a Heart',\n",
       " 'Intel_image[train_acc=88.56%, test_acc=86.43%]',\n",
       " 'kernel1bdc990a46',\n",
       " 'Setting up data generator and CNN in R',\n",
       " 'Exercise: Booleans and Conditionals Daily',\n",
       " 'Python Programming from A to Z',\n",
       " 'Starter: Median Personal, Family, and 8e118b7d-d',\n",
       " 'San Francisco Crime Resolution Predictor',\n",
       " 'kernel3bed9143b3',\n",
       " 'Manipulating Geospatial Data',\n",
       " 'Titanic : XGBoost Example in R',\n",
       " 'Keras for search ships in satellite Image',\n",
       " 'The Bidirectional LSTM',\n",
       " 'ggggggg',\n",
       " 'Lab 6 Sentiment DS',\n",
       " 'nih chest x ray age',\n",
       " 'Datos - TP1',\n",
       " 'Starter: Home, Homeowner Vacancy Rate 9b88d748-f',\n",
       " 'cyrilSantos_examtaxi',\n",
       " 'Exercise: Strings and Dictionaries',\n",
       " 'Analysis of Titanic',\n",
       " 'kekek',\n",
       " '051062 social network ads K-NEAREST\\tNEIGHBORS',\n",
       " 'Severstal: Steel Defect Detection - Seg Only',\n",
       " 'fastai-BERT-train-baseline',\n",
       " 'Suicide data exploration and analysis',\n",
       " 'Guia Taller Analisis de Datos con Python 3',\n",
       " 'summarizer',\n",
       " 'MNIST : from data visualization to submission',\n",
       " 'mytesta',\n",
       " 'Starter: [Dataset no longer available] d6ea66e0-4',\n",
       " 'demo-yelp-sentiment-analysis',\n",
       " 'ResNet34_ Mel_ver3_log Multi_HardAug',\n",
       " 'kernel5cebee9c6a',\n",
       " '4-Channel Resnet from Scratch [pytorch] [LB 0.16]',\n",
       " 'Starter: Poverty Universe, All Ages d46fd456-5',\n",
       " 'ENAS2',\n",
       " 'kernel36d8416a7d',\n",
       " 'Starter: Google-Landmarks Dataset 64982466-3',\n",
       " 'IEEE-CIS Fraud Detection',\n",
       " 'RFclass0',\n",
       " '1111sss',\n",
       " 'ExercicioSala-AvaliacaoPoliticasPublicas',\n",
       " 'Kodryan MMP MSU GACRP (my best)',\n",
       " 'Data Visualizations - Iris Dataset',\n",
       " 'MAS Image Segmentation',\n",
       " 'Facebook_Checkin',\n",
       " 'naive_bayers+bow kernel',\n",
       " 'Pandas Exercises',\n",
       " 'Hands on Machine Learning with Python',\n",
       " 'MINIST_DigitRecognition_CNN',\n",
       " 'uber_decision_tree',\n",
       " 'LightGBM with weighted averages & dropout [.787]',\n",
       " 'IEEE Fraud : New Features Export [0.94+ LB]',\n",
       " 'Starter: Parking Garage Data 0e44771e-b',\n",
       " 'Collab comp ninth try',\n",
       " 'rekaggle-favorita-timeseries-feature-engineering',\n",
       " 'Starter: Parking Garage Data edda6fee-1',\n",
       " 'kernel66c0f7919b',\n",
       " 'Keras around 0.9633*',\n",
       " 'Natural Language Processing (NLP) Project',\n",
       " 'Simple CNN for Kannada classification',\n",
       " 'script_fb_test',\n",
       " 'NLPHW2',\n",
       " 'Custumer Satisfaction Prediction (classification)',\n",
       " 'EHR_1',\n",
       " '70% Public sem Machine Learning',\n",
       " 'Sentiment140 modified',\n",
       " 'Avian Project AAP',\n",
       " 'UGATIT selfie2anime',\n",
       " 'Digit Recognizer - MNIST',\n",
       " 'Data Science best practices',\n",
       " 'IP4DS: Day 1 - Getting Started With Python',\n",
       " 'House Prices: Regression',\n",
       " 'PSPNet',\n",
       " 'Starter: [Dataset no longer available] 5c1f88e1-6',\n",
       " 'train1-kaggle',\n",
       " 'Extensive Data Exploration & Modelling (Python)',\n",
       " 'Starter: [Dataset no longer available] e2d271aa-8',\n",
       " 'Starter: World Bank Quarterly External 99d1f1c6-7',\n",
       " 'How good does your chocolate taste?',\n",
       " 'Keras CNN Whale Detection Beginner Level',\n",
       " 'HP:ART',\n",
       " 'Titanic Survival Prediction - Decision Tree',\n",
       " 'Very Simple NN in PyTorch with SparseTensor',\n",
       " 'Corvus - Part 2 - Using Keras Neural Networks',\n",
       " 'Exploratory',\n",
       " 'Titanic - 決定木(DecisionTreeClassifier)を用いた分析',\n",
       " 'FastAI (v3) lesson 2: horses by color breed',\n",
       " 'Predict_Future_Monthly_Sales_with_Prophet',\n",
       " 'kernel6678b9f628',\n",
       " 'first',\n",
       " 'To the TOP v3',\n",
       " '2019-10-04 Cactus Detection',\n",
       " 'Starter: [Dataset no longer available] fd5a51a5-9',\n",
       " 'Digit_recognizer_nn_2000Samples_pca',\n",
       " '1931133066 - Trabalho 20191021',\n",
       " 'Bag of words',\n",
       " 'Starter: Malaria Cell Images Dataset 556a5e9b-7',\n",
       " 'Notebook e5e51d4a3337e1e0306f',\n",
       " 'World Happiness Index',\n",
       " 'SalePrice prediction',\n",
       " 'TEMPLATE NOTEBOOK b8b4f1',\n",
       " 'Housing Prices',\n",
       " 'RM HW1',\n",
       " 'kernel45fed06501',\n",
       " '0.24 with xgboost in R',\n",
       " 'WL-Blackjack(clean)',\n",
       " 'exploring_and_some_baseline_models',\n",
       " 'Predict Future Sales',\n",
       " 'Russian Troll Tweets- What, Why, When',\n",
       " 'Final Submission',\n",
       " 'Compresserator',\n",
       " 'Springleaf competition : EDA (second attempt)',\n",
       " 'Merge datasets',\n",
       " 'Starter: [Dataset no longer available] 3cea7f1d-7',\n",
       " 'Zhas1ke_sf_crime',\n",
       " 'Titanic:My first submission',\n",
       " 'Kannada_v0.1',\n",
       " 'Python Exercise: Functions and Getting Help',\n",
       " 'BigQuery WorkFlow',\n",
       " 'Aibnb Challenge',\n",
       " '151 Pokemon GAN',\n",
       " 'DeepFake_Without_Moral_Issues_2/3_Bart+Homer_AE',\n",
       " 'Digit-recognizer',\n",
       " 'Starter: [Dataset no longer available] 2bbfab26-3',\n",
       " 'Machine learning digit-recognizer',\n",
       " 'Keras NN mixup',\n",
       " 'Notebook1c70cf9837',\n",
       " 'Digit Recognition From Scratch',\n",
       " 'MachineHack- Predict Food Prices',\n",
       " 'Two sigma competition',\n",
       " 'Santander starter EDA',\n",
       " 'Analysis of Flight Delay',\n",
       " 'Catboost',\n",
       " 'Predict_House_Prices',\n",
       " 'Data Visualization with Happiness Data',\n",
       " 'CAR NOISE data',\n",
       " 'Kannada MNIST competition',\n",
       " 'Youtube Video Trending Days in English Countries',\n",
       " 'Exercise: Working with External Libraries',\n",
       " 'kernel33027ba647',\n",
       " 'Starter: paris metro line 42bf2ced-f',\n",
       " 'keras_DRN_PSPnet',\n",
       " 'QSSCode',\n",
       " 'Advanced Uses of SHAP Values',\n",
       " 'kerneldfaa4e888b',\n",
       " 'Starter: WaPo/DEA MI Opioid Data 49a2522f-9',\n",
       " 'Turkey-Child',\n",
       " 'Dog vs Cat classification, CNN approximation',\n",
       " 'Taming the BERT - a baseline',\n",
       " 'Template: Aula 1 | Exercício 1',\n",
       " 'Scraping Sports Data with R',\n",
       " 'Forest Cover: Stacking Multiple Classifiers',\n",
       " 'SFO Crime - Multi Class Algorithms',\n",
       " 'Starter: Pesquisadores_2017 5e28b43b-5',\n",
       " 'CNN n-gram',\n",
       " 'Smile Parental Recognizing',\n",
       " 'MNIST: Simple CNN with Keras',\n",
       " 'Starter: Heart Disease UCI 4b1ad5ac-9',\n",
       " 'NY_airbnb',\n",
       " 'Blender of 0.901 solutions',\n",
       " 'library',\n",
       " \"DON'T OVERFIT?\",\n",
       " 'Sample_1',\n",
       " 'WoW Auction DB Lua Parser',\n",
       " 'Machine Learning Models Demonstration',\n",
       " 'PyTorch Data Loader Code',\n",
       " 'First submission: Group-7',\n",
       " 'Testing',\n",
       " 'Lithuania Temperature Change 1900-2013',\n",
       " 'My Notebook',\n",
       " 'lakshh',\n",
       " 'kernel719b07ed7f',\n",
       " 'Categorical_Feature_Engineering_XGB',\n",
       " 'Starter: [Dataset no longer available] ff5863a2-1',\n",
       " 'MiniVGGNet for Cifar10',\n",
       " 'How to Impute Missing Values',\n",
       " 'Report on Project Work 06 - Test Rib Masks',\n",
       " 'K-Means',\n",
       " 'How Models Work',\n",
       " 'Starter: [Dataset no longer available] a6d09409-4',\n",
       " 'kernel5f6932067d',\n",
       " 'Kagglers: The Gender Story:- A 2018 Survey',\n",
       " 'Is that a Dog or a Cat? (Acc. : ~90%)',\n",
       " 'lastTit',\n",
       " 'Starter: Gas Prices in Brazil 7f5e8670-f',\n",
       " 'test waves data',\n",
       " 'first_attempt',\n",
       " 'CookingPrediction',\n",
       " 'Starter: Parking Garage Data 04ed6bd1-7',\n",
       " 'World Happiness Report',\n",
       " 'Whose Turn(over) it is ????',\n",
       " 'A step by step guide to Image segmentation.',\n",
       " 'Starter: Parking Garage Data 1481e4fa-8',\n",
       " 'Titanic feature engineering',\n",
       " 'Are You Gonna Eat There? SF health violations',\n",
       " 'kernel39e4c332c1',\n",
       " 'AppStore application - Exploration',\n",
       " 'Fast lags calculation using numpy arrays',\n",
       " 'Test1',\n",
       " 'EDA analysis',\n",
       " 'kernel3de22037de',\n",
       " 'Group 9',\n",
       " 'Random Forest Script',\n",
       " 'severstal classification PyTorch',\n",
       " 'Youtube Trending Videos Interactive EDA',\n",
       " 'kerneldb46a732e0',\n",
       " 'kernel19333aa037',\n",
       " 'Santandar',\n",
       " 'kernel7932716392',\n",
       " '[Time Series - Garch, TS Regression]',\n",
       " 'Starter: [Dataset no longer available] 2a11eb9f-d',\n",
       " 'Toxic comment classification using BERT',\n",
       " 'RyzhStaralsya',\n",
       " 'Data Visualization for Beginners',\n",
       " '[3rd ML month] models ensemble inference',\n",
       " 'DeepDream as in Keras book',\n",
       " 'Time decay',\n",
       " 'Bike Sharing Prediction',\n",
       " 'Fork of real_estate',\n",
       " 'Starter: NOAA Severe Weather Data 7b5b4625-2',\n",
       " 'Digit_Recognizer_2',\n",
       " 'Data analysis',\n",
       " 'Land cover classification Keras DenseNet 169',\n",
       " 'Starter: [Dataset no longer available] 4279a7af-0',\n",
       " 'Starter: [Dataset no longer available] 9ed1c30a-5',\n",
       " 'Power Line Fault Detection Create Model',\n",
       " 'CO2 after GRETA',\n",
       " 'BIGGAN AaronLeong 64',\n",
       " 'Prime Sieves',\n",
       " 'kernel7ce9677931',\n",
       " 'Insincere questions EDA  understanding',\n",
       " 'Fork of Fork of Fork of Fork of Fork of For 94ff24',\n",
       " 'data_science_bowl_fast_compact_solution',\n",
       " 'Demo 10. Xception and Dense',\n",
       " 'Titanic with Random Forest',\n",
       " 'Anomaly Detection_Assign_DS',\n",
       " 'black_to_transparent rgba',\n",
       " 'NLPHW3',\n",
       " 'deconvnet',\n",
       " \"Titanic: A complete Beginner's guide\",\n",
       " 'Feature Generation using time series stats',\n",
       " 'Analysis of world crime',\n",
       " 'House pricing',\n",
       " 'EDA + Windowing Allowed per Rules',\n",
       " 'Data Visualization',\n",
       " 'Nick - Third Week Benchmark',\n",
       " 'NYC Cab XGB',\n",
       " 'Santander_Test1',\n",
       " '2017A7PS0096G',\n",
       " \"PUBG's kernel\",\n",
       " 'PatchGAN',\n",
       " 'Credit Card Fraud Detection Verisinin incelenmesi',\n",
       " 'sklearn_test',\n",
       " 'Bokeh visualization',\n",
       " 'Notebook a8e6365242e3e9e21bef',\n",
       " 'New in Kaggle? EDA step by step',\n",
       " 'Breast Cancer Diagnosis with LR',\n",
       " 'kernel_Digit Recognizer',\n",
       " 'Song Recom',\n",
       " 'ASHRAE - CV options',\n",
       " 'IBM Attrition Prediction using Logistic Regression',\n",
       " \"Let's Classify Dog Breeds\",\n",
       " 'Santander - Simple DNN',\n",
       " 'SFv characters analysis',\n",
       " 'Bruno_Kernel',\n",
       " 'Exp Kaggle - 5.39275 (4)',\n",
       " 'One-shot method to tackle kinship problem [Keras]',\n",
       " 'Starter: model_second cd50c6ff-c',\n",
       " 'Are you a \"real\" painter?',\n",
       " 'Wombat Inference Kernel',\n",
       " 'Starter: Parking Garage Data 8a6cc652-2',\n",
       " 'baseline_VggNet',\n",
       " 'LDA topics',\n",
       " \"Don't Overfit\",\n",
       " 'IEEE - Internal Blend',\n",
       " 'Starter: Eleições c1ab87e1-f',\n",
       " 'Fraudster',\n",
       " 'Forest Classification Kernel_Aninda_XGBoost',\n",
       " 'Plotly HK',\n",
       " 'RF_XGBoost_Trial',\n",
       " 'Violent Crime Prediction Using RF',\n",
       " 'Wordcloud',\n",
       " 'Meta Kaggle: What happened to the team size?',\n",
       " 'Credit Card Fraud Detection',\n",
       " 'Starter: [Dataset no longer available] 4acf8554-5',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4dd0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_popular_titles(popular_titles):\n",
    "    re_print = re.compile('[^%s]' %re.escape(string.printable))\n",
    "    table = str.maketrans('' , '' , string.punctuation)\n",
    "    cleaned = []\n",
    "    for title in popular_titles:\n",
    "        title = normalize('NFD' , title).encode('ascii' , 'ignore')\n",
    "        title = title.decode('UTF-8')\n",
    "        title = title.split()\n",
    "        title = [word.lower() for word in title]\n",
    "        title = [word.translate(table) for word in title]\n",
    "        title = [re_print.sub('' , w) for w in title]\n",
    "        title = [word for word in title if word.isalpha()]\n",
    "        title = ' '.join(title)\n",
    "        cleaned.append(title)\n",
    "        \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fff95e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_titles = preprocessing_popular_titles(popular_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "890ebd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing a song lyrics is here'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_titles[17326]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "013fbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (\"\" in popular_titles):\n",
    "    popular_titles.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "825db190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest type classification',\n",
       " 'great guide of starters lightgbm',\n",
       " 'titanicedar',\n",
       " 'exercise machine learning competitions',\n",
       " 'different embeddings with attention fork',\n",
       " 'modular visu',\n",
       " 'data augmentation packages overview',\n",
       " 'stylebaseline',\n",
       " 'poverty prediction from preprocessing to stacking',\n",
       " 'deterministic neural networks using pytorch',\n",
       " 'fastai lesson',\n",
       " 'fly me to the moon',\n",
       " 'exploring motivations for kiva loans',\n",
       " 'all state claim severity neural net',\n",
       " 'seattle crisis data set dashboard',\n",
       " 'sangmans frozen pollack pancake',\n",
       " 'evaluating magnetic shield tensors',\n",
       " 'bike sharingfeature engineering random forest',\n",
       " 'yusril',\n",
       " 'digit recognition using nn',\n",
       " 'starter dataset no longer available',\n",
       " 'animalshelterdatasetdatasciencetermproject',\n",
       " 'keras',\n",
       " 'first neural net model',\n",
       " 'ml month solution',\n",
       " 'house prices prediction',\n",
       " 'ieee fraud baseline',\n",
       " 'best kannada mnist selfcnn test',\n",
       " 'contagious diseases maps and data analysis',\n",
       " 'first attempt',\n",
       " 'digit recognizer using neural networks',\n",
       " 'starter dataset no longer available',\n",
       " 'densenet tfkeras on',\n",
       " 'starter lgbmaaa',\n",
       " 'kakr kerasxception',\n",
       " 'movie similarity search using',\n",
       " 'beginner forest classification kernelaninda',\n",
       " 'suicide report data visualization',\n",
       " 'starter dadosia',\n",
       " 'convert dataset to cocoformat tools',\n",
       " 'visualization useful functions small eda',\n",
       " 'food preferences',\n",
       " 'starter dataset no longer available',\n",
       " 'how people learn to code',\n",
       " 'analysing the rain forest burnings',\n",
       " 'starter dataset no longer available',\n",
       " 'students performance visualization',\n",
       " 'starter dataset no longer available',\n",
       " 'iris data analsis',\n",
       " 'digit recognizer using mlp for beginners',\n",
       " 'testser',\n",
       " 'berlin neighbourhoods',\n",
       " 'starter dataset no longer available',\n",
       " 'visualization for',\n",
       " 'notebook',\n",
       " 'laba social',\n",
       " 'gapminder graph using r',\n",
       " 'autoregressive model natural gas consumption',\n",
       " 'ultrasound nerve segmentation with fastai',\n",
       " 'exercise random forests',\n",
       " 'starter fivethirtyeight biopics',\n",
       " 'fastai implements with mixup multiprepro',\n",
       " 'pdssc lab session anomaly detection',\n",
       " 'ig public data',\n",
       " 'exercise partial plots',\n",
       " 'exercise joining data',\n",
       " 'ciphertext challenge iii',\n",
       " 'bigquery machine learning exercise',\n",
       " 'titanic',\n",
       " 'setnet trainer',\n",
       " 'simpleconvolutnnforbeginner',\n",
       " 'visualization of molecules with plotly',\n",
       " 'lyft eda animations generating csvs',\n",
       " 'understandingcloudsfromsatelliteimages',\n",
       " 'san francisco crime',\n",
       " 'for severstal sdd',\n",
       " 'schnet',\n",
       " 'exercise creating reading and writing',\n",
       " 'house price prediction',\n",
       " 'fraud detection ieee',\n",
       " 'visualizacion con python',\n",
       " 'starter dataset no longer available',\n",
       " 'predict winplaceperc of pupg',\n",
       " 'exercise group by having count',\n",
       " 'starter simple stock data set',\n",
       " 'house prices deep learning by keras',\n",
       " 'gre dataset analysis',\n",
       " 'aicamp decision tree exercise',\n",
       " 'exercise bar charts and heatmaps',\n",
       " 'complete titanic tutorial with ml nn ensembling',\n",
       " 'simple linear regression using sklearn',\n",
       " 'linear regression',\n",
       " 'xception baseline for severstal transfer learning',\n",
       " 'rltest',\n",
       " 'iceberg challenge convolutional net',\n",
       " 'trabalho software ii',\n",
       " 'topic analysis of imdb reviews chaza',\n",
       " 'ml tutorial using breast cancer dataset',\n",
       " 'airbnb seattle data cleaning',\n",
       " 'transfer learning for digit recognizer',\n",
       " 'textclassificationexample',\n",
       " 'kaggle meta data simple analysis',\n",
       " 'creditcard',\n",
       " 'nlp',\n",
       " 'the race to predict molecular properties',\n",
       " 'mnist digit detection',\n",
       " 'calculas',\n",
       " 'house price prediction',\n",
       " 'house sales analysis',\n",
       " 'rsna eda',\n",
       " 'fighter',\n",
       " 'starter dataset no longer available',\n",
       " 'boston crime analysis',\n",
       " 'exercise tensorflow programming',\n",
       " 'carclassification',\n",
       " 'us twitter airline sentiment',\n",
       " 'proyecto inteligencia artificial',\n",
       " 'wordl cup my first example',\n",
       " 'how effectively business is driving conversions',\n",
       " 'split',\n",
       " 'chaos',\n",
       " 'using finetuned',\n",
       " 'helsings solution',\n",
       " 'ibm hr flight risk',\n",
       " 'severstal fastai unet baseline',\n",
       " 'exercise syntax variables and numbers',\n",
       " 'suicide study for brazil',\n",
       " 'predicting app ratings and eda',\n",
       " 'fastai lesson camvid',\n",
       " 'new inferance with classifier',\n",
       " 'starter cardiovascular disease dataset',\n",
       " 'collab comp twelfth try',\n",
       " 'dmmm',\n",
       " 'mas keras dataframe',\n",
       " 'convnetmnist',\n",
       " 'titanic oma',\n",
       " 'knnadult',\n",
       " 'gradientinabox',\n",
       " 'ig eda and models',\n",
       " 'movie reviews eda dnn',\n",
       " 'the secret charts library',\n",
       " 'movie recommender systems',\n",
       " 'first try',\n",
       " 'starter dataset no longer available',\n",
       " 'tactic hyperparameter optimization lightgbm',\n",
       " 'probability of default bank loan data',\n",
       " 'team vengers',\n",
       " 'dataexplorationandmodelingfortitanic',\n",
       " 'starter dataset no longer available',\n",
       " 'contextaware recommender',\n",
       " 'starter tictactoe endgame dataset',\n",
       " 'squad visualization xy coordinate',\n",
       " 'nyctaxitripduration',\n",
       " 'housing price',\n",
       " 'dataset preparation for classification task',\n",
       " 'titanickj',\n",
       " 'lagdataanalysispositionanalysis',\n",
       " 'data exploration and visualization',\n",
       " 'kaggle survey starter kit',\n",
       " 'query for us census for and',\n",
       " 'first r project iris flowers classification',\n",
       " 'unsupervised jigsaw puzzle solving on mnist',\n",
       " 'logsticregweatheraus',\n",
       " 'kneeelbow point detection',\n",
       " 'ongoing',\n",
       " 'steelmasking',\n",
       " 'understanding clouds keras unet',\n",
       " 'rsnaintracranialhemorrhagedetection',\n",
       " 'eda and a neural network',\n",
       " 'test bert',\n",
       " 'learning ml and python with titanic disaster',\n",
       " 'learning sign language digits with cnn dl',\n",
       " 'vsb power lstm understanding',\n",
       " 'basic neural network using tensorflow',\n",
       " 'xgboostinganimaldiseasepredictor',\n",
       " 'titanicsolution',\n",
       " 'san francisco open data',\n",
       " 'predicting molecular properties',\n",
       " 'cs data science',\n",
       " 'analysis of crimes in boston',\n",
       " 'starter dataset no longer available',\n",
       " 'optimizing lightgbm hyperparameters',\n",
       " 'what proper weights give ieeeint blend',\n",
       " 'aerial cactus identification',\n",
       " 'all shit',\n",
       " 'exercise lists',\n",
       " 'tactic class weight',\n",
       " 'using tensorflow w bert on nq',\n",
       " 'insightful eda modeling lgbm and xgb on gpu',\n",
       " 'classify country of usage',\n",
       " 'unet no data augmentation no regularization',\n",
       " 'mushroom data with classifiers',\n",
       " 'ieee fraud detection lgbm single model',\n",
       " 'carleton ai intro to data science workshop',\n",
       " 'submit maskrcnn',\n",
       " 'olympics games',\n",
       " 'trabalho desligamentos',\n",
       " 'from prototyping to submission fastai',\n",
       " 'vehicle angle prediction understanding eda',\n",
       " 'average masks',\n",
       " 'linear regression for bagrut averages in israel',\n",
       " 'bank loan modeling ile ml',\n",
       " 'ml workshop',\n",
       " 'self driving car steering angle predictions',\n",
       " 'binanceapi',\n",
       " 'movie review data preprocessing tutorial',\n",
       " 'titanic solution',\n",
       " 'steel detection',\n",
       " 'multilayer perceptron using tensorflow',\n",
       " 'keras blueprint',\n",
       " 'detailed project walkthough of petfindermy',\n",
       " 'exercicioavaliacaopoliticaspublicas',\n",
       " 'cs data science',\n",
       " 'starter dataset no longer available',\n",
       " 'titanic begining',\n",
       " 'mlbre',\n",
       " 'playing with thresholds',\n",
       " 'feature engineering and regression',\n",
       " 'single rnn with folds',\n",
       " 'ranran',\n",
       " 'dr titanic on kaggle',\n",
       " 'pneumonia prediction from chest xray images',\n",
       " 'kernelaptosmodeltesting',\n",
       " 'starter dataset no longer available',\n",
       " 'severstal mlcompcatalyst infer',\n",
       " 'whales a simple guide',\n",
       " 'signusdetection',\n",
       " 'extensive eda and modeling xgb and hyperopt',\n",
       " 'fastai titanic',\n",
       " 'titanic kaggle practice',\n",
       " 'baseline in pytorch',\n",
       " 'synthetic financial datasets for fraud detection',\n",
       " 'titanic survive predictionradom forest',\n",
       " 'exploratory analysis and model building',\n",
       " 'kannadamnist',\n",
       " 'titanic survival prediction',\n",
       " 'music classification using cnn model',\n",
       " 'titatninc my first solution of ml',\n",
       " 'singapore aibnb analysis',\n",
       " 'forecast simple exponential arima',\n",
       " 'nlphw',\n",
       " 'statistical analysis for elo',\n",
       " 'airbnbdata',\n",
       " 'categorical feature encoding challenge edamodel',\n",
       " 'footstats',\n",
       " 'ds bowl simple lgbm using aggregated data',\n",
       " 'exercise introduction',\n",
       " 'breast cancer wisconsin diagnostic data set',\n",
       " 'prudential life assessment fastai',\n",
       " 'recommending news articles based on read articles',\n",
       " 'starter median age of the population',\n",
       " 'riga flights small review',\n",
       " 'my first titanic survival pred',\n",
       " 'using knn predicator on the adul',\n",
       " 'starter notebook',\n",
       " 'box office linear regression',\n",
       " 'facial keypoints detection',\n",
       " 'advanced eda on ny airbnb',\n",
       " 'cnn lstm vietnamese sentiment',\n",
       " 'salt segmentation',\n",
       " 'ministcnn',\n",
       " 'stock behavior from business news',\n",
       " 'examplepy',\n",
       " 'petfinder simple lgbm',\n",
       " 'classifying wines by the continent',\n",
       " 'exploratoryclassifiersinterpretation',\n",
       " 'starter dataset no longer available',\n",
       " 'nyc inmates in custody kaggle class',\n",
       " 'cnn filters on',\n",
       " 'fastai ootb cutoutefficientnet',\n",
       " 'eda feat engineering encode conquer',\n",
       " 'exercise feature selection',\n",
       " 'lgbmbaseline',\n",
       " 'students performance analysis',\n",
       " 'blue book for bulldozers using random forest',\n",
       " 'liver patients analysis and prediction',\n",
       " 'la parking violation explorer and recommendations',\n",
       " 'starter dataset no longer available',\n",
       " 'encourage diversity reduce bias cola',\n",
       " 'mnist classification',\n",
       " 'seedlings',\n",
       " 'deep autoencoder',\n",
       " 'home credit default risk model building',\n",
       " 'starter health insurance coverage in',\n",
       " 'elaboracao modelo aula python ml ii',\n",
       " 'taxipriceprediction',\n",
       " 'pytorch',\n",
       " 'predicting fraud in financial payment services',\n",
       " 'grab traffic mgmt',\n",
       " 'iris data classification and eda',\n",
       " 'kickstarterdataexploary',\n",
       " 'pimaindiansdiabetespredictionkeras',\n",
       " 'device classification',\n",
       " 'demo analyzing cardiovascular data',\n",
       " 'insights into kickstarter crowdfunding data',\n",
       " 'cnn kernel for video capture',\n",
       " 'skin cancer mnist',\n",
       " 'motorgendcgan',\n",
       " 'xgboost feature selection dsbowl',\n",
       " 'kernalcbt',\n",
       " 'toxic comment visualization',\n",
       " 'death records',\n",
       " 'different linear models',\n",
       " 'perfumerecommendations',\n",
       " 'fashionmnist',\n",
       " 'hr analytics practice',\n",
       " 'best model and result analysis',\n",
       " 'heart disease preprocessing prediction',\n",
       " 'better nlp summarisers notebook',\n",
       " 'titanic using extratrees',\n",
       " 'aptos blindness',\n",
       " 'cost of living',\n",
       " 'ai project',\n",
       " 'pet adoption eda preliminary model',\n",
       " 'starter dataset no longer available',\n",
       " 'truncatedsvd tsne and decision tree baseline',\n",
       " 'hospitality in era of airbnb',\n",
       " 'quality prediction in iron ore',\n",
       " 'basic ensemble model',\n",
       " 'fastai rf vs classic titanic',\n",
       " 'svmknn',\n",
       " 'news category classifier',\n",
       " 'titanic competition data exploration',\n",
       " 'kernellrkd',\n",
       " 'santander customer prediction',\n",
       " 'house prices from data cleaning to modeling',\n",
       " 'the examination on fatal police shootings in usa',\n",
       " 'housespriceprediction',\n",
       " 'musclehub gym ab test',\n",
       " 'ashrae great energy predictor iii',\n",
       " 'keras binary cats dogs resnet',\n",
       " 'arcfacehumpbackcustomheadfastai',\n",
       " 'starter birds songs numeric dataset',\n",
       " 'eeglea',\n",
       " 'candidates popularity heatmap by state',\n",
       " 'electricity consumption in the largest nl cities',\n",
       " 'pbmc dataset',\n",
       " 'transfer learning tutorial',\n",
       " 'bikebuyer prediction',\n",
       " 'exercise pipelines',\n",
       " 'text preprocessing load embeddings and cnn',\n",
       " 'titanic ml challenge',\n",
       " 'movielensanalysis',\n",
       " 'automating data pipelines day',\n",
       " 'predicting graduate admission',\n",
       " 'suicide data an exploration and analysis',\n",
       " 'costa rica problem',\n",
       " 'exercise crossvalidation',\n",
       " 'starter noaa precipitation minute',\n",
       " 'titanic model',\n",
       " 'movie review competition public leaderboard',\n",
       " 'yake brown clustering pipeline',\n",
       " 'image shape distribution previous and present',\n",
       " 'spotify data analysis',\n",
       " 'discussion upvotes how long till the medal',\n",
       " 'materiationproperty',\n",
       " 'learn python',\n",
       " 'pytorch resnext',\n",
       " 'causal impact analysis on android market',\n",
       " 'jigsaw text classify',\n",
       " 'exercise order by',\n",
       " 'xgbclassifier',\n",
       " 'starter dataset no longer available',\n",
       " 'getting started with titanic',\n",
       " 'use multiple year data',\n",
       " 'ucode script',\n",
       " 'deep learning from scratch learning note chinese',\n",
       " 'ksmconsulting',\n",
       " 'movie revenue prediction',\n",
       " 'housingregressionusingkeras',\n",
       " 'captchas single characters',\n",
       " 'titanic with simple scikitlearn',\n",
       " 'exercise as with',\n",
       " 'load all tables for data exploration',\n",
       " 'it takes a village and a markov model',\n",
       " 'just showing off a cool plot',\n",
       " 'scriptaminos',\n",
       " 'careervillage initial analysis',\n",
       " 'starter deepscapulassm',\n",
       " 'risk assessment in social lending',\n",
       " 'mainkernel',\n",
       " 'house simple random forest regression',\n",
       " 'wine data visualization',\n",
       " 'multilabel segmentation using fastai',\n",
       " 'house prices data',\n",
       " 'pandasconcatappend',\n",
       " 'feature selection with random forest',\n",
       " 'santander genetic feature engineering',\n",
       " 'bilstmgru dual embedding new test',\n",
       " 'crimes',\n",
       " 'simple recommender pivot tfidf cossim',\n",
       " 'recognising mnist digits',\n",
       " 'dl',\n",
       " 'controller',\n",
       " 'starter dataset no longer available',\n",
       " 'notebook',\n",
       " 'city of la',\n",
       " 'midas',\n",
       " 'preprocessing train and validation',\n",
       " 'club mahindra challenge',\n",
       " 'confidence interval estimation via bootstrapping',\n",
       " 'advanced fires analysis with plotly',\n",
       " 'aicamp ensemble bias vs variance exercise',\n",
       " 'headline generation reuters',\n",
       " 'ashrae energy simple average',\n",
       " 'primerintento',\n",
       " 'statisticallearninginpython',\n",
       " 'ibm capstone project',\n",
       " 'starter malaria cell images dataset',\n",
       " 'starter dataset no longer available',\n",
       " 'rossmanndataengineering',\n",
       " 'with pytorch not that terrified',\n",
       " 'data visualization',\n",
       " 'nmt playground',\n",
       " 'easiestkernelforeveryoneinpython',\n",
       " 'deep dive into edafeature engineering',\n",
       " 'dataprep',\n",
       " 'starter hr all models',\n",
       " 'keras cnn',\n",
       " 'poverty level prediction beginers kernel',\n",
       " 'airline price optimization microchallenge',\n",
       " 'rape crimes india eda',\n",
       " 'pad wt',\n",
       " 'boston with xgboost',\n",
       " 'sentiment analysis using bidirectional lstm',\n",
       " 'introduction to generative adversarial networks',\n",
       " 'exploration of traffic dataset',\n",
       " 'trainandtest',\n",
       " 'trabalhoworldmarathonmajors',\n",
       " 'kannadaminstlgb',\n",
       " 'starter parking garage data',\n",
       " 'ieeecis fraud detection with xgboost in r',\n",
       " 'my ibm data attrition',\n",
       " 'starter oecd registered unemployment',\n",
       " 'supervised and unsupervised model',\n",
       " 'predicting ted talks views with ml models',\n",
       " 'starter people years and over',\n",
       " 'titanic daniel y ana',\n",
       " 'testnotebook',\n",
       " 'bayesian nerual networks with tensorflow',\n",
       " 'lgbm demand forecasting',\n",
       " 'bigquerygeotab intersection congestion',\n",
       " 'red pinedo chang velasquez',\n",
       " 'exercise functions and getting help',\n",
       " 'multiinput deep learning model baseline',\n",
       " 'xgbmgall',\n",
       " 'starter dataset no longer available',\n",
       " 'lightgbm starter bayesianoptimization',\n",
       " 'steel mmdet',\n",
       " 'steel defect detection',\n",
       " 'ashrae interactive data visualization with plotly',\n",
       " 'house pricing using neural nets',\n",
       " 'final',\n",
       " 'rsna ih detection eda baseline',\n",
       " 'ver scriptsiskagglekernelorscriptruninng',\n",
       " 'starter dataset no longer available',\n",
       " 'starter dataset no longer available',\n",
       " 'compressing mnist images to bits',\n",
       " 'plotly tutorial for beginners',\n",
       " 'histologybaseline',\n",
       " 'using r for eda modeling',\n",
       " 'penalised logistic regression model titanic',\n",
       " 'us airline sentiment lstm',\n",
       " 'kernel group',\n",
       " 'starter dataset no longer available',\n",
       " 'xceptionbaseline',\n",
       " 'fork of freesound curated mix',\n",
       " 'keras added preproc aptos',\n",
       " 'exercise explore your data',\n",
       " 'starter trainingdata',\n",
       " 'model prediction submission',\n",
       " 'bertwithfastaitutorial',\n",
       " 'cuisine analysis',\n",
       " 'gcn on bonds and distances',\n",
       " 'audio emotion part apply to new audio data',\n",
       " 'starter mohantydata',\n",
       " 'stanford dogs keras',\n",
       " 'classification of field position decision tree',\n",
       " 'recommendation systems different models',\n",
       " 'neural network baseline',\n",
       " 'fastai',\n",
       " 'plant disease detection using keras n',\n",
       " 'nyc open data tree colors autumn',\n",
       " 'starter dataset no longer available',\n",
       " 'policy gradient',\n",
       " 'utils',\n",
       " 'gstore part data cleansing',\n",
       " 'new features',\n",
       " 'basic digits recognizer with keras',\n",
       " 'starter dataset no longer available',\n",
       " 'first look',\n",
       " 'tweet topic modeling',\n",
       " 'leis model',\n",
       " 'simple rf starter',\n",
       " 'computer vision with seedlings',\n",
       " 'fork of hello',\n",
       " 'my stacking method',\n",
       " 'creating reading writing data',\n",
       " 'starter atp matches cleaned',\n",
       " 'convert from training images to pytorch dataset',\n",
       " 'cellularimages',\n",
       " 'gan dogs starter custom layers',\n",
       " 'quickclassification',\n",
       " 'darthkernel',\n",
       " 'dashboarding with scheduled notebooks',\n",
       " 'cnn with fast ai',\n",
       " 'severstal preparing dataset for classification',\n",
       " 'extensive eda and modelling geotab inertsection',\n",
       " 'mymnist',\n",
       " 'petfinderpredictionnotebook',\n",
       " 'group final',\n",
       " 'summarisercosinemethodclass',\n",
       " 'playground',\n",
       " 'data cleaning challenge scale and normalize data',\n",
       " 'vsb fault detection dwt denoising',\n",
       " 'handwrittendigitrecognition',\n",
       " 'kannada mnist activation visualization',\n",
       " 'kernel',\n",
       " 'starter ebird brazilian observations',\n",
       " 'data breaches tableau visualisation',\n",
       " 'place solution',\n",
       " 'eda chicago sex offenders',\n",
       " 'starter heart disease uci',\n",
       " 'predicting customer churn',\n",
       " 'ensemblelightgbmcatboost',\n",
       " 'python notebook',\n",
       " 'how to remember pandas index methods',\n",
       " 'flatiron vg model',\n",
       " 'flower recognition',\n",
       " 'wine data',\n",
       " 'svm on telugu handwritten characters',\n",
       " 'starter dataset no longer available',\n",
       " 'tfnn',\n",
       " 'exercicioavaliacaopoliticaspublicas',\n",
       " 'digit recognition',\n",
       " 'extract image features from pretrained nnver',\n",
       " 'starter parking garage data',\n",
       " 'fraud detection using different algorithms',\n",
       " 'temporal analysis of the denver police dataset',\n",
       " 'nba player salary and median influence',\n",
       " 'my try with titanic',\n",
       " 'convert categorical to numerical data',\n",
       " 'ner detection',\n",
       " 'starter parking garage data',\n",
       " 'learning rates study dogs vs cats',\n",
       " 'sigma news benchmark months',\n",
       " 'analise exploratoria suicidios',\n",
       " 'titanic explore features',\n",
       " 'memory optimization and analysis of wildfire data',\n",
       " 'starter bitcoin blockchain',\n",
       " 'starter world bank health nutrition',\n",
       " 'quora',\n",
       " 'using keras',\n",
       " 'starter severstal',\n",
       " 'clark final project',\n",
       " 'csii assignment c image classifier',\n",
       " 'simple ensemble model',\n",
       " 'detailed eda with visualizations',\n",
       " 'exercise your first machine learning model',\n",
       " 'baseline model',\n",
       " 'nyc taxi fare prediction',\n",
       " 'nyc data science project',\n",
       " 'starter kernel for',\n",
       " 'cardusagekmeans',\n",
       " 'whales competition',\n",
       " 'visualize soccer data with seaborn',\n",
       " 'titaniclogistic regression',\n",
       " 'digit recognitions',\n",
       " 'interactive car with plotly',\n",
       " 'firsttest',\n",
       " 'san francisco crime classification',\n",
       " 'start here a gentle introduction',\n",
       " 'datingkernel',\n",
       " 'second day interactive dashboard',\n",
       " 'denoised autoencoder',\n",
       " 'world happiness report eda',\n",
       " 'aapractice frauddetection',\n",
       " 'a simple tutorial on exploratory data analysis',\n",
       " 'datafile',\n",
       " 'churn modelling data visualization and prediction',\n",
       " 'starter dataset no longer available',\n",
       " 'starter dataset no longer available',\n",
       " 'computer vision with seedlings',\n",
       " 'dcgan',\n",
       " 'pytorchoverview',\n",
       " 'severstalmlcomptrain',\n",
       " 'mxnetgluonbaseline',\n",
       " 'simple lgbm solution',\n",
       " 'desmatamento amazonia legal',\n",
       " 'exercise final project',\n",
       " 'knearest neighbor',\n",
       " 'eliminate features recursively cv',\n",
       " 'flower recogition hackerearth ensemble',\n",
       " 'warm up machine learning with a heart',\n",
       " 'setting up data generator and cnn in r',\n",
       " 'exercise booleans and conditionals daily',\n",
       " 'python programming from a to z',\n",
       " 'starter median personal family and',\n",
       " 'san francisco crime resolution predictor',\n",
       " 'manipulating geospatial data',\n",
       " 'titanic xgboost example in r',\n",
       " 'keras for search ships in satellite image',\n",
       " 'the bidirectional lstm',\n",
       " 'ggggggg',\n",
       " 'lab sentiment ds',\n",
       " 'nih chest x ray age',\n",
       " 'datos',\n",
       " 'starter home homeowner vacancy rate',\n",
       " 'cyrilsantosexamtaxi',\n",
       " 'exercise strings and dictionaries',\n",
       " 'analysis of titanic',\n",
       " 'kekek',\n",
       " 'social network ads knearest neighbors',\n",
       " 'severstal steel defect detection seg only',\n",
       " 'fastaiberttrainbaseline',\n",
       " 'suicide data exploration and analysis',\n",
       " 'guia taller analisis de datos con python',\n",
       " 'summarizer',\n",
       " 'mnist from data visualization to submission',\n",
       " 'mytesta',\n",
       " 'starter dataset no longer available',\n",
       " 'demoyelpsentimentanalysis',\n",
       " 'multihardaug',\n",
       " 'resnet from scratch pytorch lb',\n",
       " 'starter poverty universe all ages',\n",
       " 'starter googlelandmarks dataset',\n",
       " 'ieeecis fraud detection',\n",
       " 'exerciciosalaavaliacaopoliticaspublicas',\n",
       " 'kodryan mmp msu gacrp my best',\n",
       " 'data visualizations iris dataset',\n",
       " 'mas image segmentation',\n",
       " 'facebookcheckin',\n",
       " 'naivebayersbow kernel',\n",
       " 'pandas exercises',\n",
       " 'hands on machine learning with python',\n",
       " 'ministdigitrecognitioncnn',\n",
       " 'uberdecisiontree',\n",
       " 'lightgbm with weighted averages dropout',\n",
       " 'ieee fraud new features export lb',\n",
       " 'starter parking garage data',\n",
       " 'collab comp ninth try',\n",
       " 'rekagglefavoritatimeseriesfeatureengineering',\n",
       " 'starter parking garage data',\n",
       " 'keras around',\n",
       " 'natural language processing nlp project',\n",
       " 'simple cnn for kannada classification',\n",
       " 'scriptfbtest',\n",
       " 'custumer satisfaction prediction classification',\n",
       " 'public sem machine learning',\n",
       " 'modified',\n",
       " 'avian project aap',\n",
       " 'ugatit',\n",
       " 'digit recognizer mnist',\n",
       " 'data science best practices',\n",
       " 'day getting started with python',\n",
       " 'house prices regression',\n",
       " 'pspnet',\n",
       " 'starter dataset no longer available',\n",
       " 'extensive data exploration modelling python',\n",
       " 'starter dataset no longer available',\n",
       " 'starter world bank quarterly external',\n",
       " 'how good does your chocolate taste',\n",
       " 'keras cnn whale detection beginner level',\n",
       " 'hpart',\n",
       " 'titanic survival prediction decision tree',\n",
       " 'very simple nn in pytorch with sparsetensor',\n",
       " 'corvus part using keras neural networks',\n",
       " 'exploratory',\n",
       " 'titanic decisiontreeclassifier',\n",
       " 'fastai lesson horses by color breed',\n",
       " 'predictfuturemonthlysaleswithprophet',\n",
       " 'first',\n",
       " 'to the top',\n",
       " 'cactus detection',\n",
       " 'starter dataset no longer available',\n",
       " 'trabalho',\n",
       " 'bag of words',\n",
       " 'starter malaria cell images dataset',\n",
       " 'notebook',\n",
       " 'world happiness index',\n",
       " 'saleprice prediction',\n",
       " 'template notebook',\n",
       " 'housing prices',\n",
       " 'rm',\n",
       " 'with xgboost in r',\n",
       " 'wlblackjackclean',\n",
       " 'exploringandsomebaselinemodels',\n",
       " 'predict future sales',\n",
       " 'russian troll tweets what why when',\n",
       " 'final submission',\n",
       " 'compresserator',\n",
       " 'springleaf competition eda second attempt',\n",
       " 'merge datasets',\n",
       " 'starter dataset no longer available',\n",
       " 'titanicmy first submission',\n",
       " 'python exercise functions and getting help',\n",
       " 'bigquery workflow',\n",
       " 'aibnb challenge',\n",
       " 'pokemon gan',\n",
       " 'digitrecognizer',\n",
       " 'starter dataset no longer available',\n",
       " 'machine learning digitrecognizer',\n",
       " 'keras nn mixup',\n",
       " 'digit recognition from scratch',\n",
       " 'machinehack predict food prices',\n",
       " 'two sigma competition',\n",
       " 'santander starter eda',\n",
       " 'analysis of flight delay',\n",
       " 'catboost',\n",
       " 'predicthouseprices',\n",
       " 'data visualization with happiness data',\n",
       " 'car noise data',\n",
       " 'kannada mnist competition',\n",
       " 'youtube video trending days in english countries',\n",
       " 'exercise working with external libraries',\n",
       " 'starter paris metro line',\n",
       " 'kerasdrnpspnet',\n",
       " 'qsscode',\n",
       " 'advanced uses of shap values',\n",
       " 'starter wapodea mi opioid data',\n",
       " 'turkeychild',\n",
       " 'dog vs cat classification cnn approximation',\n",
       " 'taming the bert a baseline',\n",
       " 'template aula exercicio',\n",
       " 'scraping sports data with r',\n",
       " 'forest cover stacking multiple classifiers',\n",
       " 'sfo crime multi class algorithms',\n",
       " 'starter',\n",
       " 'cnn ngram',\n",
       " 'smile parental recognizing',\n",
       " 'mnist simple cnn with keras',\n",
       " 'starter heart disease uci',\n",
       " 'nyairbnb',\n",
       " 'blender of solutions',\n",
       " 'library',\n",
       " 'dont overfit',\n",
       " 'wow auction db lua parser',\n",
       " 'machine learning models demonstration',\n",
       " 'pytorch data loader code',\n",
       " 'first submission',\n",
       " 'testing',\n",
       " 'lithuania temperature change',\n",
       " 'my notebook',\n",
       " 'lakshh',\n",
       " 'categoricalfeatureengineeringxgb',\n",
       " 'starter dataset no longer available',\n",
       " 'minivggnet for',\n",
       " 'how to impute missing values',\n",
       " 'report on project work test rib masks',\n",
       " 'kmeans',\n",
       " 'how models work',\n",
       " 'starter dataset no longer available',\n",
       " 'kagglers the gender story a survey',\n",
       " 'is that a dog or a cat acc',\n",
       " 'lasttit',\n",
       " 'starter gas prices in brazil',\n",
       " 'test waves data',\n",
       " 'firstattempt',\n",
       " 'cookingprediction',\n",
       " 'starter parking garage data',\n",
       " 'world happiness report',\n",
       " 'whose turnover it is',\n",
       " 'a step by step guide to image segmentation',\n",
       " 'starter parking garage data',\n",
       " 'titanic feature engineering',\n",
       " 'are you gonna eat there sf health violations',\n",
       " 'appstore application exploration',\n",
       " 'fast lags calculation using numpy arrays',\n",
       " 'eda analysis',\n",
       " 'group',\n",
       " 'random forest script',\n",
       " 'severstal classification pytorch',\n",
       " 'youtube trending videos interactive eda',\n",
       " 'santandar',\n",
       " 'time series garch ts regression',\n",
       " 'starter dataset no longer available',\n",
       " 'toxic comment classification using bert',\n",
       " 'ryzhstaralsya',\n",
       " 'data visualization for beginners',\n",
       " 'ml month models ensemble inference',\n",
       " 'deepdream as in keras book',\n",
       " 'time decay',\n",
       " 'bike sharing prediction',\n",
       " 'fork of realestate',\n",
       " 'starter noaa severe weather data',\n",
       " 'data analysis',\n",
       " 'land cover classification keras densenet',\n",
       " 'starter dataset no longer available',\n",
       " 'starter dataset no longer available',\n",
       " 'power line fault detection create model',\n",
       " 'after greta',\n",
       " 'biggan aaronleong',\n",
       " 'prime sieves',\n",
       " 'insincere questions eda understanding',\n",
       " 'fork of fork of fork of fork of fork of for',\n",
       " 'datasciencebowlfastcompactsolution',\n",
       " 'demo xception and dense',\n",
       " 'titanic with random forest',\n",
       " 'anomaly detectionassignds',\n",
       " 'blacktotransparent rgba',\n",
       " 'deconvnet',\n",
       " 'titanic a complete beginners guide',\n",
       " 'feature generation using time series stats',\n",
       " 'analysis of world crime',\n",
       " 'house pricing',\n",
       " 'eda windowing allowed per rules',\n",
       " 'data visualization',\n",
       " 'nick third week benchmark',\n",
       " 'nyc cab xgb',\n",
       " 'pubgs kernel',\n",
       " 'patchgan',\n",
       " 'credit card fraud detection verisinin incelenmesi',\n",
       " 'sklearntest',\n",
       " 'bokeh visualization',\n",
       " 'notebook',\n",
       " 'new in kaggle eda step by step',\n",
       " 'breast cancer diagnosis with lr',\n",
       " 'kerneldigit recognizer',\n",
       " 'song recom',\n",
       " 'ashrae cv options',\n",
       " 'ibm attrition prediction using logistic regression',\n",
       " 'lets classify dog breeds',\n",
       " 'santander simple dnn',\n",
       " 'sfv characters analysis',\n",
       " 'brunokernel',\n",
       " 'exp kaggle',\n",
       " 'oneshot method to tackle kinship problem keras',\n",
       " 'starter modelsecond',\n",
       " 'are you a real painter',\n",
       " 'wombat inference kernel',\n",
       " 'starter parking garage data',\n",
       " 'baselinevggnet',\n",
       " 'lda topics',\n",
       " 'dont overfit',\n",
       " 'ieee internal blend',\n",
       " 'starter eleicoes',\n",
       " 'fraudster',\n",
       " 'forest classification kernelanindaxgboost',\n",
       " 'plotly hk',\n",
       " 'rfxgboosttrial',\n",
       " 'violent crime prediction using rf',\n",
       " 'wordcloud',\n",
       " 'meta kaggle what happened to the team size',\n",
       " 'credit card fraud detection',\n",
       " 'starter dataset no longer available',\n",
       " 'pets adoption simple pandas random forest',\n",
       " 'deepartist identify artist from art',\n",
       " 'bhujithbikesharekernel',\n",
       " 'fashioncategoryidentification',\n",
       " 'titanic is sinking',\n",
       " 'python lgb baseline',\n",
       " 'multiplelinear regression fish weight estimation',\n",
       " 'heart',\n",
       " 'dog vs cat classifier',\n",
       " 'kannnadamnisttest',\n",
       " 'santander dealing with imbalanced data',\n",
       " 'la metro bike share',\n",
       " 'my first practice',\n",
       " 'project euler not the dataset',\n",
       " 'starter lunarrock',\n",
       " 'churnpredictiondecisontree',\n",
       " 'random forest regressor',\n",
       " 'matplotlib tutorial for beginners',\n",
       " 'global terrorism storytelling',\n",
       " 'tweet classification using awdlstm',\n",
       " 'house pricing fastai',\n",
       " 'first exploration',\n",
       " 'twitter sentiment analysis',\n",
       " 'exercise model validation',\n",
       " 'stripped down code',\n",
       " 'starter part',\n",
       " 'taller en moldeamiento series de tiempo',\n",
       " 'web scrapping',\n",
       " 'kuzushiji visualisation',\n",
       " 'health data',\n",
       " 'microsoft malware detection xgboost tuning',\n",
       " 'eda in crime of rape in india',\n",
       " 'layer neural network for graduate admissionshw',\n",
       " 'dashboarding',\n",
       " 'elo competition',\n",
       " 'catsdogsclassifiation',\n",
       " 'exploring random forest on a grid',\n",
       " 'in a few lines of code',\n",
       " 'btnotebook',\n",
       " 'advanced feature exploration',\n",
       " 'svd pca and tsne simple explanation',\n",
       " 'zomato ratings',\n",
       " 'first competition',\n",
       " 'actividad modelo de propension al churn',\n",
       " 'world happiness report my first project',\n",
       " 'digitsnotebook',\n",
       " 'starbucks in world countries with india',\n",
       " 'titanicsurvivedrandomforest',\n",
       " 'analyzing the graduate admission eda ml',\n",
       " 'trial script',\n",
       " 'graduate admissions data prediction model',\n",
       " 'starter parking garage data',\n",
       " 'airbus ship detection yet another eda',\n",
       " 'facebook competition',\n",
       " 'sklearn pipeline playground for classifiers',\n",
       " 'eda modeling post models analysis are ongoing',\n",
       " 'pytorch baseline updated',\n",
       " 'pytorch fastai top or good results',\n",
       " 'advanced prediction of ames house prices',\n",
       " 'data cleaning challenge character encodings',\n",
       " 'starter dataset no longer available',\n",
       " 'youtubeprediction',\n",
       " 'starter dataset no longer available',\n",
       " 'picnichack',\n",
       " 'eda for crime data',\n",
       " 'exoplanetsnotebook',\n",
       " 'housing price predictions',\n",
       " 'tensorflow',\n",
       " 'facebook comment dataset',\n",
       " 'data mining',\n",
       " 'gazing into the data abyss time series analysis',\n",
       " 'book recommendation',\n",
       " 'foresttypes',\n",
       " 'exercise categorical variables',\n",
       " 'lstm for personality binary classification',\n",
       " 'classification for bank data',\n",
       " 'starter dataset no longer available',\n",
       " 'starter medina municipality dataset',\n",
       " 'localetask',\n",
       " 'santander customer transaction prediction',\n",
       " 'learn python for data science',\n",
       " 'enem eda',\n",
       " 'house prices',\n",
       " 'lesson',\n",
       " 'club mahindra all models',\n",
       " 'starter dataset no longer available',\n",
       " 'larger parts',\n",
       " 'xgb features',\n",
       " 'iris species homework',\n",
       " 'starter dataset no longer available',\n",
       " 'house prices advanced regression techniques',\n",
       " 'transfer learning in nlp',\n",
       " 'the halloween frankencandy generator',\n",
       " 'nlunotebook',\n",
       " 'aplicacoes em nlp aula',\n",
       " 'fifa',\n",
       " 'fraud detection',\n",
       " 'kerneltitanic',\n",
       " 'tuning an extratreesclassifier with gridserachcv',\n",
       " 'eda feature eng lgbgpu cbgpu ranking',\n",
       " 'pytorch cnn sixth generation',\n",
       " 'pubgplacementpredictiontapan',\n",
       " 'fashion class classification',\n",
       " 'starter hostel',\n",
       " 'blindness detection with',\n",
       " 'aerial cactus identification keras',\n",
       " 'starter',\n",
       " 'starter denver crime data',\n",
       " 'comb of thresholdmask',\n",
       " 'bert lstm rank blender',\n",
       " 'pipeline boosting',\n",
       " 'introduction to vsb kaggle competition',\n",
       " 'ft',\n",
       " 'beginner kernel',\n",
       " 'ibm attrition prediction with ensemble classifier',\n",
       " 'dataaugmentation for object localization',\n",
       " 'pixel mean and variances by digit',\n",
       " 'principal component analysis with scikitlearn',\n",
       " 'imu sensor data exploration',\n",
       " 'numpy scipy and pandas for dummy data scientists',\n",
       " 'exploring jupyter notebook survey data',\n",
       " 'load gap coreference data',\n",
       " 'image to image translation',\n",
       " 'glove xgboost and lgbm',\n",
       " 'basic eda data visualization',\n",
       " 'malaria detection',\n",
       " 'starter virginia lamb auction',\n",
       " 'beginner',\n",
       " 'titanic top with xgboost',\n",
       " 'houseprize',\n",
       " 'select from where',\n",
       " 'memorizing anime face generator',\n",
       " 'glazy recipes eda',\n",
       " 'testjust',\n",
       " 'extra trees',\n",
       " 'nyc taxi speed',\n",
       " 'regression tutorial',\n",
       " 'vicyclekagglepy',\n",
       " 'starter data on statistical capacity',\n",
       " 'titanic data analysis',\n",
       " 'france youtube analysis homework i',\n",
       " 'myutilitymethods',\n",
       " 'catdog image classification',\n",
       " 'simple xgb',\n",
       " 'tutorial cnn partie mnist digits classification',\n",
       " 'with rf and log transformation',\n",
       " 'competition',\n",
       " 'light gbm',\n",
       " 'mobileappsappstore',\n",
       " 'tmubaseline',\n",
       " 'from csv machine learning training',\n",
       " 'et',\n",
       " 'python learning course lesson',\n",
       " 'yolo notebook',\n",
       " 'starter gdpkorea',\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7dcf7785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17326"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(popular_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f1a7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOKENIZING AND PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dcf90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(num_words = 20000 , oov_token ='<oov>')\n",
    "# tokenizer.fit_on_texts(popular_titles)\n",
    "# word_idx = tokenizer.word_index\n",
    "# print(word_idx)\n",
    "# length = 0\n",
    "# j = 0 \n",
    "# for i in range(0,len(popular_titles)):\n",
    "#     if len(popular_titles[i]) > length:\n",
    "#         length = len(popular_titles[i])\n",
    "#         j = i\n",
    "# print(length)\n",
    "# print(popular_titles[j])\n",
    "# print(j)\n",
    "# sequences = tokenizer.texts_to_sequences(popular_titles )\n",
    "# padded = pad_sequences(sequences , maxlen = length , padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d59d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0445d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### max length is 82 and it lies at the 4160th position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8bbc10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[word for word in document.split()] for document in popular_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "946f9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# documents = [\"Human machine interface for lab abc computer applications\",\n",
    "#              \"A survey of user opinion of computer system response time\",\n",
    "#              \"The EPS user interface management system\",\n",
    "#              \"System and human system engineering testing of EPS\",\n",
    "#              \"Relation of user perceived response time to error measurement\",\n",
    "#              \"The generation of random binary unordered trees\",\n",
    "#              \"The intersection graph of paths in trees\",\n",
    "#              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#              \"Graph minors A survey\"]\n",
    "# sentences = [[word for word in document.lower().split()] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a547bdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['forest', 'type', 'classification'],\n",
       " ['great', 'guide', 'of', 'starters', 'lightgbm'],\n",
       " ['titanicedar'],\n",
       " ['exercise', 'machine', 'learning', 'competitions'],\n",
       " ['different', 'embeddings', 'with', 'attention', 'fork'],\n",
       " ['modular', 'visu'],\n",
       " ['data', 'augmentation', 'packages', 'overview'],\n",
       " ['stylebaseline'],\n",
       " ['poverty', 'prediction', 'from', 'preprocessing', 'to', 'stacking'],\n",
       " ['deterministic', 'neural', 'networks', 'using', 'pytorch'],\n",
       " ['fastai', 'lesson'],\n",
       " ['fly', 'me', 'to', 'the', 'moon'],\n",
       " ['exploring', 'motivations', 'for', 'kiva', 'loans'],\n",
       " ['all', 'state', 'claim', 'severity', 'neural', 'net'],\n",
       " ['seattle', 'crisis', 'data', 'set', 'dashboard'],\n",
       " ['sangmans', 'frozen', 'pollack', 'pancake'],\n",
       " ['evaluating', 'magnetic', 'shield', 'tensors'],\n",
       " ['bike', 'sharingfeature', 'engineering', 'random', 'forest'],\n",
       " ['yusril'],\n",
       " ['digit', 'recognition', 'using', 'nn'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['animalshelterdatasetdatasciencetermproject'],\n",
       " ['keras'],\n",
       " ['first', 'neural', 'net', 'model'],\n",
       " ['ml', 'month', 'solution'],\n",
       " ['house', 'prices', 'prediction'],\n",
       " ['ieee', 'fraud', 'baseline'],\n",
       " ['best', 'kannada', 'mnist', 'selfcnn', 'test'],\n",
       " ['contagious', 'diseases', 'maps', 'and', 'data', 'analysis'],\n",
       " ['first', 'attempt'],\n",
       " ['digit', 'recognizer', 'using', 'neural', 'networks'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['densenet', 'tfkeras', 'on'],\n",
       " ['starter', 'lgbmaaa'],\n",
       " ['kakr', 'kerasxception'],\n",
       " ['movie', 'similarity', 'search', 'using'],\n",
       " ['beginner', 'forest', 'classification', 'kernelaninda'],\n",
       " ['suicide', 'report', 'data', 'visualization'],\n",
       " ['starter', 'dadosia'],\n",
       " ['convert', 'dataset', 'to', 'cocoformat', 'tools'],\n",
       " ['visualization', 'useful', 'functions', 'small', 'eda'],\n",
       " ['food', 'preferences'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['how', 'people', 'learn', 'to', 'code'],\n",
       " ['analysing', 'the', 'rain', 'forest', 'burnings'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['students', 'performance', 'visualization'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['iris', 'data', 'analsis'],\n",
       " ['digit', 'recognizer', 'using', 'mlp', 'for', 'beginners'],\n",
       " ['testser'],\n",
       " ['berlin', 'neighbourhoods'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['visualization', 'for'],\n",
       " ['notebook'],\n",
       " ['laba', 'social'],\n",
       " ['gapminder', 'graph', 'using', 'r'],\n",
       " ['autoregressive', 'model', 'natural', 'gas', 'consumption'],\n",
       " ['ultrasound', 'nerve', 'segmentation', 'with', 'fastai'],\n",
       " ['exercise', 'random', 'forests'],\n",
       " ['starter', 'fivethirtyeight', 'biopics'],\n",
       " ['fastai', 'implements', 'with', 'mixup', 'multiprepro'],\n",
       " ['pdssc', 'lab', 'session', 'anomaly', 'detection'],\n",
       " ['ig', 'public', 'data'],\n",
       " ['exercise', 'partial', 'plots'],\n",
       " ['exercise', 'joining', 'data'],\n",
       " ['ciphertext', 'challenge', 'iii'],\n",
       " ['bigquery', 'machine', 'learning', 'exercise'],\n",
       " ['titanic'],\n",
       " ['setnet', 'trainer'],\n",
       " ['simpleconvolutnnforbeginner'],\n",
       " ['visualization', 'of', 'molecules', 'with', 'plotly'],\n",
       " ['lyft', 'eda', 'animations', 'generating', 'csvs'],\n",
       " ['understandingcloudsfromsatelliteimages'],\n",
       " ['san', 'francisco', 'crime'],\n",
       " ['for', 'severstal', 'sdd'],\n",
       " ['schnet'],\n",
       " ['exercise', 'creating', 'reading', 'and', 'writing'],\n",
       " ['house', 'price', 'prediction'],\n",
       " ['fraud', 'detection', 'ieee'],\n",
       " ['visualizacion', 'con', 'python'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['predict', 'winplaceperc', 'of', 'pupg'],\n",
       " ['exercise', 'group', 'by', 'having', 'count'],\n",
       " ['starter', 'simple', 'stock', 'data', 'set'],\n",
       " ['house', 'prices', 'deep', 'learning', 'by', 'keras'],\n",
       " ['gre', 'dataset', 'analysis'],\n",
       " ['aicamp', 'decision', 'tree', 'exercise'],\n",
       " ['exercise', 'bar', 'charts', 'and', 'heatmaps'],\n",
       " ['complete', 'titanic', 'tutorial', 'with', 'ml', 'nn', 'ensembling'],\n",
       " ['simple', 'linear', 'regression', 'using', 'sklearn'],\n",
       " ['linear', 'regression'],\n",
       " ['xception', 'baseline', 'for', 'severstal', 'transfer', 'learning'],\n",
       " ['rltest'],\n",
       " ['iceberg', 'challenge', 'convolutional', 'net'],\n",
       " ['trabalho', 'software', 'ii'],\n",
       " ['topic', 'analysis', 'of', 'imdb', 'reviews', 'chaza'],\n",
       " ['ml', 'tutorial', 'using', 'breast', 'cancer', 'dataset'],\n",
       " ['airbnb', 'seattle', 'data', 'cleaning'],\n",
       " ['transfer', 'learning', 'for', 'digit', 'recognizer'],\n",
       " ['textclassificationexample'],\n",
       " ['kaggle', 'meta', 'data', 'simple', 'analysis'],\n",
       " ['creditcard'],\n",
       " ['nlp'],\n",
       " ['the', 'race', 'to', 'predict', 'molecular', 'properties'],\n",
       " ['mnist', 'digit', 'detection'],\n",
       " ['calculas'],\n",
       " ['house', 'price', 'prediction'],\n",
       " ['house', 'sales', 'analysis'],\n",
       " ['rsna', 'eda'],\n",
       " ['fighter'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['boston', 'crime', 'analysis'],\n",
       " ['exercise', 'tensorflow', 'programming'],\n",
       " ['carclassification'],\n",
       " ['us', 'twitter', 'airline', 'sentiment'],\n",
       " ['proyecto', 'inteligencia', 'artificial'],\n",
       " ['wordl', 'cup', 'my', 'first', 'example'],\n",
       " ['how', 'effectively', 'business', 'is', 'driving', 'conversions'],\n",
       " ['split'],\n",
       " ['chaos'],\n",
       " ['using', 'finetuned'],\n",
       " ['helsings', 'solution'],\n",
       " ['ibm', 'hr', 'flight', 'risk'],\n",
       " ['severstal', 'fastai', 'unet', 'baseline'],\n",
       " ['exercise', 'syntax', 'variables', 'and', 'numbers'],\n",
       " ['suicide', 'study', 'for', 'brazil'],\n",
       " ['predicting', 'app', 'ratings', 'and', 'eda'],\n",
       " ['fastai', 'lesson', 'camvid'],\n",
       " ['new', 'inferance', 'with', 'classifier'],\n",
       " ['starter', 'cardiovascular', 'disease', 'dataset'],\n",
       " ['collab', 'comp', 'twelfth', 'try'],\n",
       " ['dmmm'],\n",
       " ['mas', 'keras', 'dataframe'],\n",
       " ['convnetmnist'],\n",
       " ['titanic', 'oma'],\n",
       " ['knnadult'],\n",
       " ['gradientinabox'],\n",
       " ['ig', 'eda', 'and', 'models'],\n",
       " ['movie', 'reviews', 'eda', 'dnn'],\n",
       " ['the', 'secret', 'charts', 'library'],\n",
       " ['movie', 'recommender', 'systems'],\n",
       " ['first', 'try'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['tactic', 'hyperparameter', 'optimization', 'lightgbm'],\n",
       " ['probability', 'of', 'default', 'bank', 'loan', 'data'],\n",
       " ['team', 'vengers'],\n",
       " ['dataexplorationandmodelingfortitanic'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['contextaware', 'recommender'],\n",
       " ['starter', 'tictactoe', 'endgame', 'dataset'],\n",
       " ['squad', 'visualization', 'xy', 'coordinate'],\n",
       " ['nyctaxitripduration'],\n",
       " ['housing', 'price'],\n",
       " ['dataset', 'preparation', 'for', 'classification', 'task'],\n",
       " ['titanickj'],\n",
       " ['lagdataanalysispositionanalysis'],\n",
       " ['data', 'exploration', 'and', 'visualization'],\n",
       " ['kaggle', 'survey', 'starter', 'kit'],\n",
       " ['query', 'for', 'us', 'census', 'for', 'and'],\n",
       " ['first', 'r', 'project', 'iris', 'flowers', 'classification'],\n",
       " ['unsupervised', 'jigsaw', 'puzzle', 'solving', 'on', 'mnist'],\n",
       " ['logsticregweatheraus'],\n",
       " ['kneeelbow', 'point', 'detection'],\n",
       " ['ongoing'],\n",
       " ['steelmasking'],\n",
       " ['understanding', 'clouds', 'keras', 'unet'],\n",
       " ['rsnaintracranialhemorrhagedetection'],\n",
       " ['eda', 'and', 'a', 'neural', 'network'],\n",
       " ['test', 'bert'],\n",
       " ['learning', 'ml', 'and', 'python', 'with', 'titanic', 'disaster'],\n",
       " ['learning', 'sign', 'language', 'digits', 'with', 'cnn', 'dl'],\n",
       " ['vsb', 'power', 'lstm', 'understanding'],\n",
       " ['basic', 'neural', 'network', 'using', 'tensorflow'],\n",
       " ['xgboostinganimaldiseasepredictor'],\n",
       " ['titanicsolution'],\n",
       " ['san', 'francisco', 'open', 'data'],\n",
       " ['predicting', 'molecular', 'properties'],\n",
       " ['cs', 'data', 'science'],\n",
       " ['analysis', 'of', 'crimes', 'in', 'boston'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['optimizing', 'lightgbm', 'hyperparameters'],\n",
       " ['what', 'proper', 'weights', 'give', 'ieeeint', 'blend'],\n",
       " ['aerial', 'cactus', 'identification'],\n",
       " ['all', 'shit'],\n",
       " ['exercise', 'lists'],\n",
       " ['tactic', 'class', 'weight'],\n",
       " ['using', 'tensorflow', 'w', 'bert', 'on', 'nq'],\n",
       " ['insightful', 'eda', 'modeling', 'lgbm', 'and', 'xgb', 'on', 'gpu'],\n",
       " ['classify', 'country', 'of', 'usage'],\n",
       " ['unet', 'no', 'data', 'augmentation', 'no', 'regularization'],\n",
       " ['mushroom', 'data', 'with', 'classifiers'],\n",
       " ['ieee', 'fraud', 'detection', 'lgbm', 'single', 'model'],\n",
       " ['carleton', 'ai', 'intro', 'to', 'data', 'science', 'workshop'],\n",
       " ['submit', 'maskrcnn'],\n",
       " ['olympics', 'games'],\n",
       " ['trabalho', 'desligamentos'],\n",
       " ['from', 'prototyping', 'to', 'submission', 'fastai'],\n",
       " ['vehicle', 'angle', 'prediction', 'understanding', 'eda'],\n",
       " ['average', 'masks'],\n",
       " ['linear', 'regression', 'for', 'bagrut', 'averages', 'in', 'israel'],\n",
       " ['bank', 'loan', 'modeling', 'ile', 'ml'],\n",
       " ['ml', 'workshop'],\n",
       " ['self', 'driving', 'car', 'steering', 'angle', 'predictions'],\n",
       " ['binanceapi'],\n",
       " ['movie', 'review', 'data', 'preprocessing', 'tutorial'],\n",
       " ['titanic', 'solution'],\n",
       " ['steel', 'detection'],\n",
       " ['multilayer', 'perceptron', 'using', 'tensorflow'],\n",
       " ['keras', 'blueprint'],\n",
       " ['detailed', 'project', 'walkthough', 'of', 'petfindermy'],\n",
       " ['exercicioavaliacaopoliticaspublicas'],\n",
       " ['cs', 'data', 'science'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['titanic', 'begining'],\n",
       " ['mlbre'],\n",
       " ['playing', 'with', 'thresholds'],\n",
       " ['feature', 'engineering', 'and', 'regression'],\n",
       " ['single', 'rnn', 'with', 'folds'],\n",
       " ['ranran'],\n",
       " ['dr', 'titanic', 'on', 'kaggle'],\n",
       " ['pneumonia', 'prediction', 'from', 'chest', 'xray', 'images'],\n",
       " ['kernelaptosmodeltesting'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['severstal', 'mlcompcatalyst', 'infer'],\n",
       " ['whales', 'a', 'simple', 'guide'],\n",
       " ['signusdetection'],\n",
       " ['extensive', 'eda', 'and', 'modeling', 'xgb', 'and', 'hyperopt'],\n",
       " ['fastai', 'titanic'],\n",
       " ['titanic', 'kaggle', 'practice'],\n",
       " ['baseline', 'in', 'pytorch'],\n",
       " ['synthetic', 'financial', 'datasets', 'for', 'fraud', 'detection'],\n",
       " ['titanic', 'survive', 'predictionradom', 'forest'],\n",
       " ['exploratory', 'analysis', 'and', 'model', 'building'],\n",
       " ['kannadamnist'],\n",
       " ['titanic', 'survival', 'prediction'],\n",
       " ['music', 'classification', 'using', 'cnn', 'model'],\n",
       " ['titatninc', 'my', 'first', 'solution', 'of', 'ml'],\n",
       " ['singapore', 'aibnb', 'analysis'],\n",
       " ['forecast', 'simple', 'exponential', 'arima'],\n",
       " ['nlphw'],\n",
       " ['statistical', 'analysis', 'for', 'elo'],\n",
       " ['airbnbdata'],\n",
       " ['categorical', 'feature', 'encoding', 'challenge', 'edamodel'],\n",
       " ['footstats'],\n",
       " ['ds', 'bowl', 'simple', 'lgbm', 'using', 'aggregated', 'data'],\n",
       " ['exercise', 'introduction'],\n",
       " ['breast', 'cancer', 'wisconsin', 'diagnostic', 'data', 'set'],\n",
       " ['prudential', 'life', 'assessment', 'fastai'],\n",
       " ['recommending', 'news', 'articles', 'based', 'on', 'read', 'articles'],\n",
       " ['starter', 'median', 'age', 'of', 'the', 'population'],\n",
       " ['riga', 'flights', 'small', 'review'],\n",
       " ['my', 'first', 'titanic', 'survival', 'pred'],\n",
       " ['using', 'knn', 'predicator', 'on', 'the', 'adul'],\n",
       " ['starter', 'notebook'],\n",
       " ['box', 'office', 'linear', 'regression'],\n",
       " ['facial', 'keypoints', 'detection'],\n",
       " ['advanced', 'eda', 'on', 'ny', 'airbnb'],\n",
       " ['cnn', 'lstm', 'vietnamese', 'sentiment'],\n",
       " ['salt', 'segmentation'],\n",
       " ['ministcnn'],\n",
       " ['stock', 'behavior', 'from', 'business', 'news'],\n",
       " ['examplepy'],\n",
       " ['petfinder', 'simple', 'lgbm'],\n",
       " ['classifying', 'wines', 'by', 'the', 'continent'],\n",
       " ['exploratoryclassifiersinterpretation'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['nyc', 'inmates', 'in', 'custody', 'kaggle', 'class'],\n",
       " ['cnn', 'filters', 'on'],\n",
       " ['fastai', 'ootb', 'cutoutefficientnet'],\n",
       " ['eda', 'feat', 'engineering', 'encode', 'conquer'],\n",
       " ['exercise', 'feature', 'selection'],\n",
       " ['lgbmbaseline'],\n",
       " ['students', 'performance', 'analysis'],\n",
       " ['blue', 'book', 'for', 'bulldozers', 'using', 'random', 'forest'],\n",
       " ['liver', 'patients', 'analysis', 'and', 'prediction'],\n",
       " ['la', 'parking', 'violation', 'explorer', 'and', 'recommendations'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['encourage', 'diversity', 'reduce', 'bias', 'cola'],\n",
       " ['mnist', 'classification'],\n",
       " ['seedlings'],\n",
       " ['deep', 'autoencoder'],\n",
       " ['home', 'credit', 'default', 'risk', 'model', 'building'],\n",
       " ['starter', 'health', 'insurance', 'coverage', 'in'],\n",
       " ['elaboracao', 'modelo', 'aula', 'python', 'ml', 'ii'],\n",
       " ['taxipriceprediction'],\n",
       " ['pytorch'],\n",
       " ['predicting', 'fraud', 'in', 'financial', 'payment', 'services'],\n",
       " ['grab', 'traffic', 'mgmt'],\n",
       " ['iris', 'data', 'classification', 'and', 'eda'],\n",
       " ['kickstarterdataexploary'],\n",
       " ['pimaindiansdiabetespredictionkeras'],\n",
       " ['device', 'classification'],\n",
       " ['demo', 'analyzing', 'cardiovascular', 'data'],\n",
       " ['insights', 'into', 'kickstarter', 'crowdfunding', 'data'],\n",
       " ['cnn', 'kernel', 'for', 'video', 'capture'],\n",
       " ['skin', 'cancer', 'mnist'],\n",
       " ['motorgendcgan'],\n",
       " ['xgboost', 'feature', 'selection', 'dsbowl'],\n",
       " ['kernalcbt'],\n",
       " ['toxic', 'comment', 'visualization'],\n",
       " ['death', 'records'],\n",
       " ['different', 'linear', 'models'],\n",
       " ['perfumerecommendations'],\n",
       " ['fashionmnist'],\n",
       " ['hr', 'analytics', 'practice'],\n",
       " ['best', 'model', 'and', 'result', 'analysis'],\n",
       " ['heart', 'disease', 'preprocessing', 'prediction'],\n",
       " ['better', 'nlp', 'summarisers', 'notebook'],\n",
       " ['titanic', 'using', 'extratrees'],\n",
       " ['aptos', 'blindness'],\n",
       " ['cost', 'of', 'living'],\n",
       " ['ai', 'project'],\n",
       " ['pet', 'adoption', 'eda', 'preliminary', 'model'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['truncatedsvd', 'tsne', 'and', 'decision', 'tree', 'baseline'],\n",
       " ['hospitality', 'in', 'era', 'of', 'airbnb'],\n",
       " ['quality', 'prediction', 'in', 'iron', 'ore'],\n",
       " ['basic', 'ensemble', 'model'],\n",
       " ['fastai', 'rf', 'vs', 'classic', 'titanic'],\n",
       " ['svmknn'],\n",
       " ['news', 'category', 'classifier'],\n",
       " ['titanic', 'competition', 'data', 'exploration'],\n",
       " ['kernellrkd'],\n",
       " ['santander', 'customer', 'prediction'],\n",
       " ['house', 'prices', 'from', 'data', 'cleaning', 'to', 'modeling'],\n",
       " ['the', 'examination', 'on', 'fatal', 'police', 'shootings', 'in', 'usa'],\n",
       " ['housespriceprediction'],\n",
       " ['musclehub', 'gym', 'ab', 'test'],\n",
       " ['ashrae', 'great', 'energy', 'predictor', 'iii'],\n",
       " ['keras', 'binary', 'cats', 'dogs', 'resnet'],\n",
       " ['arcfacehumpbackcustomheadfastai'],\n",
       " ['starter', 'birds', 'songs', 'numeric', 'dataset'],\n",
       " ['eeglea'],\n",
       " ['candidates', 'popularity', 'heatmap', 'by', 'state'],\n",
       " ['electricity', 'consumption', 'in', 'the', 'largest', 'nl', 'cities'],\n",
       " ['pbmc', 'dataset'],\n",
       " ['transfer', 'learning', 'tutorial'],\n",
       " ['bikebuyer', 'prediction'],\n",
       " ['exercise', 'pipelines'],\n",
       " ['text', 'preprocessing', 'load', 'embeddings', 'and', 'cnn'],\n",
       " ['titanic', 'ml', 'challenge'],\n",
       " ['movielensanalysis'],\n",
       " ['automating', 'data', 'pipelines', 'day'],\n",
       " ['predicting', 'graduate', 'admission'],\n",
       " ['suicide', 'data', 'an', 'exploration', 'and', 'analysis'],\n",
       " ['costa', 'rica', 'problem'],\n",
       " ['exercise', 'crossvalidation'],\n",
       " ['starter', 'noaa', 'precipitation', 'minute'],\n",
       " ['titanic', 'model'],\n",
       " ['movie', 'review', 'competition', 'public', 'leaderboard'],\n",
       " ['yake', 'brown', 'clustering', 'pipeline'],\n",
       " ['image', 'shape', 'distribution', 'previous', 'and', 'present'],\n",
       " ['spotify', 'data', 'analysis'],\n",
       " ['discussion', 'upvotes', 'how', 'long', 'till', 'the', 'medal'],\n",
       " ['materiationproperty'],\n",
       " ['learn', 'python'],\n",
       " ['pytorch', 'resnext'],\n",
       " ['causal', 'impact', 'analysis', 'on', 'android', 'market'],\n",
       " ['jigsaw', 'text', 'classify'],\n",
       " ['exercise', 'order', 'by'],\n",
       " ['xgbclassifier'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['getting', 'started', 'with', 'titanic'],\n",
       " ['use', 'multiple', 'year', 'data'],\n",
       " ['ucode', 'script'],\n",
       " ['deep', 'learning', 'from', 'scratch', 'learning', 'note', 'chinese'],\n",
       " ['ksmconsulting'],\n",
       " ['movie', 'revenue', 'prediction'],\n",
       " ['housingregressionusingkeras'],\n",
       " ['captchas', 'single', 'characters'],\n",
       " ['titanic', 'with', 'simple', 'scikitlearn'],\n",
       " ['exercise', 'as', 'with'],\n",
       " ['load', 'all', 'tables', 'for', 'data', 'exploration'],\n",
       " ['it', 'takes', 'a', 'village', 'and', 'a', 'markov', 'model'],\n",
       " ['just', 'showing', 'off', 'a', 'cool', 'plot'],\n",
       " ['scriptaminos'],\n",
       " ['careervillage', 'initial', 'analysis'],\n",
       " ['starter', 'deepscapulassm'],\n",
       " ['risk', 'assessment', 'in', 'social', 'lending'],\n",
       " ['mainkernel'],\n",
       " ['house', 'simple', 'random', 'forest', 'regression'],\n",
       " ['wine', 'data', 'visualization'],\n",
       " ['multilabel', 'segmentation', 'using', 'fastai'],\n",
       " ['house', 'prices', 'data'],\n",
       " ['pandasconcatappend'],\n",
       " ['feature', 'selection', 'with', 'random', 'forest'],\n",
       " ['santander', 'genetic', 'feature', 'engineering'],\n",
       " ['bilstmgru', 'dual', 'embedding', 'new', 'test'],\n",
       " ['crimes'],\n",
       " ['simple', 'recommender', 'pivot', 'tfidf', 'cossim'],\n",
       " ['recognising', 'mnist', 'digits'],\n",
       " ['dl'],\n",
       " ['controller'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['notebook'],\n",
       " ['city', 'of', 'la'],\n",
       " ['midas'],\n",
       " ['preprocessing', 'train', 'and', 'validation'],\n",
       " ['club', 'mahindra', 'challenge'],\n",
       " ['confidence', 'interval', 'estimation', 'via', 'bootstrapping'],\n",
       " ['advanced', 'fires', 'analysis', 'with', 'plotly'],\n",
       " ['aicamp', 'ensemble', 'bias', 'vs', 'variance', 'exercise'],\n",
       " ['headline', 'generation', 'reuters'],\n",
       " ['ashrae', 'energy', 'simple', 'average'],\n",
       " ['primerintento'],\n",
       " ['statisticallearninginpython'],\n",
       " ['ibm', 'capstone', 'project'],\n",
       " ['starter', 'malaria', 'cell', 'images', 'dataset'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['rossmanndataengineering'],\n",
       " ['with', 'pytorch', 'not', 'that', 'terrified'],\n",
       " ['data', 'visualization'],\n",
       " ['nmt', 'playground'],\n",
       " ['easiestkernelforeveryoneinpython'],\n",
       " ['deep', 'dive', 'into', 'edafeature', 'engineering'],\n",
       " ['dataprep'],\n",
       " ['starter', 'hr', 'all', 'models'],\n",
       " ['keras', 'cnn'],\n",
       " ['poverty', 'level', 'prediction', 'beginers', 'kernel'],\n",
       " ['airline', 'price', 'optimization', 'microchallenge'],\n",
       " ['rape', 'crimes', 'india', 'eda'],\n",
       " ['pad', 'wt'],\n",
       " ['boston', 'with', 'xgboost'],\n",
       " ['sentiment', 'analysis', 'using', 'bidirectional', 'lstm'],\n",
       " ['introduction', 'to', 'generative', 'adversarial', 'networks'],\n",
       " ['exploration', 'of', 'traffic', 'dataset'],\n",
       " ['trainandtest'],\n",
       " ['trabalhoworldmarathonmajors'],\n",
       " ['kannadaminstlgb'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['ieeecis', 'fraud', 'detection', 'with', 'xgboost', 'in', 'r'],\n",
       " ['my', 'ibm', 'data', 'attrition'],\n",
       " ['starter', 'oecd', 'registered', 'unemployment'],\n",
       " ['supervised', 'and', 'unsupervised', 'model'],\n",
       " ['predicting', 'ted', 'talks', 'views', 'with', 'ml', 'models'],\n",
       " ['starter', 'people', 'years', 'and', 'over'],\n",
       " ['titanic', 'daniel', 'y', 'ana'],\n",
       " ['testnotebook'],\n",
       " ['bayesian', 'nerual', 'networks', 'with', 'tensorflow'],\n",
       " ['lgbm', 'demand', 'forecasting'],\n",
       " ['bigquerygeotab', 'intersection', 'congestion'],\n",
       " ['red', 'pinedo', 'chang', 'velasquez'],\n",
       " ['exercise', 'functions', 'and', 'getting', 'help'],\n",
       " ['multiinput', 'deep', 'learning', 'model', 'baseline'],\n",
       " ['xgbmgall'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['lightgbm', 'starter', 'bayesianoptimization'],\n",
       " ['steel', 'mmdet'],\n",
       " ['steel', 'defect', 'detection'],\n",
       " ['ashrae', 'interactive', 'data', 'visualization', 'with', 'plotly'],\n",
       " ['house', 'pricing', 'using', 'neural', 'nets'],\n",
       " ['final'],\n",
       " ['rsna', 'ih', 'detection', 'eda', 'baseline'],\n",
       " ['ver', 'scriptsiskagglekernelorscriptruninng'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['compressing', 'mnist', 'images', 'to', 'bits'],\n",
       " ['plotly', 'tutorial', 'for', 'beginners'],\n",
       " ['histologybaseline'],\n",
       " ['using', 'r', 'for', 'eda', 'modeling'],\n",
       " ['penalised', 'logistic', 'regression', 'model', 'titanic'],\n",
       " ['us', 'airline', 'sentiment', 'lstm'],\n",
       " ['kernel', 'group'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['xceptionbaseline'],\n",
       " ['fork', 'of', 'freesound', 'curated', 'mix'],\n",
       " ['keras', 'added', 'preproc', 'aptos'],\n",
       " ['exercise', 'explore', 'your', 'data'],\n",
       " ['starter', 'trainingdata'],\n",
       " ['model', 'prediction', 'submission'],\n",
       " ['bertwithfastaitutorial'],\n",
       " ['cuisine', 'analysis'],\n",
       " ['gcn', 'on', 'bonds', 'and', 'distances'],\n",
       " ['audio', 'emotion', 'part', 'apply', 'to', 'new', 'audio', 'data'],\n",
       " ['starter', 'mohantydata'],\n",
       " ['stanford', 'dogs', 'keras'],\n",
       " ['classification', 'of', 'field', 'position', 'decision', 'tree'],\n",
       " ['recommendation', 'systems', 'different', 'models'],\n",
       " ['neural', 'network', 'baseline'],\n",
       " ['fastai'],\n",
       " ['plant', 'disease', 'detection', 'using', 'keras', 'n'],\n",
       " ['nyc', 'open', 'data', 'tree', 'colors', 'autumn'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['policy', 'gradient'],\n",
       " ['utils'],\n",
       " ['gstore', 'part', 'data', 'cleansing'],\n",
       " ['new', 'features'],\n",
       " ['basic', 'digits', 'recognizer', 'with', 'keras'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['first', 'look'],\n",
       " ['tweet', 'topic', 'modeling'],\n",
       " ['leis', 'model'],\n",
       " ['simple', 'rf', 'starter'],\n",
       " ['computer', 'vision', 'with', 'seedlings'],\n",
       " ['fork', 'of', 'hello'],\n",
       " ['my', 'stacking', 'method'],\n",
       " ['creating', 'reading', 'writing', 'data'],\n",
       " ['starter', 'atp', 'matches', 'cleaned'],\n",
       " ['convert', 'from', 'training', 'images', 'to', 'pytorch', 'dataset'],\n",
       " ['cellularimages'],\n",
       " ['gan', 'dogs', 'starter', 'custom', 'layers'],\n",
       " ['quickclassification'],\n",
       " ['darthkernel'],\n",
       " ['dashboarding', 'with', 'scheduled', 'notebooks'],\n",
       " ['cnn', 'with', 'fast', 'ai'],\n",
       " ['severstal', 'preparing', 'dataset', 'for', 'classification'],\n",
       " ['extensive', 'eda', 'and', 'modelling', 'geotab', 'inertsection'],\n",
       " ['mymnist'],\n",
       " ['petfinderpredictionnotebook'],\n",
       " ['group', 'final'],\n",
       " ['summarisercosinemethodclass'],\n",
       " ['playground'],\n",
       " ['data', 'cleaning', 'challenge', 'scale', 'and', 'normalize', 'data'],\n",
       " ['vsb', 'fault', 'detection', 'dwt', 'denoising'],\n",
       " ['handwrittendigitrecognition'],\n",
       " ['kannada', 'mnist', 'activation', 'visualization'],\n",
       " ['kernel'],\n",
       " ['starter', 'ebird', 'brazilian', 'observations'],\n",
       " ['data', 'breaches', 'tableau', 'visualisation'],\n",
       " ['place', 'solution'],\n",
       " ['eda', 'chicago', 'sex', 'offenders'],\n",
       " ['starter', 'heart', 'disease', 'uci'],\n",
       " ['predicting', 'customer', 'churn'],\n",
       " ['ensemblelightgbmcatboost'],\n",
       " ['python', 'notebook'],\n",
       " ['how', 'to', 'remember', 'pandas', 'index', 'methods'],\n",
       " ['flatiron', 'vg', 'model'],\n",
       " ['flower', 'recognition'],\n",
       " ['wine', 'data'],\n",
       " ['svm', 'on', 'telugu', 'handwritten', 'characters'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['tfnn'],\n",
       " ['exercicioavaliacaopoliticaspublicas'],\n",
       " ['digit', 'recognition'],\n",
       " ['extract', 'image', 'features', 'from', 'pretrained', 'nnver'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['fraud', 'detection', 'using', 'different', 'algorithms'],\n",
       " ['temporal', 'analysis', 'of', 'the', 'denver', 'police', 'dataset'],\n",
       " ['nba', 'player', 'salary', 'and', 'median', 'influence'],\n",
       " ['my', 'try', 'with', 'titanic'],\n",
       " ['convert', 'categorical', 'to', 'numerical', 'data'],\n",
       " ['ner', 'detection'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['learning', 'rates', 'study', 'dogs', 'vs', 'cats'],\n",
       " ['sigma', 'news', 'benchmark', 'months'],\n",
       " ['analise', 'exploratoria', 'suicidios'],\n",
       " ['titanic', 'explore', 'features'],\n",
       " ['memory', 'optimization', 'and', 'analysis', 'of', 'wildfire', 'data'],\n",
       " ['starter', 'bitcoin', 'blockchain'],\n",
       " ['starter', 'world', 'bank', 'health', 'nutrition'],\n",
       " ['quora'],\n",
       " ['using', 'keras'],\n",
       " ['starter', 'severstal'],\n",
       " ['clark', 'final', 'project'],\n",
       " ['csii', 'assignment', 'c', 'image', 'classifier'],\n",
       " ['simple', 'ensemble', 'model'],\n",
       " ['detailed', 'eda', 'with', 'visualizations'],\n",
       " ['exercise', 'your', 'first', 'machine', 'learning', 'model'],\n",
       " ['baseline', 'model'],\n",
       " ['nyc', 'taxi', 'fare', 'prediction'],\n",
       " ['nyc', 'data', 'science', 'project'],\n",
       " ['starter', 'kernel', 'for'],\n",
       " ['cardusagekmeans'],\n",
       " ['whales', 'competition'],\n",
       " ['visualize', 'soccer', 'data', 'with', 'seaborn'],\n",
       " ['titaniclogistic', 'regression'],\n",
       " ['digit', 'recognitions'],\n",
       " ['interactive', 'car', 'with', 'plotly'],\n",
       " ['firsttest'],\n",
       " ['san', 'francisco', 'crime', 'classification'],\n",
       " ['start', 'here', 'a', 'gentle', 'introduction'],\n",
       " ['datingkernel'],\n",
       " ['second', 'day', 'interactive', 'dashboard'],\n",
       " ['denoised', 'autoencoder'],\n",
       " ['world', 'happiness', 'report', 'eda'],\n",
       " ['aapractice', 'frauddetection'],\n",
       " ['a', 'simple', 'tutorial', 'on', 'exploratory', 'data', 'analysis'],\n",
       " ['datafile'],\n",
       " ['churn', 'modelling', 'data', 'visualization', 'and', 'prediction'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['computer', 'vision', 'with', 'seedlings'],\n",
       " ['dcgan'],\n",
       " ['pytorchoverview'],\n",
       " ['severstalmlcomptrain'],\n",
       " ['mxnetgluonbaseline'],\n",
       " ['simple', 'lgbm', 'solution'],\n",
       " ['desmatamento', 'amazonia', 'legal'],\n",
       " ['exercise', 'final', 'project'],\n",
       " ['knearest', 'neighbor'],\n",
       " ['eliminate', 'features', 'recursively', 'cv'],\n",
       " ['flower', 'recogition', 'hackerearth', 'ensemble'],\n",
       " ['warm', 'up', 'machine', 'learning', 'with', 'a', 'heart'],\n",
       " ['setting', 'up', 'data', 'generator', 'and', 'cnn', 'in', 'r'],\n",
       " ['exercise', 'booleans', 'and', 'conditionals', 'daily'],\n",
       " ['python', 'programming', 'from', 'a', 'to', 'z'],\n",
       " ['starter', 'median', 'personal', 'family', 'and'],\n",
       " ['san', 'francisco', 'crime', 'resolution', 'predictor'],\n",
       " ['manipulating', 'geospatial', 'data'],\n",
       " ['titanic', 'xgboost', 'example', 'in', 'r'],\n",
       " ['keras', 'for', 'search', 'ships', 'in', 'satellite', 'image'],\n",
       " ['the', 'bidirectional', 'lstm'],\n",
       " ['ggggggg'],\n",
       " ['lab', 'sentiment', 'ds'],\n",
       " ['nih', 'chest', 'x', 'ray', 'age'],\n",
       " ['datos'],\n",
       " ['starter', 'home', 'homeowner', 'vacancy', 'rate'],\n",
       " ['cyrilsantosexamtaxi'],\n",
       " ['exercise', 'strings', 'and', 'dictionaries'],\n",
       " ['analysis', 'of', 'titanic'],\n",
       " ['kekek'],\n",
       " ['social', 'network', 'ads', 'knearest', 'neighbors'],\n",
       " ['severstal', 'steel', 'defect', 'detection', 'seg', 'only'],\n",
       " ['fastaiberttrainbaseline'],\n",
       " ['suicide', 'data', 'exploration', 'and', 'analysis'],\n",
       " ['guia', 'taller', 'analisis', 'de', 'datos', 'con', 'python'],\n",
       " ['summarizer'],\n",
       " ['mnist', 'from', 'data', 'visualization', 'to', 'submission'],\n",
       " ['mytesta'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['demoyelpsentimentanalysis'],\n",
       " ['multihardaug'],\n",
       " ['resnet', 'from', 'scratch', 'pytorch', 'lb'],\n",
       " ['starter', 'poverty', 'universe', 'all', 'ages'],\n",
       " ['starter', 'googlelandmarks', 'dataset'],\n",
       " ['ieeecis', 'fraud', 'detection'],\n",
       " ['exerciciosalaavaliacaopoliticaspublicas'],\n",
       " ['kodryan', 'mmp', 'msu', 'gacrp', 'my', 'best'],\n",
       " ['data', 'visualizations', 'iris', 'dataset'],\n",
       " ['mas', 'image', 'segmentation'],\n",
       " ['facebookcheckin'],\n",
       " ['naivebayersbow', 'kernel'],\n",
       " ['pandas', 'exercises'],\n",
       " ['hands', 'on', 'machine', 'learning', 'with', 'python'],\n",
       " ['ministdigitrecognitioncnn'],\n",
       " ['uberdecisiontree'],\n",
       " ['lightgbm', 'with', 'weighted', 'averages', 'dropout'],\n",
       " ['ieee', 'fraud', 'new', 'features', 'export', 'lb'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['collab', 'comp', 'ninth', 'try'],\n",
       " ['rekagglefavoritatimeseriesfeatureengineering'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['keras', 'around'],\n",
       " ['natural', 'language', 'processing', 'nlp', 'project'],\n",
       " ['simple', 'cnn', 'for', 'kannada', 'classification'],\n",
       " ['scriptfbtest'],\n",
       " ['custumer', 'satisfaction', 'prediction', 'classification'],\n",
       " ['public', 'sem', 'machine', 'learning'],\n",
       " ['modified'],\n",
       " ['avian', 'project', 'aap'],\n",
       " ['ugatit'],\n",
       " ['digit', 'recognizer', 'mnist'],\n",
       " ['data', 'science', 'best', 'practices'],\n",
       " ['day', 'getting', 'started', 'with', 'python'],\n",
       " ['house', 'prices', 'regression'],\n",
       " ['pspnet'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['extensive', 'data', 'exploration', 'modelling', 'python'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['starter', 'world', 'bank', 'quarterly', 'external'],\n",
       " ['how', 'good', 'does', 'your', 'chocolate', 'taste'],\n",
       " ['keras', 'cnn', 'whale', 'detection', 'beginner', 'level'],\n",
       " ['hpart'],\n",
       " ['titanic', 'survival', 'prediction', 'decision', 'tree'],\n",
       " ['very', 'simple', 'nn', 'in', 'pytorch', 'with', 'sparsetensor'],\n",
       " ['corvus', 'part', 'using', 'keras', 'neural', 'networks'],\n",
       " ['exploratory'],\n",
       " ['titanic', 'decisiontreeclassifier'],\n",
       " ['fastai', 'lesson', 'horses', 'by', 'color', 'breed'],\n",
       " ['predictfuturemonthlysaleswithprophet'],\n",
       " ['first'],\n",
       " ['to', 'the', 'top'],\n",
       " ['cactus', 'detection'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['trabalho'],\n",
       " ['bag', 'of', 'words'],\n",
       " ['starter', 'malaria', 'cell', 'images', 'dataset'],\n",
       " ['notebook'],\n",
       " ['world', 'happiness', 'index'],\n",
       " ['saleprice', 'prediction'],\n",
       " ['template', 'notebook'],\n",
       " ['housing', 'prices'],\n",
       " ['rm'],\n",
       " ['with', 'xgboost', 'in', 'r'],\n",
       " ['wlblackjackclean'],\n",
       " ['exploringandsomebaselinemodels'],\n",
       " ['predict', 'future', 'sales'],\n",
       " ['russian', 'troll', 'tweets', 'what', 'why', 'when'],\n",
       " ['final', 'submission'],\n",
       " ['compresserator'],\n",
       " ['springleaf', 'competition', 'eda', 'second', 'attempt'],\n",
       " ['merge', 'datasets'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['titanicmy', 'first', 'submission'],\n",
       " ['python', 'exercise', 'functions', 'and', 'getting', 'help'],\n",
       " ['bigquery', 'workflow'],\n",
       " ['aibnb', 'challenge'],\n",
       " ['pokemon', 'gan'],\n",
       " ['digitrecognizer'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['machine', 'learning', 'digitrecognizer'],\n",
       " ['keras', 'nn', 'mixup'],\n",
       " ['digit', 'recognition', 'from', 'scratch'],\n",
       " ['machinehack', 'predict', 'food', 'prices'],\n",
       " ['two', 'sigma', 'competition'],\n",
       " ['santander', 'starter', 'eda'],\n",
       " ['analysis', 'of', 'flight', 'delay'],\n",
       " ['catboost'],\n",
       " ['predicthouseprices'],\n",
       " ['data', 'visualization', 'with', 'happiness', 'data'],\n",
       " ['car', 'noise', 'data'],\n",
       " ['kannada', 'mnist', 'competition'],\n",
       " ['youtube', 'video', 'trending', 'days', 'in', 'english', 'countries'],\n",
       " ['exercise', 'working', 'with', 'external', 'libraries'],\n",
       " ['starter', 'paris', 'metro', 'line'],\n",
       " ['kerasdrnpspnet'],\n",
       " ['qsscode'],\n",
       " ['advanced', 'uses', 'of', 'shap', 'values'],\n",
       " ['starter', 'wapodea', 'mi', 'opioid', 'data'],\n",
       " ['turkeychild'],\n",
       " ['dog', 'vs', 'cat', 'classification', 'cnn', 'approximation'],\n",
       " ['taming', 'the', 'bert', 'a', 'baseline'],\n",
       " ['template', 'aula', 'exercicio'],\n",
       " ['scraping', 'sports', 'data', 'with', 'r'],\n",
       " ['forest', 'cover', 'stacking', 'multiple', 'classifiers'],\n",
       " ['sfo', 'crime', 'multi', 'class', 'algorithms'],\n",
       " ['starter'],\n",
       " ['cnn', 'ngram'],\n",
       " ['smile', 'parental', 'recognizing'],\n",
       " ['mnist', 'simple', 'cnn', 'with', 'keras'],\n",
       " ['starter', 'heart', 'disease', 'uci'],\n",
       " ['nyairbnb'],\n",
       " ['blender', 'of', 'solutions'],\n",
       " ['library'],\n",
       " ['dont', 'overfit'],\n",
       " ['wow', 'auction', 'db', 'lua', 'parser'],\n",
       " ['machine', 'learning', 'models', 'demonstration'],\n",
       " ['pytorch', 'data', 'loader', 'code'],\n",
       " ['first', 'submission'],\n",
       " ['testing'],\n",
       " ['lithuania', 'temperature', 'change'],\n",
       " ['my', 'notebook'],\n",
       " ['lakshh'],\n",
       " ['categoricalfeatureengineeringxgb'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['minivggnet', 'for'],\n",
       " ['how', 'to', 'impute', 'missing', 'values'],\n",
       " ['report', 'on', 'project', 'work', 'test', 'rib', 'masks'],\n",
       " ['kmeans'],\n",
       " ['how', 'models', 'work'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['kagglers', 'the', 'gender', 'story', 'a', 'survey'],\n",
       " ['is', 'that', 'a', 'dog', 'or', 'a', 'cat', 'acc'],\n",
       " ['lasttit'],\n",
       " ['starter', 'gas', 'prices', 'in', 'brazil'],\n",
       " ['test', 'waves', 'data'],\n",
       " ['firstattempt'],\n",
       " ['cookingprediction'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['world', 'happiness', 'report'],\n",
       " ['whose', 'turnover', 'it', 'is'],\n",
       " ['a', 'step', 'by', 'step', 'guide', 'to', 'image', 'segmentation'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['titanic', 'feature', 'engineering'],\n",
       " ['are', 'you', 'gonna', 'eat', 'there', 'sf', 'health', 'violations'],\n",
       " ['appstore', 'application', 'exploration'],\n",
       " ['fast', 'lags', 'calculation', 'using', 'numpy', 'arrays'],\n",
       " ['eda', 'analysis'],\n",
       " ['group'],\n",
       " ['random', 'forest', 'script'],\n",
       " ['severstal', 'classification', 'pytorch'],\n",
       " ['youtube', 'trending', 'videos', 'interactive', 'eda'],\n",
       " ['santandar'],\n",
       " ['time', 'series', 'garch', 'ts', 'regression'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['toxic', 'comment', 'classification', 'using', 'bert'],\n",
       " ['ryzhstaralsya'],\n",
       " ['data', 'visualization', 'for', 'beginners'],\n",
       " ['ml', 'month', 'models', 'ensemble', 'inference'],\n",
       " ['deepdream', 'as', 'in', 'keras', 'book'],\n",
       " ['time', 'decay'],\n",
       " ['bike', 'sharing', 'prediction'],\n",
       " ['fork', 'of', 'realestate'],\n",
       " ['starter', 'noaa', 'severe', 'weather', 'data'],\n",
       " ['data', 'analysis'],\n",
       " ['land', 'cover', 'classification', 'keras', 'densenet'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['power', 'line', 'fault', 'detection', 'create', 'model'],\n",
       " ['after', 'greta'],\n",
       " ['biggan', 'aaronleong'],\n",
       " ['prime', 'sieves'],\n",
       " ['insincere', 'questions', 'eda', 'understanding'],\n",
       " ['fork', 'of', 'fork', 'of', 'fork', 'of', 'fork', 'of', 'fork', 'of', 'for'],\n",
       " ['datasciencebowlfastcompactsolution'],\n",
       " ['demo', 'xception', 'and', 'dense'],\n",
       " ['titanic', 'with', 'random', 'forest'],\n",
       " ['anomaly', 'detectionassignds'],\n",
       " ['blacktotransparent', 'rgba'],\n",
       " ['deconvnet'],\n",
       " ['titanic', 'a', 'complete', 'beginners', 'guide'],\n",
       " ['feature', 'generation', 'using', 'time', 'series', 'stats'],\n",
       " ['analysis', 'of', 'world', 'crime'],\n",
       " ['house', 'pricing'],\n",
       " ['eda', 'windowing', 'allowed', 'per', 'rules'],\n",
       " ['data', 'visualization'],\n",
       " ['nick', 'third', 'week', 'benchmark'],\n",
       " ['nyc', 'cab', 'xgb'],\n",
       " ['pubgs', 'kernel'],\n",
       " ['patchgan'],\n",
       " ['credit', 'card', 'fraud', 'detection', 'verisinin', 'incelenmesi'],\n",
       " ['sklearntest'],\n",
       " ['bokeh', 'visualization'],\n",
       " ['notebook'],\n",
       " ['new', 'in', 'kaggle', 'eda', 'step', 'by', 'step'],\n",
       " ['breast', 'cancer', 'diagnosis', 'with', 'lr'],\n",
       " ['kerneldigit', 'recognizer'],\n",
       " ['song', 'recom'],\n",
       " ['ashrae', 'cv', 'options'],\n",
       " ['ibm', 'attrition', 'prediction', 'using', 'logistic', 'regression'],\n",
       " ['lets', 'classify', 'dog', 'breeds'],\n",
       " ['santander', 'simple', 'dnn'],\n",
       " ['sfv', 'characters', 'analysis'],\n",
       " ['brunokernel'],\n",
       " ['exp', 'kaggle'],\n",
       " ['oneshot', 'method', 'to', 'tackle', 'kinship', 'problem', 'keras'],\n",
       " ['starter', 'modelsecond'],\n",
       " ['are', 'you', 'a', 'real', 'painter'],\n",
       " ['wombat', 'inference', 'kernel'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['baselinevggnet'],\n",
       " ['lda', 'topics'],\n",
       " ['dont', 'overfit'],\n",
       " ['ieee', 'internal', 'blend'],\n",
       " ['starter', 'eleicoes'],\n",
       " ['fraudster'],\n",
       " ['forest', 'classification', 'kernelanindaxgboost'],\n",
       " ['plotly', 'hk'],\n",
       " ['rfxgboosttrial'],\n",
       " ['violent', 'crime', 'prediction', 'using', 'rf'],\n",
       " ['wordcloud'],\n",
       " ['meta', 'kaggle', 'what', 'happened', 'to', 'the', 'team', 'size'],\n",
       " ['credit', 'card', 'fraud', 'detection'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['pets', 'adoption', 'simple', 'pandas', 'random', 'forest'],\n",
       " ['deepartist', 'identify', 'artist', 'from', 'art'],\n",
       " ['bhujithbikesharekernel'],\n",
       " ['fashioncategoryidentification'],\n",
       " ['titanic', 'is', 'sinking'],\n",
       " ['python', 'lgb', 'baseline'],\n",
       " ['multiplelinear', 'regression', 'fish', 'weight', 'estimation'],\n",
       " ['heart'],\n",
       " ['dog', 'vs', 'cat', 'classifier'],\n",
       " ['kannnadamnisttest'],\n",
       " ['santander', 'dealing', 'with', 'imbalanced', 'data'],\n",
       " ['la', 'metro', 'bike', 'share'],\n",
       " ['my', 'first', 'practice'],\n",
       " ['project', 'euler', 'not', 'the', 'dataset'],\n",
       " ['starter', 'lunarrock'],\n",
       " ['churnpredictiondecisontree'],\n",
       " ['random', 'forest', 'regressor'],\n",
       " ['matplotlib', 'tutorial', 'for', 'beginners'],\n",
       " ['global', 'terrorism', 'storytelling'],\n",
       " ['tweet', 'classification', 'using', 'awdlstm'],\n",
       " ['house', 'pricing', 'fastai'],\n",
       " ['first', 'exploration'],\n",
       " ['twitter', 'sentiment', 'analysis'],\n",
       " ['exercise', 'model', 'validation'],\n",
       " ['stripped', 'down', 'code'],\n",
       " ['starter', 'part'],\n",
       " ['taller', 'en', 'moldeamiento', 'series', 'de', 'tiempo'],\n",
       " ['web', 'scrapping'],\n",
       " ['kuzushiji', 'visualisation'],\n",
       " ['health', 'data'],\n",
       " ['microsoft', 'malware', 'detection', 'xgboost', 'tuning'],\n",
       " ['eda', 'in', 'crime', 'of', 'rape', 'in', 'india'],\n",
       " ['layer', 'neural', 'network', 'for', 'graduate', 'admissionshw'],\n",
       " ['dashboarding'],\n",
       " ['elo', 'competition'],\n",
       " ['catsdogsclassifiation'],\n",
       " ['exploring', 'random', 'forest', 'on', 'a', 'grid'],\n",
       " ['in', 'a', 'few', 'lines', 'of', 'code'],\n",
       " ['btnotebook'],\n",
       " ['advanced', 'feature', 'exploration'],\n",
       " ['svd', 'pca', 'and', 'tsne', 'simple', 'explanation'],\n",
       " ['zomato', 'ratings'],\n",
       " ['first', 'competition'],\n",
       " ['actividad', 'modelo', 'de', 'propension', 'al', 'churn'],\n",
       " ['world', 'happiness', 'report', 'my', 'first', 'project'],\n",
       " ['digitsnotebook'],\n",
       " ['starbucks', 'in', 'world', 'countries', 'with', 'india'],\n",
       " ['titanicsurvivedrandomforest'],\n",
       " ['analyzing', 'the', 'graduate', 'admission', 'eda', 'ml'],\n",
       " ['trial', 'script'],\n",
       " ['graduate', 'admissions', 'data', 'prediction', 'model'],\n",
       " ['starter', 'parking', 'garage', 'data'],\n",
       " ['airbus', 'ship', 'detection', 'yet', 'another', 'eda'],\n",
       " ['facebook', 'competition'],\n",
       " ['sklearn', 'pipeline', 'playground', 'for', 'classifiers'],\n",
       " ['eda', 'modeling', 'post', 'models', 'analysis', 'are', 'ongoing'],\n",
       " ['pytorch', 'baseline', 'updated'],\n",
       " ['pytorch', 'fastai', 'top', 'or', 'good', 'results'],\n",
       " ['advanced', 'prediction', 'of', 'ames', 'house', 'prices'],\n",
       " ['data', 'cleaning', 'challenge', 'character', 'encodings'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['youtubeprediction'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['picnichack'],\n",
       " ['eda', 'for', 'crime', 'data'],\n",
       " ['exoplanetsnotebook'],\n",
       " ['housing', 'price', 'predictions'],\n",
       " ['tensorflow'],\n",
       " ['facebook', 'comment', 'dataset'],\n",
       " ['data', 'mining'],\n",
       " ['gazing', 'into', 'the', 'data', 'abyss', 'time', 'series', 'analysis'],\n",
       " ['book', 'recommendation'],\n",
       " ['foresttypes'],\n",
       " ['exercise', 'categorical', 'variables'],\n",
       " ['lstm', 'for', 'personality', 'binary', 'classification'],\n",
       " ['classification', 'for', 'bank', 'data'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['starter', 'medina', 'municipality', 'dataset'],\n",
       " ['localetask'],\n",
       " ['santander', 'customer', 'transaction', 'prediction'],\n",
       " ['learn', 'python', 'for', 'data', 'science'],\n",
       " ['enem', 'eda'],\n",
       " ['house', 'prices'],\n",
       " ['lesson'],\n",
       " ['club', 'mahindra', 'all', 'models'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['larger', 'parts'],\n",
       " ['xgb', 'features'],\n",
       " ['iris', 'species', 'homework'],\n",
       " ['starter', 'dataset', 'no', 'longer', 'available'],\n",
       " ['house', 'prices', 'advanced', 'regression', 'techniques'],\n",
       " ['transfer', 'learning', 'in', 'nlp'],\n",
       " ['the', 'halloween', 'frankencandy', 'generator'],\n",
       " ['nlunotebook'],\n",
       " ['aplicacoes', 'em', 'nlp', 'aula'],\n",
       " ['fifa'],\n",
       " ['fraud', 'detection'],\n",
       " ['kerneltitanic'],\n",
       " ['tuning', 'an', 'extratreesclassifier', 'with', 'gridserachcv'],\n",
       " ['eda', 'feature', 'eng', 'lgbgpu', 'cbgpu', 'ranking'],\n",
       " ['pytorch', 'cnn', 'sixth', 'generation'],\n",
       " ['pubgplacementpredictiontapan'],\n",
       " ['fashion', 'class', 'classification'],\n",
       " ['starter', 'hostel'],\n",
       " ['blindness', 'detection', 'with'],\n",
       " ['aerial', 'cactus', 'identification', 'keras'],\n",
       " ['starter'],\n",
       " ['starter', 'denver', 'crime', 'data'],\n",
       " ['comb', 'of', 'thresholdmask'],\n",
       " ['bert', 'lstm', 'rank', 'blender'],\n",
       " ['pipeline', 'boosting'],\n",
       " ['introduction', 'to', 'vsb', 'kaggle', 'competition'],\n",
       " ['ft'],\n",
       " ['beginner', 'kernel'],\n",
       " ['ibm', 'attrition', 'prediction', 'with', 'ensemble', 'classifier'],\n",
       " ['dataaugmentation', 'for', 'object', 'localization'],\n",
       " ['pixel', 'mean', 'and', 'variances', 'by', 'digit'],\n",
       " ['principal', 'component', 'analysis', 'with', 'scikitlearn'],\n",
       " ['imu', 'sensor', 'data', 'exploration'],\n",
       " ['numpy', 'scipy', 'and', 'pandas', 'for', 'dummy', 'data', 'scientists'],\n",
       " ['exploring', 'jupyter', 'notebook', 'survey', 'data'],\n",
       " ['load', 'gap', 'coreference', 'data'],\n",
       " ['image', 'to', 'image', 'translation'],\n",
       " ['glove', 'xgboost', 'and', 'lgbm'],\n",
       " ['basic', 'eda', 'data', 'visualization'],\n",
       " ['malaria', 'detection'],\n",
       " ['starter', 'virginia', 'lamb', 'auction'],\n",
       " ['beginner'],\n",
       " ['titanic', 'top', 'with', 'xgboost'],\n",
       " ['houseprize'],\n",
       " ['select', 'from', 'where'],\n",
       " ['memorizing', 'anime', 'face', 'generator'],\n",
       " ['glazy', 'recipes', 'eda'],\n",
       " ['testjust'],\n",
       " ['extra', 'trees'],\n",
       " ['nyc', 'taxi', 'speed'],\n",
       " ['regression', 'tutorial'],\n",
       " ['vicyclekagglepy'],\n",
       " ['starter', 'data', 'on', 'statistical', 'capacity'],\n",
       " ['titanic', 'data', 'analysis'],\n",
       " ['france', 'youtube', 'analysis', 'homework', 'i'],\n",
       " ['myutilitymethods'],\n",
       " ['catdog', 'image', 'classification'],\n",
       " ['simple', 'xgb'],\n",
       " ['tutorial', 'cnn', 'partie', 'mnist', 'digits', 'classification'],\n",
       " ['with', 'rf', 'and', 'log', 'transformation'],\n",
       " ['competition'],\n",
       " ['light', 'gbm'],\n",
       " ['mobileappsappstore'],\n",
       " ['tmubaseline'],\n",
       " ['from', 'csv', 'machine', 'learning', 'training'],\n",
       " ['et'],\n",
       " ['python', 'learning', 'course', 'lesson'],\n",
       " ['yolo', 'notebook'],\n",
       " ['starter', 'gdpkorea'],\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5367b",
   "metadata": {},
   "source": [
    "### creating the word2vec embedding:\n",
    "\n",
    "Parameters: -\n",
    "sentences : The sentences we have obtained.\n",
    "\n",
    "size : The dimesnions of the vector used to represent each word.\n",
    "\n",
    "window : The number f words around any word to see the context.\n",
    "\n",
    "min_count : The minimum number of times a word should appear for its embedding to be formed or learnt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae519bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(sentences, vector_size=300, min_count = 1, window = 5)\n",
    "# w2v_model = gensim.models.Word2Vec(sentences = sentences , size = 300 , window = 10 , min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "576ce5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2309149, 2820900)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences , epochs = 50 , total_examples = len(sentences))\n",
    "# w2v_model.train(sentences,epochs=10,total_examples=len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5611ee67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15798843,  0.21935408,  0.03068349, -0.05999136,  0.04240653,\n",
       "       -0.53834546,  0.09324706,  0.57666725, -0.27672127, -0.11445758,\n",
       "        0.01677991, -0.23329471,  0.1536648 , -0.23509541, -0.20869917,\n",
       "       -0.30196512, -0.21237867, -0.24192287, -0.16210668, -0.00690482,\n",
       "       -0.27077347,  0.12946583, -0.08028858,  0.45723248, -0.05238968,\n",
       "        0.04554238, -0.16550048,  0.08760434, -0.2608805 , -0.22377014,\n",
       "        0.50491405, -0.34574693, -0.1921431 ,  0.28526577,  0.01408657,\n",
       "        0.3188401 ,  0.54520637, -0.34843132,  0.02665604, -0.5258385 ,\n",
       "        0.05637809, -0.14641109,  0.11171195, -0.20692655,  0.07535383,\n",
       "        0.35244384,  0.11195425,  0.1315868 , -0.283105  ,  0.45671287,\n",
       "        0.4818425 , -0.02301351,  0.3158965 , -0.10492869,  0.04071322,\n",
       "        0.5034987 ,  0.20907001,  0.08977146,  0.17509218,  0.25822547,\n",
       "       -0.5492994 , -0.35033292, -0.1023135 ,  0.18069942,  0.2961827 ,\n",
       "       -0.02922895,  0.36184514,  0.08493043, -0.00742134, -0.27619028,\n",
       "       -0.01173875,  0.26748106,  0.49928993, -0.11711235, -0.21545109,\n",
       "        0.24542196, -0.22040278,  0.23137307,  0.05656163, -0.02961917,\n",
       "       -0.17869608, -0.17473488,  0.08337236,  0.58966285,  0.08071575,\n",
       "        0.40204245, -0.07011812,  0.09026647,  0.1251953 ,  0.3955935 ,\n",
       "       -0.2614636 ,  0.3101341 ,  0.17905633,  0.52017295,  0.2803983 ,\n",
       "       -0.06511031,  0.08793346, -0.03994311, -0.16830344, -0.33893543,\n",
       "       -0.18077901, -0.0436961 ,  0.05433185, -0.32763442,  0.54168445,\n",
       "       -0.11216424, -0.03195066, -0.00439063,  0.24687943,  0.20415187,\n",
       "       -0.48925084,  0.06187681, -0.38023102,  0.27020532,  0.26808578,\n",
       "        0.10395522, -0.12064856,  0.19649455,  0.26268265, -0.22707964,\n",
       "       -0.02552322,  0.47620344,  0.05667229, -0.40306118, -0.27047926,\n",
       "        0.07355431,  0.11381481, -0.32473734,  0.04630833, -0.15582824,\n",
       "        0.16359587,  0.29267132,  0.5120044 , -0.24641094,  0.4834009 ,\n",
       "        0.243226  , -0.20391564,  0.14684911, -0.14836952,  0.0602611 ,\n",
       "        0.16590084, -0.22940992,  0.56459683, -0.33036458, -0.05908319,\n",
       "        0.11619511, -0.2772614 ,  0.09258623,  0.09277026, -0.0879702 ,\n",
       "       -0.01338965, -0.34994084, -0.17964906, -0.13504684, -0.19536197,\n",
       "        0.07674919, -0.00926312, -0.00557434, -0.32532775,  0.38432407,\n",
       "        0.2180442 ,  0.42566958, -0.35928774,  0.81049335, -0.03954587,\n",
       "        0.0800254 , -0.26811764, -0.00435041,  0.18544988, -0.09391133,\n",
       "       -0.02146181, -0.00143719,  0.12671335,  0.04462269, -0.10268624,\n",
       "       -0.07804147,  0.2521187 , -0.06870556,  0.4117458 ,  0.36533812,\n",
       "        0.11238226, -0.18839355, -0.4070856 , -0.29732537, -0.17568511,\n",
       "        0.19558701,  0.13594833,  0.20899783, -0.04334577, -0.40354738,\n",
       "        0.05125596, -0.21102999, -0.41820142,  0.06196758,  0.4058768 ,\n",
       "        0.13211624, -0.02349293, -0.23692398,  0.07109541,  0.44911093,\n",
       "       -0.26536438,  0.08167969,  0.4986575 , -0.5666527 ,  0.16309553,\n",
       "       -0.09263644,  0.01856619, -0.16383836, -0.04614298, -0.06711818,\n",
       "       -0.01059701, -0.08545814, -0.28533348, -0.2040329 ,  0.1970898 ,\n",
       "       -0.08735926, -0.40835747, -0.37720773, -0.08798148, -0.25671646,\n",
       "        0.7062337 ,  0.4489854 , -0.00244034,  0.09726764, -0.28961426,\n",
       "        0.12672262,  0.17506057, -0.0893952 , -0.13345005,  0.38149077,\n",
       "        0.2601951 ,  0.00801416, -0.27936292,  0.08175038, -0.26722726,\n",
       "        0.06003414,  0.110621  ,  0.37221515,  0.31551307, -0.07232536,\n",
       "        0.26256588,  0.43011016, -0.32135585, -0.08028343, -0.19466437,\n",
       "       -0.37177572,  0.08329727,  0.01920504,  0.09935137,  0.0424921 ,\n",
       "        0.22601882,  0.2071022 ,  0.2963633 , -0.24770665, -0.08816592,\n",
       "       -0.40414852,  0.5542741 ,  0.08013622, -0.23077826, -0.11034501,\n",
       "       -0.0299758 ,  0.28055257, -0.09416015, -0.45112404, -0.02164144,\n",
       "       -0.2275687 ,  0.25458282, -0.11978128, -0.13883667,  0.03150325,\n",
       "        0.15615267, -0.17503677, -0.4117085 , -0.4605606 ,  0.36364686,\n",
       "       -0.392671  ,  0.0621381 ,  0.5231625 , -0.32277122,  0.03977792,\n",
       "        0.11129789, -0.23810865,  0.07547756,  0.01518973, -0.25559646,\n",
       "       -0.19811971, -0.25123677,  0.18252437,  0.12098876, -0.07876546,\n",
       "        0.21755989, -0.27259192,  0.47237676, -0.02356154,  0.01418093,\n",
       "        0.27310762, -0.23985465, -0.298926  ,  0.02575896, -0.14451626],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.get_vector('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1981bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words are:  10134\n"
     ]
    }
   ],
   "source": [
    "# printing the vocab , the total number of extracted words\n",
    "vocab = list(w2v_model.wv.index_to_key)\n",
    "# voacb = w2v_model.wv.vocab\n",
    "# rock_idx = model.wv.key_to_index[\"rock\"]\n",
    "print(\"The total number of words are: \" , len(vocab))\n",
    "words = w2v_model.wv.index_to_key\n",
    "keys = w2v_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "929f82f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notebook',\n",
       " 'starter',\n",
       " 'data',\n",
       " 'and',\n",
       " 'with',\n",
       " 'of',\n",
       " 'analysis',\n",
       " 'dataset',\n",
       " 'titanic',\n",
       " 'no',\n",
       " 'eda',\n",
       " 'the',\n",
       " 'longer',\n",
       " 'available',\n",
       " 'in',\n",
       " 'for',\n",
       " 'using',\n",
       " 'prediction',\n",
       " 'to',\n",
       " 'a',\n",
       " 'on',\n",
       " 'keras',\n",
       " 'simple',\n",
       " 'model',\n",
       " 'xgboost',\n",
       " 'learning',\n",
       " 'first',\n",
       " 'test',\n",
       " 'regression',\n",
       " 'r',\n",
       " 'python',\n",
       " 'cnn',\n",
       " 'classification',\n",
       " 'exploration',\n",
       " 'by',\n",
       " 'fork',\n",
       " 'parking',\n",
       " 'random',\n",
       " 'garage',\n",
       " 'forest',\n",
       " 'from',\n",
       " 'my',\n",
       " 'visualization',\n",
       " 'house',\n",
       " 'feature',\n",
       " 'detection',\n",
       " 'mnist',\n",
       " 'exploring',\n",
       " 'kernel',\n",
       " 'kaggle',\n",
       " 'machine',\n",
       " 'vs',\n",
       " 'exploratory',\n",
       " 'script',\n",
       " 'ml',\n",
       " 'tutorial',\n",
       " 'challenge',\n",
       " 'day',\n",
       " 'neural',\n",
       " 'lb',\n",
       " 'time',\n",
       " 'features',\n",
       " 'digit',\n",
       " 'predicting',\n",
       " 'network',\n",
       " 'deep',\n",
       " 'prices',\n",
       " 'logistic',\n",
       " 'tensorflow',\n",
       " 'linear',\n",
       " 'predict',\n",
       " 'pytorch',\n",
       " 'models',\n",
       " 'basic',\n",
       " 'xgb',\n",
       " 'price',\n",
       " 'exercise',\n",
       " 'world',\n",
       " 'baseline',\n",
       " 'survival',\n",
       " 'sentiment',\n",
       " 'classifier',\n",
       " 'project',\n",
       " 'testing',\n",
       " 'try',\n",
       " 'nn',\n",
       " 'top',\n",
       " 'rf',\n",
       " 'image',\n",
       " 'crime',\n",
       " 'svm',\n",
       " 'iris',\n",
       " 'benchmark',\n",
       " 'competition',\n",
       " 'knn',\n",
       " 'clustering',\n",
       " 'fraud',\n",
       " 'recognition',\n",
       " 'engineering',\n",
       " 'fastai',\n",
       " 'recognizer',\n",
       " 'is',\n",
       " 'how',\n",
       " 'solution',\n",
       " 'text',\n",
       " 'lightgbm',\n",
       " 'decision',\n",
       " 'new',\n",
       " 'series',\n",
       " 'science',\n",
       " 'cleaning',\n",
       " 'submission',\n",
       " 'tree',\n",
       " 'pca',\n",
       " 'cancer',\n",
       " 'pandas',\n",
       " 'example',\n",
       " 'lstm',\n",
       " 'beginners',\n",
       " 'code',\n",
       " 'images',\n",
       " 'part',\n",
       " 'lgbm',\n",
       " 'us',\n",
       " 'santander',\n",
       " 'at',\n",
       " 'sales',\n",
       " 'through',\n",
       " 'credit',\n",
       " 'sf',\n",
       " 'score',\n",
       " 'training',\n",
       " 'housing',\n",
       " 'naive',\n",
       " 'ensemble',\n",
       " 'nlp',\n",
       " 'map',\n",
       " 'customer',\n",
       " 'journey',\n",
       " 'approach',\n",
       " 'attempt',\n",
       " 'global',\n",
       " 'survey',\n",
       " 'accuracy',\n",
       " 'beginner',\n",
       " 'movie',\n",
       " 'predictions',\n",
       " 'sql',\n",
       " 'getting',\n",
       " 'preprocessing',\n",
       " 'final',\n",
       " 'interactive',\n",
       " 'best',\n",
       " 'introduction',\n",
       " 'dogs',\n",
       " 'most',\n",
       " 'w',\n",
       " 'set',\n",
       " 'sklearn',\n",
       " 'learn',\n",
       " 'quick',\n",
       " 'nyc',\n",
       " 'some',\n",
       " 'modeling',\n",
       " 'what',\n",
       " 'understanding',\n",
       " 'an',\n",
       " 'based',\n",
       " 'are',\n",
       " 'all',\n",
       " 'your',\n",
       " 'practice',\n",
       " 'cv',\n",
       " 'de',\n",
       " 'or',\n",
       " 'explore',\n",
       " 'analytics',\n",
       " 'taxi',\n",
       " 'selection',\n",
       " 'quora',\n",
       " 'gbm',\n",
       " 'missing',\n",
       " 'transfer',\n",
       " 'started',\n",
       " 'bank',\n",
       " 'cats',\n",
       " 'bayes',\n",
       " 'google',\n",
       " 'pubg',\n",
       " 'news',\n",
       " 'i',\n",
       " 'randomforest',\n",
       " 'home',\n",
       " 'over',\n",
       " 'nfl',\n",
       " 'seaborn',\n",
       " 'train',\n",
       " 'this',\n",
       " 'word',\n",
       " 'pokemon',\n",
       " 'sample',\n",
       " 'kiva',\n",
       " 'scavenger',\n",
       " 'hunt',\n",
       " 'scratch',\n",
       " 'intro',\n",
       " 'plotly',\n",
       " 'insights',\n",
       " 'plot',\n",
       " 'breast',\n",
       " 'gender',\n",
       " 'state',\n",
       " 'reviews',\n",
       " 'different',\n",
       " 'la',\n",
       " 'more',\n",
       " 'demo',\n",
       " 'names',\n",
       " 'india',\n",
       " 'validation',\n",
       " 'disease',\n",
       " 'problem',\n",
       " 'step',\n",
       " 'class',\n",
       " 'age',\n",
       " 'rate',\n",
       " 'crimes',\n",
       " 'guide',\n",
       " 'who',\n",
       " 'lgb',\n",
       " 'tuning',\n",
       " 'card',\n",
       " 'not',\n",
       " 'market',\n",
       " 'dashboard',\n",
       " 'visualizations',\n",
       " 'look',\n",
       " 'statistics',\n",
       " 'one',\n",
       " 'game',\n",
       " 'default',\n",
       " 'dashboarding',\n",
       " 'trying',\n",
       " 'single',\n",
       " 'stacking',\n",
       " 'basics',\n",
       " 'income',\n",
       " 'heart',\n",
       " 'study',\n",
       " 'do',\n",
       " 'just',\n",
       " 'two',\n",
       " 'lesson',\n",
       " 'churn',\n",
       " 'kmeans',\n",
       " 'analyzing',\n",
       " 'networks',\n",
       " 'wine',\n",
       " 'ai',\n",
       " 'digits',\n",
       " 'stock',\n",
       " 'visualizing',\n",
       " 'assignment',\n",
       " 'happiness',\n",
       " 'start',\n",
       " 'rnn',\n",
       " 'suicide',\n",
       " 'embeddings',\n",
       " 'ieee',\n",
       " 'lasso',\n",
       " 'unet',\n",
       " 'initial',\n",
       " 'loan',\n",
       " 'questions',\n",
       " 'segmentation',\n",
       " 'words',\n",
       " 'search',\n",
       " 'bayesian',\n",
       " 'trial',\n",
       " 'working',\n",
       " 'version',\n",
       " 'mean',\n",
       " 'disaster',\n",
       " 'job',\n",
       " 'reddit',\n",
       " 'mining',\n",
       " 'video',\n",
       " 'twitter',\n",
       " 'airbnb',\n",
       " 'number',\n",
       " 'review',\n",
       " 'elo',\n",
       " 'numpy',\n",
       " 'plots',\n",
       " 'you',\n",
       " 'another',\n",
       " 'extensive',\n",
       " 'net',\n",
       " 'bike',\n",
       " 'exercises',\n",
       " 'total',\n",
       " 'algorithms',\n",
       " 'processing',\n",
       " 'public',\n",
       " 'stats',\n",
       " 'only',\n",
       " 'week',\n",
       " 'homework',\n",
       " 'traffic',\n",
       " 'imdb',\n",
       " 'we',\n",
       " 'pipeline',\n",
       " 'fivethirtyeight',\n",
       " 'games',\n",
       " 'poverty',\n",
       " 'into',\n",
       " 'classifiers',\n",
       " 'fifa',\n",
       " 'advanced',\n",
       " 'diabetes',\n",
       " 'results',\n",
       " 'comments',\n",
       " 'recommendation',\n",
       " 'quality',\n",
       " 'detailed',\n",
       " 'method',\n",
       " 'hello',\n",
       " 'car',\n",
       " 'visualisation',\n",
       " 'convolutional',\n",
       " 'grid',\n",
       " 'group',\n",
       " 'per',\n",
       " 'lets',\n",
       " 'as',\n",
       " 'health',\n",
       " 'auc',\n",
       " 'predictor',\n",
       " 'parameter',\n",
       " 'dog',\n",
       " 'get',\n",
       " 'terrorism',\n",
       " 'performance',\n",
       " 'hr',\n",
       " 'forecasting',\n",
       " 'real',\n",
       " 'can',\n",
       " 'comparison',\n",
       " 'oecd',\n",
       " 'players',\n",
       " 'dont',\n",
       " 'ridge',\n",
       " 'sigma',\n",
       " 'run',\n",
       " 'files',\n",
       " 'generation',\n",
       " 'gradient',\n",
       " 'city',\n",
       " 'it',\n",
       " 'values',\n",
       " 'language',\n",
       " 'optimization',\n",
       " 'type',\n",
       " 'punt',\n",
       " 'average',\n",
       " 'change',\n",
       " 'trees',\n",
       " 'good',\n",
       " 'apps',\n",
       " 'toxic',\n",
       " 'use',\n",
       " 'augmentation',\n",
       " 'algorithm',\n",
       " 'cost',\n",
       " 'catboost',\n",
       " 'draft',\n",
       " 'transaction',\n",
       " 'second',\n",
       " 'year',\n",
       " 'report',\n",
       " 'san',\n",
       " 'aptos',\n",
       " 'datasets',\n",
       " 'check',\n",
       " 'scikitlearn',\n",
       " 'baby',\n",
       " 'play',\n",
       " 'importance',\n",
       " 'plotting',\n",
       " 'salary',\n",
       " 'workbook',\n",
       " 'implementation',\n",
       " 'mlp',\n",
       " 'insurance',\n",
       " 'youtube',\n",
       " 'overview',\n",
       " 'fare',\n",
       " 'distribution',\n",
       " 'country',\n",
       " 'list',\n",
       " 'police',\n",
       " 'v',\n",
       " 'handling',\n",
       " 'boosting',\n",
       " 'me',\n",
       " 'insincere',\n",
       " 'stack',\n",
       " 'revenue',\n",
       " 'out',\n",
       " 'spam',\n",
       " 'end',\n",
       " 'name',\n",
       " 'stackoverflow',\n",
       " 'work',\n",
       " 'support',\n",
       " 'bigquery',\n",
       " 'find',\n",
       " 'complete',\n",
       " 'full',\n",
       " 'modelling',\n",
       " 'lr',\n",
       " 'categorical',\n",
       " 'building',\n",
       " 'trabalho',\n",
       " 'cluster',\n",
       " 'user',\n",
       " 'countries',\n",
       " 'store',\n",
       " 'cooking',\n",
       " 'risk',\n",
       " 'lasagne',\n",
       " 'light',\n",
       " 'food',\n",
       " 'gan',\n",
       " 'team',\n",
       " 'bert',\n",
       " 'club',\n",
       " 'financial',\n",
       " 'heatmap',\n",
       " 'evaluation',\n",
       " 'load',\n",
       " 'temperature',\n",
       " 'easy',\n",
       " 'resnet',\n",
       " 'variables',\n",
       " 'identification',\n",
       " 'forests',\n",
       " 'nba',\n",
       " 'attacks',\n",
       " 'median',\n",
       " 'leaf',\n",
       " 'system',\n",
       " 'playground',\n",
       " 'facebook',\n",
       " 'indian',\n",
       " 'trends',\n",
       " 'usa',\n",
       " 'airline',\n",
       " 'used',\n",
       " 'talkingdata',\n",
       " 'embedding',\n",
       " 'whale',\n",
       " 'wordcloud',\n",
       " 'ranking',\n",
       " 'dnn',\n",
       " 'fast',\n",
       " 'tsne',\n",
       " 'flower',\n",
       " 'statistical',\n",
       " 'techniques',\n",
       " 'energy',\n",
       " 'population',\n",
       " 'demand',\n",
       " 'chicago',\n",
       " 'users',\n",
       " 'comprehensive',\n",
       " 'popular',\n",
       " 'value',\n",
       " 'up',\n",
       " 'playing',\n",
       " 'which',\n",
       " 'go',\n",
       " 'donorschoose',\n",
       " 'types',\n",
       " 'level',\n",
       " 'university',\n",
       " 'why',\n",
       " 'tweets',\n",
       " 'log',\n",
       " 'functions',\n",
       " 'fe',\n",
       " 'restaurant',\n",
       " 'overfit',\n",
       " 'medical',\n",
       " 'correlation',\n",
       " 'product',\n",
       " 'julia',\n",
       " 'maps',\n",
       " 'classifying',\n",
       " 'kickstarter',\n",
       " 'pricing',\n",
       " 'big',\n",
       " 'without',\n",
       " 'predictive',\n",
       " 'convnet',\n",
       " 'red',\n",
       " 'kobe',\n",
       " 'ii',\n",
       " 'object',\n",
       " 'forecast',\n",
       " 'classify',\n",
       " 'ipl',\n",
       " 'states',\n",
       " 'encoding',\n",
       " 'open',\n",
       " 'earthquake',\n",
       " 'graph',\n",
       " 'matrix',\n",
       " 'salaries',\n",
       " 'reading',\n",
       " 'census',\n",
       " 'modified',\n",
       " 'francisco',\n",
       " 'creating',\n",
       " 'player',\n",
       " 'animation',\n",
       " 'around',\n",
       " 'automl',\n",
       " 'when',\n",
       " 'graduate',\n",
       " 'generator',\n",
       " 'question',\n",
       " 'visualize',\n",
       " 'daily',\n",
       " 'between',\n",
       " 'lending',\n",
       " 'animal',\n",
       " 'finding',\n",
       " 'malware',\n",
       " 'programming',\n",
       " 'starting',\n",
       " 'template',\n",
       " 'very',\n",
       " 'attention',\n",
       " 'where',\n",
       " 'star',\n",
       " 'years',\n",
       " 'fashion',\n",
       " 'vector',\n",
       " 'database',\n",
       " 'instacart',\n",
       " 'about',\n",
       " 'topic',\n",
       " 'solutions',\n",
       " 'ds',\n",
       " 'tfidf',\n",
       " 'index',\n",
       " 'rankings',\n",
       " 'count',\n",
       " 'shot',\n",
       " 'ny',\n",
       " 'be',\n",
       " 'chest',\n",
       " 'reg',\n",
       " 'sparse',\n",
       " 'whats',\n",
       " 'voice',\n",
       " 'boost',\n",
       " 'attrition',\n",
       " 'detecting',\n",
       " 'speed',\n",
       " 'autoencoder',\n",
       " 'notebooks',\n",
       " 'weather',\n",
       " 'course',\n",
       " 'college',\n",
       " 'hyperparameter',\n",
       " 'unsupervised',\n",
       " 'progress',\n",
       " 'summary',\n",
       " 'trip',\n",
       " 'k',\n",
       " 'species',\n",
       " 'our',\n",
       " 'last',\n",
       " 'cloud',\n",
       " 'costa',\n",
       " 'vehicle',\n",
       " 'location',\n",
       " 'student',\n",
       " 'aula',\n",
       " 'workshop',\n",
       " 'plant',\n",
       " 'similarity',\n",
       " 'air',\n",
       " 'gpu',\n",
       " 'lda',\n",
       " 'kannada',\n",
       " 'reduction',\n",
       " 'bimbo',\n",
       " 'rates',\n",
       " 'future',\n",
       " 'table',\n",
       " 'primary',\n",
       " 'consumption',\n",
       " 'private',\n",
       " 'experiment',\n",
       " 'debate',\n",
       " 'severstal',\n",
       " 'writing',\n",
       " 'scores',\n",
       " 'recommender',\n",
       " 'package',\n",
       " 'external',\n",
       " 'cat',\n",
       " 'split',\n",
       " 'numbers',\n",
       " 'does',\n",
       " 'base',\n",
       " 'bag',\n",
       " 'layer',\n",
       " 'multiple',\n",
       " 'stacked',\n",
       " 'place',\n",
       " 'parameters',\n",
       " 'beating',\n",
       " 'education',\n",
       " 'loading',\n",
       " 'deaths',\n",
       " 'cactus',\n",
       " 'xray',\n",
       " 'comment',\n",
       " 'gaussian',\n",
       " 'csv',\n",
       " 'better',\n",
       " 'face',\n",
       " 'loans',\n",
       " 'porto',\n",
       " 'low',\n",
       " 'people',\n",
       " 'making',\n",
       " 'densenet',\n",
       " 'household',\n",
       " 'sqlite',\n",
       " 'pima',\n",
       " 'title',\n",
       " 'cell',\n",
       " 'area',\n",
       " 'malaria',\n",
       " 'english',\n",
       " 'paris',\n",
       " 'bitcoin',\n",
       " 'dr',\n",
       " 'tests',\n",
       " 'bias',\n",
       " 'uci',\n",
       " 'that',\n",
       " 'policy',\n",
       " 'proyecto',\n",
       " 'climate',\n",
       " 'genetic',\n",
       " 'outliers',\n",
       " 'custom',\n",
       " 'costs',\n",
       " 'cover',\n",
       " 'handwritten',\n",
       " 'methods',\n",
       " 'accidents',\n",
       " 'arima',\n",
       " 'overflow',\n",
       " 'iowa',\n",
       " 'early',\n",
       " 'black',\n",
       " 'inference',\n",
       " 'collisions',\n",
       " 'meta',\n",
       " 'products',\n",
       " 'weighted',\n",
       " 'blindness',\n",
       " 'output',\n",
       " 'magic',\n",
       " 'history',\n",
       " 'cs',\n",
       " 'various',\n",
       " 'visualisations',\n",
       " 'should',\n",
       " 'consumer',\n",
       " 'yet',\n",
       " 'death',\n",
       " 'trade',\n",
       " 'month',\n",
       " 'expedia',\n",
       " 'students',\n",
       " 'ashrae',\n",
       " 'box',\n",
       " 'ann',\n",
       " 'family',\n",
       " 'labels',\n",
       " 'temp',\n",
       " 'admission',\n",
       " 'passnyc',\n",
       " 'football',\n",
       " 'leaderboard',\n",
       " 'xgbooost',\n",
       " 'overfitting',\n",
       " 'fasttext',\n",
       " 'updated',\n",
       " 'nltk',\n",
       " 'activity',\n",
       " 'regressor',\n",
       " 'way',\n",
       " 'api',\n",
       " 'file',\n",
       " 'seattle',\n",
       " 'descent',\n",
       " 'zomato',\n",
       " 'york',\n",
       " 'digitrecognizer',\n",
       " 'outcome',\n",
       " 'via',\n",
       " 'fake',\n",
       " 'pretrained',\n",
       " 'viz',\n",
       " 'hotel',\n",
       " 'adversarial',\n",
       " 'flatline',\n",
       " 'telco',\n",
       " 'line',\n",
       " 'help',\n",
       " 'have',\n",
       " 'columns',\n",
       " 'correlations',\n",
       " 'survivors',\n",
       " 'ibm',\n",
       " 'scripts',\n",
       " 'yelp',\n",
       " 'business',\n",
       " 'amazon',\n",
       " 'other',\n",
       " 'redhat',\n",
       " 'steel',\n",
       " 'cities',\n",
       " 'dl',\n",
       " 'permanence',\n",
       " 'category',\n",
       " 'sale',\n",
       " 'noaa',\n",
       " 'cross',\n",
       " 'pneumonia',\n",
       " 'boston',\n",
       " 'alcohol',\n",
       " 'extraction',\n",
       " 'power',\n",
       " 'protein',\n",
       " 'mapping',\n",
       " 'spacy',\n",
       " 'save',\n",
       " 'caret',\n",
       " 'adult',\n",
       " 'fun',\n",
       " 'result',\n",
       " 'case',\n",
       " 'binary',\n",
       " 'isis',\n",
       " 'united',\n",
       " 'recommendations',\n",
       " 'languages',\n",
       " 'super',\n",
       " 'lab',\n",
       " 'allstate',\n",
       " 'pred',\n",
       " 'production',\n",
       " 'race',\n",
       " 'tf',\n",
       " 'book',\n",
       " 'shelter',\n",
       " 'length',\n",
       " 'charts',\n",
       " 'terrorist',\n",
       " 'surface',\n",
       " 'trend',\n",
       " 'extended',\n",
       " 'smote',\n",
       " 'n',\n",
       " 'diseases',\n",
       " 'inception',\n",
       " 'chart',\n",
       " 'py',\n",
       " 'acc',\n",
       " 'process',\n",
       " 'music',\n",
       " 'filtering',\n",
       " 'vars',\n",
       " 'depth',\n",
       " 'view',\n",
       " 'eye',\n",
       " 'preparation',\n",
       " 'winner',\n",
       " 'trump',\n",
       " 'seguro',\n",
       " 'social',\n",
       " 'component',\n",
       " 'glove',\n",
       " 'select',\n",
       " 'anime',\n",
       " 'doing',\n",
       " 'matplotlib',\n",
       " 'tools',\n",
       " 'cosine',\n",
       " 'like',\n",
       " 'mushroom',\n",
       " 'submit',\n",
       " 'dcgan',\n",
       " 'days',\n",
       " 'here',\n",
       " 'perceptron',\n",
       " 'sets',\n",
       " 'lanl',\n",
       " 'battle',\n",
       " 'competicao',\n",
       " 'combining',\n",
       " 'human',\n",
       " 'visual',\n",
       " 'foreign',\n",
       " 'there',\n",
       " 'descriptive',\n",
       " 'mercari',\n",
       " 'dados',\n",
       " 'sound',\n",
       " 'competitions',\n",
       " 'estate',\n",
       " 'spooky',\n",
       " 'developer',\n",
       " 'voting',\n",
       " 'restaurants',\n",
       " 'choose',\n",
       " 'aviation',\n",
       " 'density',\n",
       " 'thrones',\n",
       " 'application',\n",
       " 'scikit',\n",
       " 'stuff',\n",
       " 'survived',\n",
       " 'take',\n",
       " 'pure',\n",
       " 'path',\n",
       " 'j',\n",
       " 'wars',\n",
       " 'date',\n",
       " 'variable',\n",
       " 'impact',\n",
       " 'create',\n",
       " 'gru',\n",
       " 'economic',\n",
       " 'identify',\n",
       " 'need',\n",
       " 'its',\n",
       " 'read',\n",
       " 'clean',\n",
       " 'friday',\n",
       " 'assessment',\n",
       " 'rank',\n",
       " 'life',\n",
       " 'married',\n",
       " 'siamese',\n",
       " 'rain',\n",
       " 'wo',\n",
       " 'point',\n",
       " 'properties',\n",
       " 'principal',\n",
       " 'app',\n",
       " 'own',\n",
       " 'generate',\n",
       " 'rossmann',\n",
       " 'finish',\n",
       " 'estimation',\n",
       " 'draw',\n",
       " 'recogniser',\n",
       " 'convert',\n",
       " 'packages',\n",
       " 'ad',\n",
       " 'usage',\n",
       " 'suicides',\n",
       " 'share',\n",
       " 'personal',\n",
       " 'gun',\n",
       " 'trending',\n",
       " 'so',\n",
       " 'grouping',\n",
       " 'submissions',\n",
       " 'beer',\n",
       " 'mxnet',\n",
       " 'sign',\n",
       " 'natural',\n",
       " 'avocado',\n",
       " 'did',\n",
       " 'research',\n",
       " 'looking',\n",
       " 'subreddit',\n",
       " 'c',\n",
       " 'framework',\n",
       " 'fine',\n",
       " 'defect',\n",
       " 'know',\n",
       " 'ncaa',\n",
       " 'monitor',\n",
       " 'tune',\n",
       " 'p',\n",
       " 'breed',\n",
       " 'em',\n",
       " 'cuisine',\n",
       " 'pairs',\n",
       " 'skin',\n",
       " 'crowdfunding',\n",
       " 'bryant',\n",
       " 'ship',\n",
       " 'mcc',\n",
       " 'tactic',\n",
       " 'field',\n",
       " 'multiclass',\n",
       " 'distance',\n",
       " 'stopping',\n",
       " 'function',\n",
       " 'fire',\n",
       " 'import',\n",
       " 'blocks',\n",
       " 'region',\n",
       " 'projects',\n",
       " 'multi',\n",
       " 'trips',\n",
       " 'color',\n",
       " 'indicators',\n",
       " 'few',\n",
       " 'primes',\n",
       " 'common',\n",
       " 'lines',\n",
       " 'svd',\n",
       " 'testscript',\n",
       " 'sarcasm',\n",
       " 'comp',\n",
       " 'preliminary',\n",
       " 'bar',\n",
       " 'pet',\n",
       " 'avito',\n",
       " 'land',\n",
       " 'gstore',\n",
       " 'tableau',\n",
       " 'error',\n",
       " 'characters',\n",
       " 'zillow',\n",
       " 'tmdb',\n",
       " 'high',\n",
       " 'kit',\n",
       " 'query',\n",
       " 'wise',\n",
       " 'genre',\n",
       " 'microsoft',\n",
       " 'dropout',\n",
       " 'win',\n",
       " 'ames',\n",
       " 'hot',\n",
       " 'estimate',\n",
       " 'experiments',\n",
       " 'bad',\n",
       " 'explorer',\n",
       " 'sharing',\n",
       " 'beat',\n",
       " 'candidate',\n",
       " 'cars',\n",
       " 'development',\n",
       " 'indians',\n",
       " 'column',\n",
       " 'firsttry',\n",
       " 'dataframe',\n",
       " 'matching',\n",
       " 'internet',\n",
       " 'rmarkdown',\n",
       " 'blend',\n",
       " 'weight',\n",
       " 'graphs',\n",
       " 'fb',\n",
       " 'export',\n",
       " 'satisfaction',\n",
       " 'key',\n",
       " 'post',\n",
       " 'village',\n",
       " 'vsb',\n",
       " 'historical',\n",
       " 'nearest',\n",
       " 'x',\n",
       " 'round',\n",
       " 'workflow',\n",
       " 'starbucks',\n",
       " 'springleaf',\n",
       " 'web',\n",
       " 'european',\n",
       " 'generating',\n",
       " 'done',\n",
       " 'extra',\n",
       " 'construction',\n",
       " ...]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "226062d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('idea', 0.8313553929328918),\n",
       " ('youve', 0.8310362696647644),\n",
       " ('mgf', 0.8284841179847717),\n",
       " ('jared', 0.8264990448951721),\n",
       " ('picks', 0.8254615068435669),\n",
       " ('else', 0.8209494352340698),\n",
       " ('damn', 0.8208690285682678),\n",
       " ('brain', 0.8189692497253418),\n",
       " ('cool', 0.817270040512085),\n",
       " ('someone', 0.815057098865509)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ba2f551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45753163"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('good','like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12ca467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "j = 0\n",
    "for i in range(0,len(sentences)):\n",
    "    if len(popular_titles[i]) > max_length:\n",
    "        max_length = len(popular_titles[i])\n",
    "        j = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ab415b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82863f59",
   "metadata": {},
   "source": [
    "Now we integer encode the words in the reviews using Keras tokenizer.\n",
    "Note that there two important variables: which are the vocab_size which is the total no of unique words while the second is max_doc_len which is the length of every document after padding. Both of these are required by the Keras embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3219a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(sentences)\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "encd_rev = tok.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fb08594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_of_tokens(sentences):\n",
    "    ## tokenization\n",
    "    tok = Tokenizer()\n",
    "    tok.fit_on_texts(sentences)\n",
    "    vocab_size = len(tok.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in sentences:\n",
    "        token_list = tok.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3e43ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 347],\n",
       " [40, 347, 33],\n",
       " [1475, 221],\n",
       " [1475, 221, 6],\n",
       " [1475, 221, 6, 970],\n",
       " [1475, 221, 6, 970, 105],\n",
       " [77, 51],\n",
       " [77, 51, 26],\n",
       " [77, 51, 26, 766],\n",
       " [213, 257]]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sequences, vocab_size = get_sequence_of_tokens(sentences)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e5f13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max_length  # max lenght of a review\n",
    "vocab_size = len(tok.word_index) + 1  # total no of words\n",
    "embed_dim=300 # embedding dimension as choosen in word2vec constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "237e4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=vocab_size)\n",
    "    return predictors, label, max_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e41f8d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'notebook': 1,\n",
       " 'starter': 2,\n",
       " 'data': 3,\n",
       " 'and': 4,\n",
       " 'with': 5,\n",
       " 'of': 6,\n",
       " 'analysis': 7,\n",
       " 'dataset': 8,\n",
       " 'titanic': 9,\n",
       " 'no': 10,\n",
       " 'eda': 11,\n",
       " 'the': 12,\n",
       " 'longer': 13,\n",
       " 'available': 14,\n",
       " 'in': 15,\n",
       " 'for': 16,\n",
       " 'using': 17,\n",
       " 'prediction': 18,\n",
       " 'to': 19,\n",
       " 'a': 20,\n",
       " 'on': 21,\n",
       " 'keras': 22,\n",
       " 'simple': 23,\n",
       " 'model': 24,\n",
       " 'xgboost': 25,\n",
       " 'learning': 26,\n",
       " 'first': 27,\n",
       " 'test': 28,\n",
       " 'regression': 29,\n",
       " 'r': 30,\n",
       " 'python': 31,\n",
       " 'cnn': 32,\n",
       " 'classification': 33,\n",
       " 'exploration': 34,\n",
       " 'by': 35,\n",
       " 'fork': 36,\n",
       " 'parking': 37,\n",
       " 'random': 38,\n",
       " 'garage': 39,\n",
       " 'forest': 40,\n",
       " 'from': 41,\n",
       " 'my': 42,\n",
       " 'visualization': 43,\n",
       " 'house': 44,\n",
       " 'feature': 45,\n",
       " 'detection': 46,\n",
       " 'mnist': 47,\n",
       " 'exploring': 48,\n",
       " 'kaggle': 49,\n",
       " 'kernel': 50,\n",
       " 'machine': 51,\n",
       " 'vs': 52,\n",
       " 'ml': 53,\n",
       " 'exploratory': 54,\n",
       " 'script': 55,\n",
       " 'tutorial': 56,\n",
       " 'challenge': 57,\n",
       " 'day': 58,\n",
       " 'neural': 59,\n",
       " 'lb': 60,\n",
       " 'features': 61,\n",
       " 'time': 62,\n",
       " 'digit': 63,\n",
       " 'predicting': 64,\n",
       " 'network': 65,\n",
       " 'prices': 66,\n",
       " 'deep': 67,\n",
       " 'logistic': 68,\n",
       " 'tensorflow': 69,\n",
       " 'linear': 70,\n",
       " 'pytorch': 71,\n",
       " 'predict': 72,\n",
       " 'models': 73,\n",
       " 'basic': 74,\n",
       " 'xgb': 75,\n",
       " 'price': 76,\n",
       " 'exercise': 77,\n",
       " 'baseline': 78,\n",
       " 'survival': 79,\n",
       " 'world': 80,\n",
       " 'sentiment': 81,\n",
       " 'classifier': 82,\n",
       " 'project': 83,\n",
       " 'try': 84,\n",
       " 'testing': 85,\n",
       " 'nn': 86,\n",
       " 'top': 87,\n",
       " 'rf': 88,\n",
       " 'crime': 89,\n",
       " 'image': 90,\n",
       " 'svm': 91,\n",
       " 'iris': 92,\n",
       " 'benchmark': 93,\n",
       " 'knn': 94,\n",
       " 'competition': 95,\n",
       " 'recognition': 96,\n",
       " 'fraud': 97,\n",
       " 'clustering': 98,\n",
       " 'fastai': 99,\n",
       " 'engineering': 100,\n",
       " 'recognizer': 101,\n",
       " 'is': 102,\n",
       " 'how': 103,\n",
       " 'solution': 104,\n",
       " 'lightgbm': 105,\n",
       " 'text': 106,\n",
       " 'decision': 107,\n",
       " 'new': 108,\n",
       " 'series': 109,\n",
       " 'science': 110,\n",
       " 'cleaning': 111,\n",
       " 'tree': 112,\n",
       " 'cancer': 113,\n",
       " 'submission': 114,\n",
       " 'pca': 115,\n",
       " 'example': 116,\n",
       " 'lstm': 117,\n",
       " 'pandas': 118,\n",
       " 'code': 119,\n",
       " 'beginners': 120,\n",
       " 'us': 121,\n",
       " 'lgbm': 122,\n",
       " 'images': 123,\n",
       " 'santander': 124,\n",
       " 'part': 125,\n",
       " 'sales': 126,\n",
       " 'at': 127,\n",
       " 'credit': 128,\n",
       " 'through': 129,\n",
       " 'sf': 130,\n",
       " 'score': 131,\n",
       " 'housing': 132,\n",
       " 'training': 133,\n",
       " 'ensemble': 134,\n",
       " 'naive': 135,\n",
       " 'nlp': 136,\n",
       " 'customer': 137,\n",
       " 'journey': 138,\n",
       " 'approach': 139,\n",
       " 'map': 140,\n",
       " 'attempt': 141,\n",
       " 'global': 142,\n",
       " 'movie': 143,\n",
       " 'beginner': 144,\n",
       " 'survey': 145,\n",
       " 'predictions': 146,\n",
       " 'accuracy': 147,\n",
       " 'preprocessing': 148,\n",
       " 'getting': 149,\n",
       " 'sql': 150,\n",
       " 'best': 151,\n",
       " 'introduction': 152,\n",
       " 'interactive': 153,\n",
       " 'final': 154,\n",
       " 'set': 155,\n",
       " 'learn': 156,\n",
       " 'sklearn': 157,\n",
       " 'w': 158,\n",
       " 'dogs': 159,\n",
       " 'most': 160,\n",
       " 'nyc': 161,\n",
       " 'quick': 162,\n",
       " 'some': 163,\n",
       " 'what': 164,\n",
       " 'modeling': 165,\n",
       " 'understanding': 166,\n",
       " 'based': 167,\n",
       " 'an': 168,\n",
       " 'all': 169,\n",
       " 'your': 170,\n",
       " 'are': 171,\n",
       " 'practice': 172,\n",
       " 'analytics': 173,\n",
       " 'explore': 174,\n",
       " 'cv': 175,\n",
       " 'de': 176,\n",
       " 'or': 177,\n",
       " 'transfer': 178,\n",
       " 'selection': 179,\n",
       " 'started': 180,\n",
       " 'quora': 181,\n",
       " 'taxi': 182,\n",
       " 'missing': 183,\n",
       " 'gbm': 184,\n",
       " 'bank': 185,\n",
       " 'news': 186,\n",
       " 'cats': 187,\n",
       " 'i': 188,\n",
       " 'pubg': 189,\n",
       " 'google': 190,\n",
       " 'bayes': 191,\n",
       " 'home': 192,\n",
       " 'over': 193,\n",
       " 'randomforest': 194,\n",
       " 'nfl': 195,\n",
       " 'kiva': 196,\n",
       " 'train': 197,\n",
       " 'seaborn': 198,\n",
       " 'pokemon': 199,\n",
       " 'sample': 200,\n",
       " 'word': 201,\n",
       " 'this': 202,\n",
       " 'plotly': 203,\n",
       " 'intro': 204,\n",
       " 'scratch': 205,\n",
       " 'scavenger': 206,\n",
       " 'hunt': 207,\n",
       " 'state': 208,\n",
       " 'breast': 209,\n",
       " 'insights': 210,\n",
       " 'plot': 211,\n",
       " 'gender': 212,\n",
       " 'different': 213,\n",
       " 'reviews': 214,\n",
       " 'la': 215,\n",
       " 'demo': 216,\n",
       " 'india': 217,\n",
       " 'more': 218,\n",
       " 'names': 219,\n",
       " 'validation': 220,\n",
       " 'guide': 221,\n",
       " 'disease': 222,\n",
       " 'crimes': 223,\n",
       " 'class': 224,\n",
       " 'age': 225,\n",
       " 'problem': 226,\n",
       " 'rate': 227,\n",
       " 'step': 228,\n",
       " 'card': 229,\n",
       " 'lgb': 230,\n",
       " 'tuning': 231,\n",
       " 'who': 232,\n",
       " 'dashboard': 233,\n",
       " 'market': 234,\n",
       " 'not': 235,\n",
       " 'look': 236,\n",
       " 'visualizations': 237,\n",
       " 'default': 238,\n",
       " 'dashboarding': 239,\n",
       " 'game': 240,\n",
       " 'one': 241,\n",
       " 'statistics': 242,\n",
       " 'trying': 243,\n",
       " 'stacking': 244,\n",
       " 'lesson': 245,\n",
       " 'study': 246,\n",
       " 'single': 247,\n",
       " 'analyzing': 248,\n",
       " 'heart': 249,\n",
       " 'just': 250,\n",
       " 'churn': 251,\n",
       " 'two': 252,\n",
       " 'kmeans': 253,\n",
       " 'basics': 254,\n",
       " 'income': 255,\n",
       " 'do': 256,\n",
       " 'embeddings': 257,\n",
       " 'networks': 258,\n",
       " 'suicide': 259,\n",
       " 'stock': 260,\n",
       " 'digits': 261,\n",
       " 'ai': 262,\n",
       " 'rnn': 263,\n",
       " 'wine': 264,\n",
       " 'assignment': 265,\n",
       " 'start': 266,\n",
       " 'happiness': 267,\n",
       " 'visualizing': 268,\n",
       " 'ieee': 269,\n",
       " 'search': 270,\n",
       " 'segmentation': 271,\n",
       " 'unet': 272,\n",
       " 'loan': 273,\n",
       " 'initial': 274,\n",
       " 'bayesian': 275,\n",
       " 'words': 276,\n",
       " 'working': 277,\n",
       " 'questions': 278,\n",
       " 'trial': 279,\n",
       " 'version': 280,\n",
       " 'lasso': 281,\n",
       " 'plots': 282,\n",
       " 'airbnb': 283,\n",
       " 'twitter': 284,\n",
       " 'disaster': 285,\n",
       " 'review': 286,\n",
       " 'elo': 287,\n",
       " 'video': 288,\n",
       " 'you': 289,\n",
       " 'numpy': 290,\n",
       " 'mining': 291,\n",
       " 'mean': 292,\n",
       " 'job': 293,\n",
       " 'reddit': 294,\n",
       " 'number': 295,\n",
       " 'poverty': 296,\n",
       " 'net': 297,\n",
       " 'bike': 298,\n",
       " 'fivethirtyeight': 299,\n",
       " 'public': 300,\n",
       " 'imdb': 301,\n",
       " 'games': 302,\n",
       " 'extensive': 303,\n",
       " 'traffic': 304,\n",
       " 'pipeline': 305,\n",
       " 'algorithms': 306,\n",
       " 'only': 307,\n",
       " 'exercises': 308,\n",
       " 'processing': 309,\n",
       " 'stats': 310,\n",
       " 'week': 311,\n",
       " 'another': 312,\n",
       " 'homework': 313,\n",
       " 'we': 314,\n",
       " 'total': 315,\n",
       " 'group': 316,\n",
       " 'convolutional': 317,\n",
       " 'classifiers': 318,\n",
       " 'car': 319,\n",
       " 'detailed': 320,\n",
       " 'advanced': 321,\n",
       " 'into': 322,\n",
       " 'quality': 323,\n",
       " 'as': 324,\n",
       " 'recommendation': 325,\n",
       " 'hello': 326,\n",
       " 'method': 327,\n",
       " 'visualisation': 328,\n",
       " 'per': 329,\n",
       " 'lets': 330,\n",
       " 'grid': 331,\n",
       " 'results': 332,\n",
       " 'fifa': 333,\n",
       " 'diabetes': 334,\n",
       " 'comments': 335,\n",
       " 'performance': 336,\n",
       " 'hr': 337,\n",
       " 'health': 338,\n",
       " 'predictor': 339,\n",
       " 'forecasting': 340,\n",
       " 'dog': 341,\n",
       " 'real': 342,\n",
       " 'terrorism': 343,\n",
       " 'get': 344,\n",
       " 'parameter': 345,\n",
       " 'auc': 346,\n",
       " 'type': 347,\n",
       " 'optimization': 348,\n",
       " 'language': 349,\n",
       " 'average': 350,\n",
       " 'it': 351,\n",
       " 'city': 352,\n",
       " 'generation': 353,\n",
       " 'oecd': 354,\n",
       " 'gradient': 355,\n",
       " 'sigma': 356,\n",
       " 'good': 357,\n",
       " 'values': 358,\n",
       " 'dont': 359,\n",
       " 'change': 360,\n",
       " 'trees': 361,\n",
       " 'files': 362,\n",
       " 'ridge': 363,\n",
       " 'can': 364,\n",
       " 'comparison': 365,\n",
       " 'players': 366,\n",
       " 'punt': 367,\n",
       " 'run': 368,\n",
       " 'augmentation': 369,\n",
       " 'report': 370,\n",
       " 'san': 371,\n",
       " 'datasets': 372,\n",
       " 'toxic': 373,\n",
       " 'aptos': 374,\n",
       " 'cost': 375,\n",
       " 'use': 376,\n",
       " 'year': 377,\n",
       " 'scikitlearn': 378,\n",
       " 'salary': 379,\n",
       " 'second': 380,\n",
       " 'catboost': 381,\n",
       " 'transaction': 382,\n",
       " 'baby': 383,\n",
       " 'apps': 384,\n",
       " 'draft': 385,\n",
       " 'workbook': 386,\n",
       " 'plotting': 387,\n",
       " 'play': 388,\n",
       " 'algorithm': 389,\n",
       " 'importance': 390,\n",
       " 'check': 391,\n",
       " 'overview': 392,\n",
       " 'me': 393,\n",
       " 'mlp': 394,\n",
       " 'country': 395,\n",
       " 'insurance': 396,\n",
       " 'police': 397,\n",
       " 'distribution': 398,\n",
       " 'revenue': 399,\n",
       " 'fare': 400,\n",
       " 'youtube': 401,\n",
       " 'insincere': 402,\n",
       " 'boosting': 403,\n",
       " 'implementation': 404,\n",
       " 'list': 405,\n",
       " 'v': 406,\n",
       " 'handling': 407,\n",
       " 'out': 408,\n",
       " 'stack': 409,\n",
       " 'food': 410,\n",
       " 'bigquery': 411,\n",
       " 'complete': 412,\n",
       " 'trabalho': 413,\n",
       " 'risk': 414,\n",
       " 'building': 415,\n",
       " 'categorical': 416,\n",
       " 'modelling': 417,\n",
       " 'countries': 418,\n",
       " 'work': 419,\n",
       " 'lr': 420,\n",
       " 'light': 421,\n",
       " 'stackoverflow': 422,\n",
       " 'full': 423,\n",
       " 'spam': 424,\n",
       " 'find': 425,\n",
       " 'name': 426,\n",
       " 'store': 427,\n",
       " 'cooking': 428,\n",
       " 'support': 429,\n",
       " 'cluster': 430,\n",
       " 'user': 431,\n",
       " 'end': 432,\n",
       " 'lasagne': 433,\n",
       " 'forests': 434,\n",
       " 'airline': 435,\n",
       " 'variables': 436,\n",
       " 'team': 437,\n",
       " 'bert': 438,\n",
       " 'identification': 439,\n",
       " 'financial': 440,\n",
       " 'median': 441,\n",
       " 'usa': 442,\n",
       " 'resnet': 443,\n",
       " 'heatmap': 444,\n",
       " 'load': 445,\n",
       " 'club': 446,\n",
       " 'playground': 447,\n",
       " 'gan': 448,\n",
       " 'nba': 449,\n",
       " 'temperature': 450,\n",
       " 'facebook': 451,\n",
       " 'trends': 452,\n",
       " 'indian': 453,\n",
       " 'evaluation': 454,\n",
       " 'easy': 455,\n",
       " 'attacks': 456,\n",
       " 'system': 457,\n",
       " 'used': 458,\n",
       " 'leaf': 459,\n",
       " 'functions': 460,\n",
       " 'dnn': 461,\n",
       " 'playing': 462,\n",
       " 'statistical': 463,\n",
       " 'population': 464,\n",
       " 'tsne': 465,\n",
       " 'energy': 466,\n",
       " 'embedding': 467,\n",
       " 'level': 468,\n",
       " 'demand': 469,\n",
       " 'fast': 470,\n",
       " 'chicago': 471,\n",
       " 'flower': 472,\n",
       " 'up': 473,\n",
       " 'whale': 474,\n",
       " 'tweets': 475,\n",
       " 'why': 476,\n",
       " 'overfit': 477,\n",
       " 'wordcloud': 478,\n",
       " 'techniques': 479,\n",
       " 'ranking': 480,\n",
       " 'log': 481,\n",
       " 'medical': 482,\n",
       " 'restaurant': 483,\n",
       " 'types': 484,\n",
       " 'comprehensive': 485,\n",
       " 'donorschoose': 486,\n",
       " 'fe': 487,\n",
       " 'university': 488,\n",
       " 'value': 489,\n",
       " 'which': 490,\n",
       " 'popular': 491,\n",
       " 'talkingdata': 492,\n",
       " 'go': 493,\n",
       " 'users': 494,\n",
       " 'maps': 495,\n",
       " 'graph': 496,\n",
       " 'francisco': 497,\n",
       " 'creating': 498,\n",
       " 'reading': 499,\n",
       " 'ii': 500,\n",
       " 'census': 501,\n",
       " 'open': 502,\n",
       " 'classify': 503,\n",
       " 'forecast': 504,\n",
       " 'encoding': 505,\n",
       " 'classifying': 506,\n",
       " 'kickstarter': 507,\n",
       " 'red': 508,\n",
       " 'pricing': 509,\n",
       " 'player': 510,\n",
       " 'modified': 511,\n",
       " 'object': 512,\n",
       " 'matrix': 513,\n",
       " 'big': 514,\n",
       " 'earthquake': 515,\n",
       " 'without': 516,\n",
       " 'product': 517,\n",
       " 'convnet': 518,\n",
       " 'predictive': 519,\n",
       " 'julia': 520,\n",
       " 'kobe': 521,\n",
       " 'salaries': 522,\n",
       " 'ipl': 523,\n",
       " 'animation': 524,\n",
       " 'states': 525,\n",
       " 'correlation': 526,\n",
       " 'attention': 527,\n",
       " 'count': 528,\n",
       " 'topic': 529,\n",
       " 'programming': 530,\n",
       " 'chest': 531,\n",
       " 'ds': 532,\n",
       " 'ny': 533,\n",
       " 'graduate': 534,\n",
       " 'lending': 535,\n",
       " 'tfidf': 536,\n",
       " 'years': 537,\n",
       " 'index': 538,\n",
       " 'visualize': 539,\n",
       " 'generator': 540,\n",
       " 'daily': 541,\n",
       " 'around': 542,\n",
       " 'very': 543,\n",
       " 'template': 544,\n",
       " 'when': 545,\n",
       " 'solutions': 546,\n",
       " 'malware': 547,\n",
       " 'fashion': 548,\n",
       " 'where': 549,\n",
       " 'automl': 550,\n",
       " 'sparse': 551,\n",
       " 'reg': 552,\n",
       " 'question': 553,\n",
       " 'animal': 554,\n",
       " 'star': 555,\n",
       " 'instacart': 556,\n",
       " 'shot': 557,\n",
       " 'between': 558,\n",
       " 'database': 559,\n",
       " 'about': 560,\n",
       " 'starting': 561,\n",
       " 'finding': 562,\n",
       " 'vector': 563,\n",
       " 'rankings': 564,\n",
       " 'be': 565,\n",
       " 'kannada': 566,\n",
       " 'similarity': 567,\n",
       " 'hyperparameter': 568,\n",
       " 'unsupervised': 569,\n",
       " 'gpu': 570,\n",
       " 'workshop': 571,\n",
       " 'vehicle': 572,\n",
       " 'autoencoder': 573,\n",
       " 'aula': 574,\n",
       " 'costa': 575,\n",
       " 'attrition': 576,\n",
       " 'plant': 577,\n",
       " 'notebooks': 578,\n",
       " 'rates': 579,\n",
       " 'future': 580,\n",
       " 'weather': 581,\n",
       " 'lda': 582,\n",
       " 'species': 583,\n",
       " 'speed': 584,\n",
       " 'course': 585,\n",
       " 'bimbo': 586,\n",
       " 'progress': 587,\n",
       " 'boost': 588,\n",
       " 'summary': 589,\n",
       " 'student': 590,\n",
       " 'college': 591,\n",
       " 'cloud': 592,\n",
       " 'air': 593,\n",
       " 'location': 594,\n",
       " 'whats': 595,\n",
       " 'k': 596,\n",
       " 'detecting': 597,\n",
       " 'last': 598,\n",
       " 'trip': 599,\n",
       " 'voice': 600,\n",
       " 'our': 601,\n",
       " 'reduction': 602,\n",
       " 'loans': 603,\n",
       " 'densenet': 604,\n",
       " 'people': 605,\n",
       " 'consumption': 606,\n",
       " 'severstal': 607,\n",
       " 'writing': 608,\n",
       " 'split': 609,\n",
       " 'numbers': 610,\n",
       " 'recommender': 611,\n",
       " 'cactus': 612,\n",
       " 'xray': 613,\n",
       " 'comment': 614,\n",
       " 'better': 615,\n",
       " 'multiple': 616,\n",
       " 'place': 617,\n",
       " 'external': 618,\n",
       " 'does': 619,\n",
       " 'bag': 620,\n",
       " 'cat': 621,\n",
       " 'layer': 622,\n",
       " 'face': 623,\n",
       " 'csv': 624,\n",
       " 'education': 625,\n",
       " 'sqlite': 626,\n",
       " 'making': 627,\n",
       " 'household': 628,\n",
       " 'low': 629,\n",
       " 'base': 630,\n",
       " 'stacked': 631,\n",
       " 'pima': 632,\n",
       " 'primary': 633,\n",
       " 'private': 634,\n",
       " 'experiment': 635,\n",
       " 'deaths': 636,\n",
       " 'parameters': 637,\n",
       " 'porto': 638,\n",
       " 'package': 639,\n",
       " 'scores': 640,\n",
       " 'loading': 641,\n",
       " 'gaussian': 642,\n",
       " 'beating': 643,\n",
       " 'title': 644,\n",
       " 'debate': 645,\n",
       " 'table': 646,\n",
       " 'month': 647,\n",
       " 'students': 648,\n",
       " 'meta': 649,\n",
       " 'proyecto': 650,\n",
       " 'cs': 651,\n",
       " 'dr': 652,\n",
       " 'arima': 653,\n",
       " 'box': 654,\n",
       " 'bias': 655,\n",
       " 'death': 656,\n",
       " 'blindness': 657,\n",
       " 'ashrae': 658,\n",
       " 'admission': 659,\n",
       " 'leaderboard': 660,\n",
       " 'genetic': 661,\n",
       " 'malaria': 662,\n",
       " 'cell': 663,\n",
       " 'that': 664,\n",
       " 'policy': 665,\n",
       " 'custom': 666,\n",
       " 'uci': 667,\n",
       " 'methods': 668,\n",
       " 'handwritten': 669,\n",
       " 'bitcoin': 670,\n",
       " 'family': 671,\n",
       " 'weighted': 672,\n",
       " 'english': 673,\n",
       " 'paris': 674,\n",
       " 'cover': 675,\n",
       " 'inference': 676,\n",
       " 'yet': 677,\n",
       " 'temp': 678,\n",
       " 'products': 679,\n",
       " 'collisions': 680,\n",
       " 'trade': 681,\n",
       " 'football': 682,\n",
       " 'early': 683,\n",
       " 'area': 684,\n",
       " 'xgbooost': 685,\n",
       " 'ann': 686,\n",
       " 'magic': 687,\n",
       " 'black': 688,\n",
       " 'overfitting': 689,\n",
       " 'passnyc': 690,\n",
       " 'iowa': 691,\n",
       " 'costs': 692,\n",
       " 'accidents': 693,\n",
       " 'various': 694,\n",
       " 'should': 695,\n",
       " 'climate': 696,\n",
       " 'tests': 697,\n",
       " 'expedia': 698,\n",
       " 'history': 699,\n",
       " 'overflow': 700,\n",
       " 'outliers': 701,\n",
       " 'consumer': 702,\n",
       " 'visualisations': 703,\n",
       " 'labels': 704,\n",
       " 'output': 705,\n",
       " 'seattle': 706,\n",
       " 'boston': 707,\n",
       " 'business': 708,\n",
       " 'ibm': 709,\n",
       " 'dl': 710,\n",
       " 'power': 711,\n",
       " 'steel': 712,\n",
       " 'pneumonia': 713,\n",
       " 'result': 714,\n",
       " 'category': 715,\n",
       " 'binary': 716,\n",
       " 'cities': 717,\n",
       " 'noaa': 718,\n",
       " 'via': 719,\n",
       " 'adversarial': 720,\n",
       " 'help': 721,\n",
       " 'pretrained': 722,\n",
       " 'digitrecognizer': 723,\n",
       " 'line': 724,\n",
       " 'regressor': 725,\n",
       " 'zomato': 726,\n",
       " 'updated': 727,\n",
       " 'file': 728,\n",
       " 'outcome': 729,\n",
       " 'fasttext': 730,\n",
       " 'descent': 731,\n",
       " 'hotel': 732,\n",
       " 'activity': 733,\n",
       " 'telco': 734,\n",
       " 'fake': 735,\n",
       " 'amazon': 736,\n",
       " 'sale': 737,\n",
       " 'alcohol': 738,\n",
       " 'caret': 739,\n",
       " 'united': 740,\n",
       " 'survivors': 741,\n",
       " 'other': 742,\n",
       " 'extraction': 743,\n",
       " 'permanence': 744,\n",
       " 'scripts': 745,\n",
       " 'case': 746,\n",
       " 'spacy': 747,\n",
       " 'adult': 748,\n",
       " 'have': 749,\n",
       " 'correlations': 750,\n",
       " 'isis': 751,\n",
       " 'columns': 752,\n",
       " 'cross': 753,\n",
       " 'mapping': 754,\n",
       " 'fun': 755,\n",
       " 'save': 756,\n",
       " 'redhat': 757,\n",
       " 'api': 758,\n",
       " 'york': 759,\n",
       " 'viz': 760,\n",
       " 'way': 761,\n",
       " 'yelp': 762,\n",
       " 'protein': 763,\n",
       " 'nltk': 764,\n",
       " 'flatline': 765,\n",
       " 'competitions': 766,\n",
       " 'diseases': 767,\n",
       " 'tools': 768,\n",
       " 'social': 769,\n",
       " 'lab': 770,\n",
       " 'charts': 771,\n",
       " 'race': 772,\n",
       " 'preparation': 773,\n",
       " 'mushroom': 774,\n",
       " 'submit': 775,\n",
       " 'perceptron': 776,\n",
       " 'music': 777,\n",
       " 'pred': 778,\n",
       " 'book': 779,\n",
       " 'recommendations': 780,\n",
       " 'impact': 781,\n",
       " 'n': 782,\n",
       " 'here': 783,\n",
       " 'dcgan': 784,\n",
       " 'days': 785,\n",
       " 'acc': 786,\n",
       " 'there': 787,\n",
       " 'application': 788,\n",
       " 'create': 789,\n",
       " 'matplotlib': 790,\n",
       " 'component': 791,\n",
       " 'glove': 792,\n",
       " 'select': 793,\n",
       " 'anime': 794,\n",
       " 'super': 795,\n",
       " 'trend': 796,\n",
       " 'inception': 797,\n",
       " 'surface': 798,\n",
       " 'shelter': 799,\n",
       " 'tf': 800,\n",
       " 'spooky': 801,\n",
       " 'foreign': 802,\n",
       " 'survived': 803,\n",
       " 'visual': 804,\n",
       " 'lanl': 805,\n",
       " 'restaurants': 806,\n",
       " 'voting': 807,\n",
       " 'path': 808,\n",
       " 'density': 809,\n",
       " 'j': 810,\n",
       " 'dados': 811,\n",
       " 'thrones': 812,\n",
       " 'developer': 813,\n",
       " 'scikit': 814,\n",
       " 'sound': 815,\n",
       " 'estate': 816,\n",
       " 'terrorist': 817,\n",
       " 'chart': 818,\n",
       " 'smote': 819,\n",
       " 'extended': 820,\n",
       " 'py': 821,\n",
       " 'combining': 822,\n",
       " 'doing': 823,\n",
       " 'seguro': 824,\n",
       " 'eye': 825,\n",
       " 'view': 826,\n",
       " 'depth': 827,\n",
       " 'filtering': 828,\n",
       " 'winner': 829,\n",
       " 'aviation': 830,\n",
       " 'mercari': 831,\n",
       " 'gru': 832,\n",
       " 'competicao': 833,\n",
       " 'choose': 834,\n",
       " 'stuff': 835,\n",
       " 'like': 836,\n",
       " 'sets': 837,\n",
       " 'battle': 838,\n",
       " 'process': 839,\n",
       " 'human': 840,\n",
       " 'length': 841,\n",
       " 'take': 842,\n",
       " 'wars': 843,\n",
       " 'variable': 844,\n",
       " 'descriptive': 845,\n",
       " 'date': 846,\n",
       " 'pure': 847,\n",
       " 'allstate': 848,\n",
       " 'production': 849,\n",
       " 'trump': 850,\n",
       " 'vars': 851,\n",
       " 'languages': 852,\n",
       " 'cosine': 853,\n",
       " 'packages': 854,\n",
       " 'convert': 855,\n",
       " 'rain': 856,\n",
       " 'natural': 857,\n",
       " 'bar': 858,\n",
       " 'properties': 859,\n",
       " 'app': 860,\n",
       " 'comp': 861,\n",
       " 'tactic': 862,\n",
       " 'kit': 863,\n",
       " 'query': 864,\n",
       " 'point': 865,\n",
       " 'sign': 866,\n",
       " 'usage': 867,\n",
       " 'life': 868,\n",
       " 'assessment': 869,\n",
       " 'read': 870,\n",
       " 'explorer': 871,\n",
       " 'crowdfunding': 872,\n",
       " 'skin': 873,\n",
       " 'pet': 874,\n",
       " 'preliminary': 875,\n",
       " 'characters': 876,\n",
       " 'estimation': 877,\n",
       " 'defect': 878,\n",
       " 'cuisine': 879,\n",
       " 'field': 880,\n",
       " 'gstore': 881,\n",
       " 'tableau': 882,\n",
       " 'c': 883,\n",
       " 'personal': 884,\n",
       " 'dropout': 885,\n",
       " 'color': 886,\n",
       " 'breed': 887,\n",
       " 'trending': 888,\n",
       " 'multi': 889,\n",
       " 'sharing': 890,\n",
       " 'land': 891,\n",
       " 'identify': 892,\n",
       " 'share': 893,\n",
       " 'microsoft': 894,\n",
       " 'few': 895,\n",
       " 'lines': 896,\n",
       " 'svd': 897,\n",
       " 'ship': 898,\n",
       " 'ames': 899,\n",
       " 'em': 900,\n",
       " 'rank': 901,\n",
       " 'principal': 902,\n",
       " 'recogniser': 903,\n",
       " 'suicides': 904,\n",
       " 'draw': 905,\n",
       " 'generate': 906,\n",
       " 'fire': 907,\n",
       " 'wise': 908,\n",
       " 'pairs': 909,\n",
       " 'hot': 910,\n",
       " 'candidate': 911,\n",
       " 'need': 912,\n",
       " 'tune': 913,\n",
       " 'finish': 914,\n",
       " 'research': 915,\n",
       " 'stopping': 916,\n",
       " 'mxnet': 917,\n",
       " 'estimate': 918,\n",
       " 'experiments': 919,\n",
       " 'bad': 920,\n",
       " 'projects': 921,\n",
       " 'avito': 922,\n",
       " 'function': 923,\n",
       " 'import': 924,\n",
       " 'blocks': 925,\n",
       " 'married': 926,\n",
       " 'friday': 927,\n",
       " 'monitor': 928,\n",
       " 'fine': 929,\n",
       " 'subreddit': 930,\n",
       " 'submissions': 931,\n",
       " 'own': 932,\n",
       " 'sarcasm': 933,\n",
       " 'multiclass': 934,\n",
       " 'win': 935,\n",
       " 'indicators': 936,\n",
       " 'economic': 937,\n",
       " 'primes': 938,\n",
       " 'gun': 939,\n",
       " 'siamese': 940,\n",
       " 'testscript': 941,\n",
       " 'region': 942,\n",
       " 'cars': 943,\n",
       " 'beer': 944,\n",
       " 'its': 945,\n",
       " 'bryant': 946,\n",
       " 'grouping': 947,\n",
       " 'avocado': 948,\n",
       " 'know': 949,\n",
       " 'ncaa': 950,\n",
       " 'clean': 951,\n",
       " 'mcc': 952,\n",
       " 'tmdb': 953,\n",
       " 'did': 954,\n",
       " 'framework': 955,\n",
       " 'p': 956,\n",
       " 'rossmann': 957,\n",
       " 'high': 958,\n",
       " 'genre': 959,\n",
       " 'distance': 960,\n",
       " 'looking': 961,\n",
       " 'common': 962,\n",
       " 'so': 963,\n",
       " 'wo': 964,\n",
       " 'beat': 965,\n",
       " 'zillow': 966,\n",
       " 'ad': 967,\n",
       " 'trips': 968,\n",
       " 'error': 969,\n",
       " 'starters': 970,\n",
       " 'anomaly': 971,\n",
       " 'generating': 972,\n",
       " 'cup': 973,\n",
       " 'dataframe': 974,\n",
       " 'vsb': 975,\n",
       " 'blend': 976,\n",
       " 'weight': 977,\n",
       " 'survive': 978,\n",
       " 'prudential': 979,\n",
       " 'office': 980,\n",
       " 'village': 981,\n",
       " 'dive': 982,\n",
       " 'ieeecis': 983,\n",
       " 'ted': 984,\n",
       " 'nets': 985,\n",
       " 'scale': 986,\n",
       " 'soccer': 987,\n",
       " 'x': 988,\n",
       " 'export': 989,\n",
       " 'satisfaction': 990,\n",
       " 'springleaf': 991,\n",
       " 'workflow': 992,\n",
       " 'sinking': 993,\n",
       " 'web': 994,\n",
       " 'starbucks': 995,\n",
       " 'post': 996,\n",
       " 'extra': 997,\n",
       " 'road': 998,\n",
       " 'brief': 999,\n",
       " 'detector': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx = tok.word_index\n",
    "word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "639d4fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17326, 82)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #padding\n",
    "# pad_rev = pad_sequences(encd_rev , maxlen = max_len , padding = 'post')\n",
    "# pad_rev.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98db7b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  59, 297,  24,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad_rev[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d7807",
   "metadata": {},
   "source": [
    "### CREATING THE EMBEDDING MATRIX\n",
    "\n",
    "#### Now we need to pass the w2v word embeddings to the embedding layer in Keras. For this we will create the embedding matrix and pass it as 'embedding_initializer' parameter to the layer.\n",
    "\n",
    "The embedding matrix will be of dimensions (vocab_size,embed_dim) where the word_index of each word from keras tokenizer is its index into the matrix and the corressponding entry is its w2v vector ;)\n",
    "\n",
    "Note that there may be words which will not be present in embeddings learnt by the w2v model. The embedding matrix entry corressponding to those words will be a vector of all zeros.\n",
    "\n",
    "Also note that if u are thinkng why won't a word be present then it is bcoz now we have learnt on out own corpus but if we use pre-trained embedding then it may happen that some words specific to our dataset aren't present then in those cases we may use a fixed vector of zeros to denote all those words that earen;t present in th pre-trained embeddings. Also note that it may also happen that some words are not present ifu have filtered some words by setting min_count in w2v constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ed27181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10134\n",
      "the no of key-value pairs: 10134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.06677392,  0.14521858, -0.11577258, -0.17534584, -0.00509705,\n",
       "       -0.3009266 ,  0.07470374,  0.69906974,  0.11028467,  0.01982497,\n",
       "       -0.06891869, -0.08192637, -0.03162065,  0.14028183, -0.16882184,\n",
       "       -0.00217259, -0.17267032,  0.05913808,  0.15451282, -0.51901776,\n",
       "       -0.01120506, -0.03567332, -0.02356086,  0.05626419,  0.01832112,\n",
       "        0.11841672, -0.11013965, -0.20385939, -0.05613225,  0.02324326,\n",
       "        0.22101991,  0.0057895 , -0.15305755,  0.20544632, -0.00566075,\n",
       "        0.18533684, -0.00783941, -0.24216282,  0.38022706, -0.21066627,\n",
       "        0.09250084, -0.02022469,  0.16873707, -0.22739425,  0.26940194,\n",
       "        0.43841124,  0.07491374,  0.1241824 ,  0.12053468, -0.0254384 ,\n",
       "        0.18386628, -0.17954062,  0.11470567,  0.11893508, -0.06129062,\n",
       "        0.586587  ,  0.21437944,  0.0962599 ,  0.03647536,  0.08766542,\n",
       "        0.03760685, -0.28428143,  0.04828709, -0.07125295, -0.01423977,\n",
       "        0.11346132,  0.10012062, -0.17711027,  0.02489856, -0.1209152 ,\n",
       "       -0.20355561,  0.09806728,  0.04070761, -0.02956315,  0.11657444,\n",
       "        0.30930713, -0.00886048, -0.01742178,  0.07484837,  0.12925075,\n",
       "        0.2788099 , -0.0472439 , -0.24823178,  0.6899616 , -0.03949653,\n",
       "        0.09221421,  0.06217052,  0.0357007 ,  0.14674234, -0.03393075,\n",
       "       -0.12936588,  0.10403024,  0.13517559,  0.36226234,  0.24397862,\n",
       "        0.05442058,  0.03695016, -0.34306723,  0.00652186,  0.01445457,\n",
       "       -0.07807347,  0.23921117,  0.26070502,  0.02489515,  0.02399447,\n",
       "       -0.10493325, -0.09741614, -0.065077  , -0.10516341,  0.12550907,\n",
       "       -0.04181514, -0.16995108,  0.0957364 ,  0.02575174,  0.21689758,\n",
       "        0.08628022, -0.05982974, -0.06186202,  0.28605917, -0.20048238,\n",
       "       -0.1130252 ,  0.31461334,  0.03011719, -0.00939328, -0.42687553,\n",
       "       -0.02195528,  0.07888325, -0.24848482,  0.13419262,  0.04031822,\n",
       "        0.00741631,  0.10061885,  0.26755363, -0.08542958, -0.07696437,\n",
       "        0.01600882, -0.06855448, -0.11881308,  0.15617537, -0.28950313,\n",
       "        0.2687008 , -0.38765436,  0.296275  ,  0.0522567 , -0.05219159,\n",
       "        0.14493883, -0.2735323 ,  0.18369994,  0.03590529, -0.33029842,\n",
       "        0.07521604, -0.2453059 , -0.22735663, -0.08443642, -0.01653371,\n",
       "        0.19067201,  0.09253333, -0.10276125, -0.15074955,  0.43862173,\n",
       "        0.02282783,  0.32753655, -0.23230769,  0.14533569,  0.05898703,\n",
       "        0.10554583,  0.24403358,  0.19411324, -0.1635854 ,  0.05169443,\n",
       "        0.08932233, -0.12558416, -0.03800039,  0.1820996 , -0.02484003,\n",
       "        0.26347727,  0.28324854, -0.36046055,  0.34785   , -0.20876764,\n",
       "       -0.09885671, -0.11448666, -0.03355812,  0.01279505,  0.06980468,\n",
       "        0.3298007 , -0.04743326,  0.38316426,  0.15647887, -0.0156276 ,\n",
       "       -0.16614053, -0.19461074, -0.34692577,  0.14608493,  0.01602469,\n",
       "        0.04075786,  0.04200312, -0.08132445,  0.23498756, -0.21931534,\n",
       "        0.05470397,  0.12650518,  0.10071927,  0.17794925, -0.05356961,\n",
       "        0.15904135,  0.08422159,  0.15881951,  0.11661986,  0.22336644,\n",
       "        0.18987417, -0.08522514, -0.24780653, -0.13541228,  0.13214624,\n",
       "        0.31884006, -0.41915265, -0.11590949, -0.16027622,  0.10131255,\n",
       "        0.07297463,  0.1460672 , -0.12780002, -0.1479654 , -0.18072788,\n",
       "       -0.07361496,  0.07158388, -0.15352151, -0.08185542,  0.0158846 ,\n",
       "        0.3383576 , -0.13921733,  0.0289905 ,  0.35168743, -0.24756461,\n",
       "        0.04365616,  0.07441095, -0.21481588,  0.02579711, -0.37374592,\n",
       "        0.13232052,  0.0263411 , -0.49079704,  0.18884607,  0.0853933 ,\n",
       "       -0.25783283,  0.3370044 ,  0.04300497, -0.1520445 ,  0.03399311,\n",
       "        0.01438794,  0.1020517 ,  0.02130685, -0.17040905,  0.07561665,\n",
       "       -0.2250977 , -0.1926698 , -0.13770416, -0.38489428, -0.27918172,\n",
       "       -0.02430829,  0.31590092,  0.09890022, -0.5040393 , -0.1601825 ,\n",
       "        0.01108424,  0.05444203,  0.43719628,  0.02601979,  0.19858712,\n",
       "       -0.08635192, -0.10768298, -0.0822327 , -0.13625948,  0.48018676,\n",
       "        0.05422862, -0.08644635, -0.0697926 , -0.33166376,  0.02708684,\n",
       "        0.01393992, -0.34324738, -0.08718285,  0.22309223, -0.1453498 ,\n",
       "       -0.14078346, -0.09326119, -0.0620997 , -0.13508905, -0.01424553,\n",
       "        0.02370902,  0.25590402,  0.23304333,  0.07123213,  0.4161893 ,\n",
       "        0.10518929, -0.2860199 ,  0.12104746,  0.07108955, -0.26276875],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of words in the vocabulary\n",
    "vocab = vocab\n",
    "print(len(vocab))\n",
    "\n",
    "w2v_dict = {}\n",
    "for word in vocab:\n",
    "    w2v_dict[word] = w2v_model.wv.get_vector(word)\n",
    "    \n",
    "print(\"the no of key-value pairs:\"  , len(w2v_dict)) #should be equal to vocabze\n",
    "\n",
    "# word_vec_dict={}\n",
    "# for word in vocab:\n",
    "#   word_vec_dict[word]=w2v_model.wv.get_vector(word)\n",
    "# print(\"The no of key-value pairs : \",len(word_vec_dict)) # should come equal to vocab size\n",
    "\n",
    "w2v_dict.get('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "76ea22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the embedding matrix\n",
    "embed_matrix = np.zeros(shape= (vocab_size , embed_dim))\n",
    "for word,i in tok.word_index.items():\n",
    "    embed_vector = w2v_dict.get(word)\n",
    "    if embed_vector is not None:   # word is in the vocabulary learned by the w2v model\n",
    "        embed_matrix[i]=embed_vector\n",
    "     # if word is not found then embed_vector corressponding to that vector will stay zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5bf4e642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(embed_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dcdf9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.Constant(embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "61422d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 82, 300)           3040500   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10135)             1023635   \n",
      "=================================================================\n",
      "Total params: 4,224,535\n",
      "Trainable params: 4,224,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_len, vocab_size):\n",
    "    input_len = max_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(input_dim=vocab_size,output_dim=embed_dim,input_length=max_len,embeddings_initializer=initializer))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_len, vocab_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7ed66aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 4.9677\n",
      "Epoch 2/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 4.4265\n",
      "Epoch 3/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 3.9683\n",
      "Epoch 4/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 3.5865\n",
      "Epoch 5/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 3.2527\n",
      "Epoch 6/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 2.9589\n",
      "Epoch 7/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 2.7131\n",
      "Epoch 8/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 2.5071\n",
      "Epoch 9/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 2.3288\n",
      "Epoch 10/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 2.1936\n",
      "Epoch 11/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 2.0670\n",
      "Epoch 12/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.9671\n",
      "Epoch 13/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.8873\n",
      "Epoch 14/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.8073\n",
      "Epoch 15/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.7496\n",
      "Epoch 16/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.6863\n",
      "Epoch 17/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.6396\n",
      "Epoch 18/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.5978\n",
      "Epoch 19/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.5516\n",
      "Epoch 20/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.5139\n",
      "Epoch 21/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.4876\n",
      "Epoch 22/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.4587\n",
      "Epoch 23/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.4306\n",
      "Epoch 24/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.4057\n",
      "Epoch 25/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.3898\n",
      "Epoch 26/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.3687\n",
      "Epoch 27/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.3436\n",
      "Epoch 28/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.3322\n",
      "Epoch 29/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.3174\n",
      "Epoch 30/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2967\n",
      "Epoch 31/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2872\n",
      "Epoch 32/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2740\n",
      "Epoch 33/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2624\n",
      "Epoch 34/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2519\n",
      "Epoch 35/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2434\n",
      "Epoch 36/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2329\n",
      "Epoch 37/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2295\n",
      "Epoch 38/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2145\n",
      "Epoch 39/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.2072\n",
      "Epoch 40/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1984\n",
      "Epoch 41/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1973\n",
      "Epoch 42/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1838\n",
      "Epoch 43/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1745\n",
      "Epoch 44/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1734\n",
      "Epoch 45/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1690\n",
      "Epoch 46/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1649\n",
      "Epoch 47/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1577\n",
      "Epoch 48/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1507\n",
      "Epoch 49/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1485\n",
      "Epoch 50/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1454\n",
      "Epoch 51/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1435\n",
      "Epoch 52/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1371\n",
      "Epoch 53/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1304\n",
      "Epoch 54/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1342\n",
      "Epoch 55/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1255\n",
      "Epoch 56/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1214\n",
      "Epoch 57/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1213\n",
      "Epoch 58/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1146\n",
      "Epoch 59/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1159\n",
      "Epoch 60/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1077\n",
      "Epoch 61/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1080\n",
      "Epoch 62/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.1039\n",
      "Epoch 63/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0996\n",
      "Epoch 64/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0979\n",
      "Epoch 65/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0960\n",
      "Epoch 66/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0946\n",
      "Epoch 67/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0909\n",
      "Epoch 68/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0931\n",
      "Epoch 69/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0903\n",
      "Epoch 70/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0916\n",
      "Epoch 71/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0843\n",
      "Epoch 72/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0782\n",
      "Epoch 73/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0795\n",
      "Epoch 74/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0760\n",
      "Epoch 75/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0786\n",
      "Epoch 76/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0762\n",
      "Epoch 77/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0749\n",
      "Epoch 78/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0769\n",
      "Epoch 79/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0693\n",
      "Epoch 80/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0687\n",
      "Epoch 81/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0682\n",
      "Epoch 82/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0632\n",
      "Epoch 83/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0668\n",
      "Epoch 84/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0617\n",
      "Epoch 85/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0609\n",
      "Epoch 86/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0586\n",
      "Epoch 87/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0661\n",
      "Epoch 88/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0619\n",
      "Epoch 89/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0525\n",
      "Epoch 90/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0522\n",
      "Epoch 91/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0518\n",
      "Epoch 92/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0577\n",
      "Epoch 93/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0570\n",
      "Epoch 94/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0511\n",
      "Epoch 95/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0551\n",
      "Epoch 96/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0520\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0537\n",
      "Epoch 98/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0514\n",
      "Epoch 99/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0504\n",
      "Epoch 100/100\n",
      "1222/1222 [==============================] - 7s 6ms/step - loss: 1.0456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245d3862cd0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3880e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tok.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "#         predicted = model.predict_classes(token_list, verbose=0)\n",
    "        predicted=model.predict(token_list, verbose = 0) \n",
    "        classes_x=np.argmax(predicted,axis=1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tok.word_index.items():\n",
    "            if index == classes_x:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cf5af44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression With Tensorflow\n",
      "Linear Regression\n",
      "Xg Cv Statisticsbetter Parameters\n"
     ]
    }
   ],
   "source": [
    "print (generate_text(\"logistic\", 3, model, max_len))\n",
    "print (generate_text(\"linear\", 1, model, max_len))\n",
    "print (generate_text(\"xg\", 3, model, max_len))\n",
    "# print (generate_text(\"preident trump\", 4, model, max_len))\n",
    "# print (generate_text(\"donald trump\", 4, model, max_len))\n",
    "# print (generate_text(\"india and china\", 4, model, max_len))\n",
    "# print (generate_text(\"new york\", 4, model, max_len))\n",
    "# print (generate_text(\"science and technology\", 5, model, max_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.6.0",
   "language": "python",
   "name": "tf2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
